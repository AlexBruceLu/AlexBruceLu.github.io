[{"title":"安装Minikube","url":"/2020/01/07/安装Minikube/","content":"\n","tags":["kubernetes"],"categories":["Windows","k8s"]},{"title":"kubernetes在windows使用","url":"/2020/01/07/kubernetes在windows使用/","content":"\n@[TOC]\n\n# 通过 Minikube 在本地运行 Kubernetes\n\n`Minikube` 是一个可以在本地轻松运行 `Kubernetes` 的工具。`Minikube` 会在笔记本电脑中的虚拟机上运行一个单节点的 `Kubernetes` 集群，以便用户对 `Kubernetes` 进行试用或者在之上进行 `Kubernetes` 的日常开发。\n\n### Minikube 功能\n\n- Minikube 支持的 Kubernetes 功能包括：\n  - DNS\n  - NodePorts\n  - ConfigMaps 和 Secrets\n  - 仪表盘\n  - 容器运行时：Docker，[rkt](https://github.com/rkt/rkt) 和 [CRI-O](https://github.com/kubernetes-incubator/cri-o)\n  - 启用 CNI (Container Network Interface，容器网络接口)\n  - Ingress\n\n## 安装\n\n参见 [安装 Minikube](https://alexbrucelu.github.io/2020/01/07/kubernetes%E7%BB%84%E4%BB%B6/)\n\n## 快速入门\n\n这是 minikube 用法的简单演示。 如果希望改变虚拟机驱动（VM driver），请添加恰当的 `--vm-driver=xxx` 参数到 `minikube start`。Minikube 支持以下驱动：\n\n- virtualbox\n- vmwarefusion\n- kvm ([driver installation](https://git.k8s.io/minikube/docs/drivers.md#kvm-driver))\n- xhyve ([driver installation](https://git.k8s.io/minikube/docs/drivers.md#xhyve-driver))\n\n请注意，下面的 IP 是动态的并且可以更改。可以通过 `minikube ip` 获取。\n\n```\n$ minikube start\nStarting local Kubernetes cluster...\nRunning pre-create checks...\nCreating machine...\nStarting local Kubernetes cluster...\n\n$ kubectl run hello-minikube --image=k8s.gcr.io/echoserver:1.4 --port=8080\ndeployment \"hello-minikube\" created\n$ kubectl expose deployment hello-minikube --type=NodePort\nservice \"hello-minikube\" exposed\n\n# We have now launched an echoserver pod but we have to wait until the pod is up before curling/accessing it\n# via the exposed service.\n# To check whether the pod is up and running we can use the following:\n$ kubectl get pod\nNAME                              READY     STATUS              RESTARTS   AGE\nhello-minikube-3383150820-vctvh   1/1       ContainerCreating   0          3s\n# We can see that the pod is still being created from the ContainerCreating status\n$ kubectl get pod\nNAME                              READY     STATUS    RESTARTS   AGE\nhello-minikube-3383150820-vctvh   1/1       Running   0          13s\n# We can see that the pod is now Running and we will now be able to curl it:\n$ curl $(minikube service hello-minikube --url)\nCLIENT VALUES:\nclient_address=192.168.99.1\ncommand=GET\nreal path=/\n...\n$ kubectl delete deployment hello-minikube\ndeployment \"hello-minikube\" deleted\n$ minikube stop\nStopping local Kubernetes cluster...\nStopping \"minikube\"...\n```\n\n### 其它容器运行时\n\n#### CRI-O\n\n要使用 [CRI-O](https://github.com/kubernetes-incubator/cri-o) 作为容器运行时，请运行：\n\n```\n$ minikube start \\\n    --network-plugin=cni \\\n    --container-runtime=cri-o \\\n    --bootstrapper=kubeadm\n```\n\n或者可以使用扩展版本：\n\n```\n$ minikube start \\\n    --network-plugin=cni \\\n    --extra-config=kubelet.container-runtime=remote \\\n    --extra-config=kubelet.container-runtime-endpoint=/var/run/crio.sock \\\n    --extra-config=image-service-endpoint=/var/run/crio.sock \\\n    --bootstrapper=kubeadm\n```\n\n#### rkt 容器引擎\n\n使用 [rkt](https://github.com/rkt/rkt) 作为容器运行时，请运行：\n\n```\n$ minikube start \\\n    --network-plugin=cni \\\n    --container-runtime=rkt\n```\n\n这将使用另一个包含 rkt 和 Docker 的 minikube ISO 镜像，并启用 CNI 网络。\n\n### 驱动插件\n\n如果有需要，请参阅 [DRIVERS](https://git.k8s.io/minikube/docs/drivers.md) 了解支持的驱动程序以及如何安装插件的详细说明。\n\n### 重用 Docker 守护进程\n\n当使用单个虚拟机运行 Kubernetes 时，重用 minikube 内置的 Docker 守护进程非常方便；因为这意味着您不必在主机上搭建一个 docker 仓库并将镜像推送到上面 —— 您可以在与 minikube 相同的 docker 守护进程中构建，以加快本地实验的速度。请确保使用 ‘latest’ 以外的标签来标记您的 Docker 镜像，并在拉取镜像时使用这个标签。否则，如果不指定镜像的版本，那么它将被假定为 `:latest`，在对应的镜像拉取策略为 `Always` 时，这可能最终导致 `ErrImagePull` 错误，因为您在默认 docker 仓库（通常为 DockerHub）中可能还没有任何版本的 Docker 镜像。\n\n为了能够在您的 mac/linux 主机上使用 docker 守护进程，请在 shell 中使用 `docker-env command`：\n\n```\neval $(minikube docker-env)\n```\n\n现在您应该可以在您的 mac/linux 主机上通过命令行使用 docker 与 minikube 虚拟机中的 docker 守护进程进行通信了：\n\n```\ndocker ps\n```\n\n在 Centos 7 上，docker 可能会报告以下错误：\n\n```\nCould not read CA certificate \"/etc/docker/ca.pem\": open /etc/docker/ca.pem: no such file or directory\n```\n\n解决的办法是更新 /etc/sysconfig/docker 以确保遵循了 minikube 的环境更改：\n\n```\n< DOCKER_CERT_PATH=/etc/docker\n---\n> if [ -z \"${DOCKER_CERT_PATH}\" ]; then\n>   DOCKER_CERT_PATH=/etc/docker\n> fi\n```\n\n请记得关闭 imagePullPolicy:Always 策略，否则 Kubernetes 将不会使用您在本地创建的镜像。\n\n## 管理您的集群\n\n### 启动集群\n\n`minikube start` 命令可以用来启动您的集群。 这个命令创建并配置一个运行单节点 Kubernetes 集群的虚拟机。 这个命令还会配置您的 [kubectl](https://k8smeetup.github.io/docs/user-guide/kubectl-overview/) 以与此集群进行通信。\n\n如果您处于网络代理之后，则需要通过这种方式传递代理信息：\n\n```\nhttps_proxy=<my proxy> minikube start --docker-env HTTP_PROXY=<my proxy> --docker-env HTTPS_PROXY=<my proxy> --docker-env NO_PROXY=192.168.99.0/24\n```\n\n不幸的是，只是设置环境变量将不起作用。\n\nMinikube 还将创建一个 “minikube” 上下文，并将其设置为 kubectl 中的默认值。 以后如果要切换回这个上下文，请运行命令：`kubectl config use-context minikube`。\n\n#### 指定 Kubernetes 版本\n\nMinikube 支持运行多个不同版本的 Kubernetes。您可以像这样获取所有可用版本的列表：\n\n```\nminikube get-k8s-versions\n```\n\n您可以通过添加 `--kubernetes-version` 字符串到 `minikube start` 命令中以指示 Minikube 使用的特定的 Kubernetes 版本。例如，要运行 `v1.7.3` 版本，您可以运行以下命令：\n\n```\nminikube start --kubernetes-version v1.7.3\n```\n\n### 配置 Kubernetes\n\nMinikube 具有一个 “configurator” 功能，允许用户使用任意值配置 Kubernetes 组件。 要使用这个功能，您可以在 `minikube start` 命令中使用 `--extra-config` 参数。\n\n这个标志是可重复的，所以你可以通过几个不同的值来设置多个选项。\n\n该标志是采用 `component.key=value` 形式的字符串，其中 `component` 是下面列表中的字符串之一，`key` 是配置结构体中的项，而`value` 是要设置的值。\n\n通过检查每个组件的 Kubernetes `componentconfigs` 文档可以找到有效的 key。 以下是支持的配置的文档：\n\n- [kubelet](https://godoc.org/k8s.io/kubernetes/pkg/apis/componentconfig#KubeletConfiguration)\n- [apiserver](https://godoc.org/k8s.io/kubernetes/cmd/kube-apiserver/app/options#APIServer)\n- [proxy](https://godoc.org/k8s.io/kubernetes/pkg/apis/componentconfig#KubeProxyConfiguration)\n- [controller-manager](https://godoc.org/k8s.io/kubernetes/pkg/apis/componentconfig#KubeControllerManagerConfiguration)\n- [etcd](https://godoc.org/github.com/coreos/etcd/etcdserver#ServerConfig)\n- [scheduler](https://godoc.org/k8s.io/kubernetes/pkg/apis/componentconfig#KubeSchedulerConfiguration)\n\n#### 示例\n\n要在 Kubelet 上将 `MaxPods` 设置更改为 5，请传递此参数：`--extra-config=kubelet.MaxPods=5`。\n\n该功能还支持嵌套结构。要在 scheduler 中将 `LeaderElection.LeaderElect` 设置更改为 `true`，请传递此参数：`--extra-config=scheduler.LeaderElection.LeaderElect=true`。\n\n要将 `apiserver` 上的 `AuthorizationMode` 设置为 `RBAC`，可以使用：`--extra-config=apiserver.AuthorizationMode=RBAC`。\n\n### 停止集群\n\n`minikube stop` 命令可以用来停止集群。 该命令会关闭 minikube 虚拟机，但将保留所有集群状态和数据。 再次启动集群将恢复到之前的状态。\n\n### 删除集群\n\n`minikube delete` 命令可以用来删除集群。 该命令将关闭并删除 minikube 虚拟机。没有数据或状态会被保存下来。\n\n## 与集群交互\n\n### Kubectl\n\n`minikube start` 会创建一个名为 “minikube” 的”[kubectl context](https://k8smeetup.github.io/docs/user-guide/kubectl/v1.9/#-em-set-context-em-)“。这个 context 中包含了与您的 minikube 集群进行通信的配置。\n\nMinikube 会自动将此 context 设置为默认值，但如果将来需要切换回该值，请运行：\n\n`kubectl config use-context minikube`,\n\n或者像这样为每个命令传递 context：`kubectl get pods --context=minikube`。\n\n### 仪表盘\n\n要访问 [Kubernetes 仪表盘](https://k8smeetup.github.io/docs/tasks/access-application-cluster/web-ui-dashboard/)，请在 minikube 启动后在 shell 中运行此命令以获取访问地址：\n\n```\nminikube dashboard\n```\n\n### Services\n\n要访问通过 node port 公开的服务，请在 minikube 启动后在 shell 中运行此命令以获取访问地址：\n\n```\nminikube service [-n NAMESPACE] [--url] NAME\n```\n\n## 网络\n\nminikube 虚拟机通过 host-only IP 地址暴露给主机系统，可以通过 `minikube ip` 命令获取该地址。 可以通过该 IP 地址访问任何 NodePort 类型的服务。\n\n为了确定服务的 NodePort，您可以像这样使用 `kubectl` 命令：\n\n```\nkubectl get service $SERVICE --output='jsonpath=\"{.spec.ports[0].nodePort}\"'\n```\n\n## 持久化存储卷（Persistent Volumes）\n\nMinikube 支持 `hostPath` 类型的 [PersistentVolumes](https://k8smeetup.github.io/docs/concepts/storage/persistent-volumes/)。 这些 PersistentVolume 被映射到 minikube 虚拟机内的一个目录。\n\nMinikube 虚拟机引导到一个 tmpfs，所以大多数目录将不会在重启（`minikube stop`）后保留。\n\n- `/data`\n- `/var/lib/localkube`\n- `/var/lib/docker`\n\n下面是一个 PersistentVolume 的配置示例，用于将数据保存在 `/data` 目录中：\n\n```\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pv0001\nspec:\n  accessModes:\n    - ReadWriteOnce\n  capacity:\n    storage: 5Gi\n  hostPath:\n    path: /data/pv0001/\n```\n\n## 挂载主机文件夹\n\n一些驱动程序将在虚拟机内安装一个主机文件夹，以便您可以轻松地在虚拟机和主机之间共享文件。这些目前不可配置，而且因您正在使用的驱动程序和操作系统而有所不同。\n\n| Driver        | OS      | HostFolder | VM        |\n| :------------ | :------ | :--------- | :-------- |\n| VirtualBox    | Linux   | /home      | /hosthome |\n| VirtualBox    | OSX     | /Users     | /Users    |\n| VirtualBox    | Windows | C://Users  | /c/Users  |\n| VMWare Fusion | OSX     | /Users     | /Users    |\n| Xhyve         | OSX     | /Users     | /Users    |\n\n## 私有容器仓库\n\n要访问私有容器仓库，请按照 [此页面](https://k8smeetup.github.io/docs/concepts/containers/images/) 中的步骤操作。\n\n我们推荐使用 `ImagePullSecrets`，但是如果您想在 minikube 虚拟机上配置访问权限，可以把 `.dockercfg` 放在 `/home/docker` 目录下或将 `config.json` 放在 `/home/docker/.docker` 下。\n\n## 插件\n\n为了让 minikube 正确启动或重启自定义插件，请在 `~/.minikube/addons` 目录中放置您想用 minikube 启动的插件。这个文件夹中的插件将被移动到 minikube 虚拟机，并在 minikube 每次启动或重启时启动。\n\n## 通过 HTTP 代理使用 Minikube\n\nMinikube 创建一个包含 Kubernetes 和 Docker 守护进程的虚拟机。当 Kubernetes 尝试使用 Docker 来调度容器时，Docker 守护进程可能需要访问外部网络来拉取容器。\n\n如果您位于 HTTP 代理的后面，则可能需要向 Docker 提供代理设置。 为此，需要在 `minikube start` 期间将所需的环境变量作为参数进行传递。\n\n示例：\n\n```\n$ minikube start --docker-env HTTP_PROXY=http://$YOURPROXY:PORT \\\n                 --docker-env HTTPS_PROXY=https://$YOURPROXY:PORT\n```\n\n如果您的虚拟机地址是 192.168.99.100，那么您的代理设置很可能会阻止 kubectl 对它的直接访问。要绕过此 IP 地址的代理配置，您应该修改 no_proxy 设置。您可以这样配置：\n\n```\n$ export no_proxy=$no_proxy,$(minikube ip)\n```\n\n## 已知问题\n\n- 需要云服务提供商的功能在 Minikube 中不能使用。包括：\n  - 负载均衡器（LoadBalancer）\n- 需要多个节点的功能。包括：\n  - 高级调度策略\n\n## 设计\n\nMinikube 通过 [libmachine](https://github.com/docker/machine/tree/master/libmachine) 提供虚拟机，及使用 [localkube](https://git.k8s.io/minikube/pkg/localkube)（最初由 [RedSpread](https://redspread.com/)编写并捐赠给此项目）来运行集群。\n\n有关 minikube 的更多信息，请参阅[提案](https://git.k8s.io/community/contributors/design-proposals/cluster-lifecycle/local-cluster-ux.md)。\n\n## 其它链接\n\n- **目标和非目标**：对于 minikube 项目的目标和非目标，请参阅我们的 [路线图](https://git.k8s.io/minikube/docs/contributors/roadmap.md)。\n- **开发指南**：请参阅 [CONTRIBUTING.md](https://git.k8s.io/minikube/CONTRIBUTING.md) 了解如何发送 pull request。\n- **构建 Minikube**：有关如何从源代码构建/测试 minikube 的说明，请参阅 [构建指南](https://git.k8s.io/minikube/docs/contributors/build_guide.md)。\n- **添加一个新依赖**：有关如何添加一个新依赖到 minikube 的说明，请参阅 [添加依赖指南](https://git.k8s.io/minikube/docs/contributors/adding_a_dependency.md)。\n- **添加一个新插件**：有关如何添加一个新插件 minikube 的指导，请查看 [添加插件指南](https://git.k8s.io/minikube/docs/contributors/adding_an_addon.md)。\n- **更新 Kubernetes**：有关如何更新 Kubernetes 的说明，请参阅 [更新Kubernetes指南](https://git.k8s.io/minikube/docs/contributors/updating_kubernetes.md)。\n\n## 社区\n\n我们欢迎所有的贡献、问题和评论！Minikube 开发者在 [Slack](https://kubernetes.slack.com/) 的 #minikube 频道中闲聊（从 [这里](http://slack.kubernetes.io/) 获得一个邀请）。我们也有 [kubernetes-dev Google Groups 邮件列表](https://groups.google.com/forum/#!forum/kubernetes-dev)。如果您正在向列表中发送，请在主题前加上 “minikube: “。","tags":["kubernetes"],"categories":["Windows","k8s"]},{"title":"kubernetes组件","url":"/2020/01/07/kubernetes组件/","content":"\n@[TOC]\n\n# kubernetes组件\n\n## Master组件\n\n`master`组件提供集群管理控制中心。\n\n`master`组件可以在集群任意节点运行。但是为了简单起见，通常在一台VM/机器上启动所有Master组件，并且不会在此VM/机器上运行用户容器。请参考 [构建高可用群集](https://kubernetes.io/docs/admin/high-availability)以来构建multi-master-VM。\n\n### kube-apiserver\n\n[kube-apiserver](https://kubernetes.io/docs/admin/kube-apiserver)用于暴露Kubernetes API。任何的资源请求/调用操作都是通过kube-apiserver提供的接口进行。请参阅[构建高可用群集](https://kubernetes.io/docs/admin/high-availability)。\n\n### ETCD\n\n[etcd](https://kubernetes.io/docs/admin/etcd)是Kubernetes提供默认的存储系统，保存所有集群数据，使用时需要为etcd数据提供备份计划。\n\n### kube-controller-manager\n\n[kube-controller-manager](https://kubernetes.io/docs/admin/kube-controller-manager)运行管理控制器，它们是集群中处理常规任务的后台线程。逻辑上，每个控制器是一个单独的进程，但为了降低复杂性，它们都被编译成单个二进制文件，并在单个进程中运行。\n\n这些控制器包括：\n\n- [节点（Node）控制器](http://docs.kubernetes.org.cn/304.html)。\n- 副本（Replication）控制器：负责维护系统中每个副本中的pod。\n- 端点（Endpoints）控制器：填充Endpoints对象（即连接Services＆Pods）。\n- [Service Account](http://docs.kubernetes.org.cn/84.html)和Token控制器：为新的[Namespace](http://docs.kubernetes.org.cn/242.html) 创建默认帐户访问API Token。\n\n### cloud-controller-manager\n\n云控制器管理器负责与底层云提供商的平台交互。云控制器管理器是Kubernetes版本1.6中引入的，目前还是Alpha的功能。\n\n云控制器管理器仅运行云提供商特定的（controller loops）控制器循环。可以通过将`--cloud-provider` flag设置为external启动kube-controller-manager ，来禁用控制器循环。\n\n`cloud-controller-manager` 具体功能：\n\n- 节点（Node）控制器\n- 路由（Route）控制器\n- Service控制器\n- 卷（Volume）控制器\n\n### kube-scheduler\n\n`kube-scheduler` 监视新创建没有分配到[Node](http://docs.kubernetes.org.cn/304.html)的[Pod](http://docs.kubernetes.org.cn/312.html)，为Pod选择一个Node。\n\n### 插件addons\n\n插件（addon）是实现集群pod和Services功能的 。Pod由[Deployments](http://docs.kubernetes.org.cn/317.html)，ReplicationController等进行管理。Namespace 插件对象是在kube-system Namespace中创建。\n\n#### DNS\n\n虽然不严格要求使用插件，但Kubernetes集群都应该具有集群 DNS。\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t群集 DNS是一个DNS服务器，能够为 Kubernetes services提供 DNS记录。由Kubernetes启动的容器自动将这个DNS服务器包含在他们的DNS searches中。\n\n了解[更多详情](https://www.kubernetes.org.cn/542.html)\n\n#### 用户界面\n\nkube-ui提供集群状态基础信息查看。更多详细信息，请参阅[使用HTTP代理访问Kubernetes API](https://kubernetes.io/docs/tasks/access-kubernetes-api/http-proxy-access-api/)\n\n#### 容器资源监测\n\n[容器资源监控](https://kubernetes.io/docs/user-guide/monitoring)提供一个UI浏览监控数据。\n\n#### cluster-level logging\n\n[Cluster-level logging](https://kubernetes.io/docs/user-guide/logging/overview)，负责保存容器日志，搜索/查看日志。[Cluster-level logging](https://kubernetes.io/docs/user-guide/logging/overview)，负责保存容器日志，搜索/查看日志。\n\n## Node组件\n\n节点组件运行在[Node](http://docs.kubernetes.org.cn/304.html)，提供Kubernetes运行时环境，以及维护Pod。\n\n### kubelet\n\n[kubelet](https://kubernetes.io/docs/admin/kubelet)是主要的节点代理，它会监视已分配给节点的pod，具体功能：\n\n- 安装Pod所需的volume。\n- 下载Pod的Secrets。\n- Pod中运行的 docker（或experimentally，rkt）容器。\n- 定期执行容器健康检查。\n- Reports the status of the pod back to the rest of the system, by creating a *mirror pod* if necessary.\n- Reports the status of the node back to the rest of the system.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n### kube-proxy\n\n[kube-proxy](https://kubernetes.io/docs/admin/kube-proxy)通过在主机上维护网络规则并执行连接转发来实现Kubernetes服务抽象。\n\n### docker\n\ndocker用于运行容器。\n\n### RKT\n\nrkt运行容器，作为docker工具的替代方案。\n\n### supervisord\n\nsupervisord是一个轻量级的监控系统，用于保障kubelet和docker运行。\n\n### fluentd\n\nfluentd是一个守护进程，可提供[cluster-level logging](https://kubernetes.io/docs/concepts/overview/components/#cluster-level-logging)。\n\n\n\n","tags":["kubernetes"],"categories":["Linux","k8s"]},{"title":"kubernetes","url":"/2020/01/07/kubernetes/","content":"\n@[TOC]\n\n# 概念\n\n## k8s是什么\n\n`kubernetes` 的名字来自希腊语，意思是“舵手”或者“领航员”。k8s是将`kubernetes` 中间8个字母`ubernete`替换为8的缩写。\n\n`kubernetes` 是容器集群管理系统，是一个开源的平台，可以实现容器集群化的自动化部署、自动扩缩容、维护等功能。通过`kubernetes` 你可以实现：\n\n1. 快速部署应用\n2. 快速扩展应用\n3. 无缝对接新的应用功能\n4. 节省资源，优化硬件资源的使用\n\n## 特点\n\n1. <font color=red>**可移植：**</font> 支持公有云、私有云、混合云、多重云（multi-cloud）\n2. <font color=red>**可扩展：**</font> 模块化、插件化、可挂载、可组合\n3. <font color=red>**自动化：**</font> 自动化部署，自动重启，自动复制，自动伸缩、扩展\n\n## 为什么要使用容器\n\n\n\n![](https://raw.githubusercontent.com/wiki/AlexBruceLu/AlexBruceLu.github.io/k8s/why_containers.jpg)\n\n传统的应用部署方式是通过脚本或者插件来安装应用。这样的缺点是应用的运运行、配置、管理、所有生存周期将与当前操作系统绑定，这样做并不利于升级、回滚等操作。当然也可以使用创建虚拟机的方式来实现某些功能，但是虚拟机是非常重，并不具有可移植性。\n\n新的方式是通过部署容器的方式来实现，每个容器之间相互隔离，每一个容器都有自己的文件系统，容器之间的进程互不影响，能区分计算资源。相对虚拟机，容器能够快速部署。由于容器与底层设施、机器文件之间是解耦的，所以能在不同云、不同操作系统之间进行迁移。\n\n容器占用资源少，部署快。每个应用都可以被打包成一个镜像。使得应用与镜像之间是一一对应关系，这也让容器更加具有优势。使用容器可以在`build`或者`release`的阶段，为应用创建容器镜像，因为每个应用不需要与其他的应用堆栈组合，也不依赖于 生产环境基础结构，这就能保证开发、测试环境的一致性。同时容器比虚拟机更加的”透明“，方便监控和管理。\n\n> **<font color=red>容器的优势总结：</font>**\n>\n> 1. **快速创建、部署应用：**与虚拟机相比容器的创建更加容易\n> 2. **持续开发、集成和部署：**提供可靠且频繁的容器镜像构建、部署，并使用快速和简单的回滚（由于镜像的不可变性）。\n> 3. **开发和运行相分离：** 在build或者release阶段创建容器镜像，使得应用和基础设施解耦。\n> 4. **开发测试环境的一致性：**在本地或者外网运行一致性\n> 5. **支持云平台、或其他操作系统：**可以在`Ubuntu`、`RHEL`、` CoreOS`、`on-prem`、`Google Container Engine`或其它任何环境中运行。\n> 6. **Lossely coupled，分布式，弹性，微服务化：**应用程序分为更小更独立的部件，可以动态部署和管理。\n> 7. **资源隔离：**每个容器之间相互隔离，都有独立的文件系统、互不影响\n> 8. **资源利用：**更高效\n\n## 能做什么\n\n可以在物理机或者虚拟机的kubernetes集群上运行容器化应用，kubernetes能提供一个”以容器为中心的基础架构“，满足生产环境中运行应用的常见需求：\n\n> 1. 多个进程（作为容器运行）协同工作（pod）\n> 2. 储存系统挂载\n> 3. Distributing secrets\n> 4. 应用健康检测\n> 5. 应用实例的复制\n> 6. pod自动伸缩、扩展\n> 7. Naming and discovering\n> 8. 负载均衡\n> 9. 滚动更新\n> 10. 资源监控\n> 11. 日志访问\n> 12. 调试应用程序\n> 13. 提供认证和授权\n\n## 不是什么\n\n1. Kubernetes并不是传统的PaaS（平台即服务）系统。\n2. Kubernetes不限制支持应用的类型，不限制应用框架。不限制受支持的语言runtimes (例如, Java, Python, Ruby)，满足[12-factor applications](https://12factor.net/) 。不区分 “apps” 或者“services”。 Kubernetes支持不同负载应用，包括有状态、无状态、数据处理类型的应用。只要这个应用可以在容器里运行，那么就能很好的运行在Kubernetes上。\n3. Kubernetes不提供中间件（如message buses）、数据处理框架（如Spark）、数据库(如Mysql)或者集群存储系统(如Ceph)作为内置服务。但这些应用都可以运行在Kubernetes上面。\n4. Kubernetes不部署源码不编译应用。持续集成的 (CI)工作流方面，不同的用户有不同的需求和偏好的区域，因此，提供分层的 CI工作流，但并不定义它应该如何工作。\n5. Kubernetes允许用户选择自己的日志、监控和报警系统。\n6. Kubernetes不提供或授权一个全面的应用程序配置 语言/系统（例如，[jsonnet](https://github.com/google/jsonnet)）。\n7. Kubernetes不提供任何机器配置、维护、管理或者自修复系统。\n\n> 另一方面，大量的Paas系统都可以运行在Kubernetes上，比如Openshift、Deis、Gondor。可以构建自己的Paas平台，与自己选择的CI系统集成。\n>\n> 由于Kubernetes运行在应用级别而不是硬件级，因此提供了普通的Paas平台提供的一些通用功能，比如部署，扩展，负载均衡，日志，监控等。这些默认功能是可选的。\n>\n> 另外，Kubernetes不仅仅是一个“编排系统”；它消除了编排的需要。“编排”的定义是指执行一个预定的工作流：先执行A，之B，然C。相反，Kubernetes由一组独立的可组合控制进程组成。怎么样从A到C并不重要，达到目的就好。当然集中控制也是必不可少，方法更像排舞的过程。这使得系统更加易用、强大、弹性和可扩展。","tags":["kubernetes"],"categories":["Linux","k8s"]},{"title":"cuda常见问题解决办法","url":"/2019/12/18/cuda常见问题解决办法/","content":"\n@[TOC]\n\n### 1. libnvinfer.so.5: cannot open shared object file: No such file or directory\n\n```bash\n# Add NVIDIA package repositories\n# Add HTTPS support for apt-key\nsudo apt-get install gnupg-curl\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.0.130-1_amd64.deb\nsudo dpkg -i cuda-repo-ubuntu1604_10.0.130-1_amd64.deb\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\nsudo apt-get update\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\nsudo apt-get update\n\n# Install NVIDIA driver\n# Issue with driver install requires creating /usr/lib/nvidia\nsudo mkdir /usr/lib/nvidia\nsudo apt-get install --no-install-recommends nvidia-418\n# Reboot. Check that GPUs are visible using the command: nvidia-smi\n\n# Install development and runtime libraries (~4GB)\nsudo apt-get install --no-install-recommends \\\n    cuda-10-0 \\\n    libcudnn7=7.6.2.24-1+cuda10.0  \\\n    libcudnn7-dev=7.6.2.24-1+cuda10.0\n\n\n# Install TensorRT. Requires that libcudnn7 is installed above.\nsudo apt-get install -y --no-install-recommends libnvinfer5=5.1.5-1+cuda10.0 \\\n    libnvinfer-dev=5.1.5-1+cuda10.0\n```\n\nGPU support\n\n\n\n**Note:** GPU support is available for Ubuntu and Windows with CUDA®-enabled cards.\n\nTensorFlow GPU support requires an assortment of drivers and libraries. To simplify installation and avoid library conflicts, we recommend using a [TensorFlow Docker image with GPU support](https://www.tensorflow.org/install/docker) (Linux only). This setup only requires the [NVIDIA® GPU drivers](https://www.nvidia.com/drivers).\n\nThese install instructions are for the latest release of TensorFlow. See the [tested build configurations](https://www.tensorflow.org/install/source#linux) for CUDA and cuDNN versions to use with older TensorFlow releases.\n\nPip package\n\nSee the [pip install guide](https://www.tensorflow.org/install/pip) for available packages, systems requirements, and instructions. To `pip` install a TensorFlow package with GPU support, choose a stable or development package:\n\n```bash\npip install tensorflow-gpu  # stable\n\npip install tf-nightly      # preview\n```\n\n\n\nOlder versions of TensorFlow\n\nFor the 1.15 release, CPU and GPU support are included in a single package:\n\n```bsh\npip install --pre \"tensorflow==1.15.*\"\n```\n\n\n\nFor releases 1.14 and older, CPU and GPU packages are separate:\n\n```bsh\npip install tensorflow==1.14      \n# CPU\npip install tensorflow-gpu==1.14  \n# GPU\n```\n\n\n\nHardware requirements\n\nThe following GPU-enabled devices are supported:\n\n- NVIDIA® GPU card with CUDA® Compute Capability 3.5 or higher. See the list of [CUDA-enabled GPU cards](https://developer.nvidia.com/cuda-gpus).\n\nSoftware requirements\n\nThe following NVIDIA® software must be installed on your system:\n\n- [NVIDIA® GPU drivers](https://www.nvidia.com/drivers) —CUDA 10.0 requires 410.x or higher.\n- [CUDA® Toolkit](https://developer.nvidia.com/cuda-toolkit-archive) —TensorFlow supports CUDA 10.0 (TensorFlow >= 1.13.0)\n- [CUPTI](http://docs.nvidia.com/cuda/cupti/) ships with the CUDA Toolkit.\n- [cuDNN SDK](https://developer.nvidia.com/cudnn) (>= 7.4.1)\n- *(Optional)* [TensorRT 5.0](https://docs.nvidia.com/deeplearning/sdk/tensorrt-install-guide/index.html) to improve latency and throughput for inference on some models.\n\nLinux setup\n\nThe `apt` instructions below are the easiest way to install the required NVIDIA software on Ubuntu. However, if [building TensorFlow from source](https://www.tensorflow.org/install/source), manually install the software requirements listed above, and consider using a `-devel` [TensorFlow Docker image](https://www.tensorflow.org/install/docker) as a base.\n\nInstall [CUPTI](http://docs.nvidia.com/cuda/cupti/) which ships with the CUDA® Toolkit. Append its installation directory to the `$LD_LIBRARY_PATH` environmental variable:\n\n```\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64\n```\n\n\n\nFor a GPU with CUDA Compute Capability 3.0, or different versions of the NVIDIA libraries, see the [Linux build from source](https://www.tensorflow.org/install/source) guide.\n\nInstall CUDA with apt\n\nThis section shows how to install CUDA 10 (TensorFlow >= 1.13.0) and CUDA 9 for Ubuntu 16.04 and 18.04. These instructions may work for other Debian-based distros.\n\n**Caution:** [Secure Boot](https://wiki.ubuntu.com/UEFI/SecureBoot) complicates installation of the NVIDIA driver and is beyond the scope of these instructions.\n\nUbuntu 18.04 (CUDA 10)\n\n```bsh\n# Add NVIDIA package repositorieswget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.debsudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.debsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pubsudo apt-get updatewget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.debsudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.debsudo apt-get update# Install NVIDIA driversudo apt-get install --no-install-recommends nvidia-driver-418# Reboot. Check that GPUs are visible using the command: nvidia-smi# Install development and runtime libraries (~4GB)sudo apt-get install --no-install-recommends \\    cuda-10-0 \\    libcudnn7=7.6.2.24-1+cuda10.0  \\    libcudnn7-dev=7.6.2.24-1+cuda10.0# Install TensorRT. Requires that libcudnn7 is installed above.sudo apt-get install -y --no-install-recommends libnvinfer5=5.1.5-1+cuda10.0 \\    libnvinfer-dev=5.1.5-1+cuda10.0\n```\n\n\n\nUbuntu 16.04 (CUDA 10)\n\n```bsh\n# Add NVIDIA package repositories# Add HTTPS support for apt-keysudo apt-get install gnupg-curlwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.0.130-1_amd64.debsudo dpkg -i cuda-repo-ubuntu1604_10.0.130-1_amd64.debsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pubsudo apt-get updatewget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.debsudo apt install ./nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.debsudo apt-get update# Install NVIDIA driver# Issue with driver install requires creating /usr/lib/nvidiasudo mkdir /usr/lib/nvidiasudo apt-get install --no-install-recommends nvidia-418# Reboot. Check that GPUs are visible using the command: nvidia-smi# Install development and runtime libraries (~4GB)sudo apt-get install --no-install-recommends \\    cuda-10-0 \\    libcudnn7=7.6.2.24-1+cuda10.0  \\    libcudnn7-dev=7.6.2.24-1+cuda10.0# Install TensorRT. Requires that libcudnn7 is installed above.sudo apt-get install -y --no-install-recommends libnvinfer5=5.1.5-1+cuda10.0 \\    libnvinfer-dev=5.1.5-1+cuda10.0\n```\n\n\n\nUbuntu 16.04 (CUDA 9.0 for TensorFlow < 1.13.0)\n\n```bash\n# Add NVIDIA package repository\nsudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\n\nwget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_9.1.85-1_amd64.deb\n\nsudo apt install ./cuda-repo-ubuntu1604_9.1.85-1_amd64.deb\n\nwget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\n\nsudo apt install ./nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb\nsudo apt update\n\n# Install the NVIDIA driver\n# Issue with driver install requires creating /usr/lib/nvidiasudo \n\nmkdir /usr/lib/nvidia\nsudo apt-get install --no-install-recommends nvidia-410\n\n# Reboot. Check that GPUs are visible using the command: nvidia-smi\n# Install CUDA and tools. Include optional NCCL 2.x\n\nsudo apt install cuda9.0 cuda-cublas-9-0 cuda-cufft-9-0 cuda-curand-9-0 \\    \n\tcuda-cusolver-9-0 cuda-cusparse-9-0 libcudnn7=7.2.1.38-1+cuda9.0 \\    \n\tlibnccl2=2.2.13-1+cuda9.0 cuda-command-line-tools-9-0\n\n# Optional: Install the TensorRT runtime (must be after CUDA install)\n\nsudo apt updatesudo apt install libnvinfer4=4.1.2-1+cuda9.0\n```\n\n\n\nWindows setup\n\nSee the [hardware requirements](https://www.tensorflow.org/install/gpu#hardware_requirements) and [software requirements](https://www.tensorflow.org/install/gpu#software_requirements) listed above. Read the [CUDA® install guide for Windows](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/).\n\nMake sure the installed NVIDIA software packages match the versions listed above. In particular, TensorFlow will not load without the `cuDNN64_7.dll` file. To use a different version, see the [Windows build from source](https://www.tensorflow.org/install/source_windows) guide.\n\nAdd the CUDA, CUPTI, and cuDNN installation directories to the `%PATH%` environmental variable. For example, if the CUDA Toolkit is installed to `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0` and cuDNN to `C:\\tools\\cuda`, update your `%PATH%` to match:\n\n```\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;%PATH% SET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64;%PATH% SET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include;%PATH% SET PATH=C:\\tools\\cuda\\bin;%PATH%\n```","tags":["CUDA"],"categories":["Linux","NVIDIA"]},{"title":"golang Runtime","url":"/2019/12/13/golangRuntime/","content":"\n@[TOC]\n\n# Golang Runtime\n\n## 什么是Golang Runtime\n\n> Golang Runtime 是go语言运行时所需要的基础设施\n>\n> 1. 协程调度、内存分配、GC\n> 2. 操作系统和CPU相关操作的封装（信号处理、系统调用、寄存器操作、原子操作等）、CGO\n> 3. pprof、trace、race检测的支持\n> 4. map、channel、string等内置类型及反射的实现\n\n### 与其他语言的不同\n\n1. Go是没有虚拟机的概念的，所以runtime也被直接编译成native code\n\n2. go 语言`Runtime` 代码和`用户代码` 是直接打包在一个可执行文件中\n\n3. `Runtime` 代码和`用户代码`在执行的时候并没有明显的界限，就是函数调用关系\n\n4. go对系统调用的函数进行了封装，可不依赖于glibc\n\n5. 一些go的关键字被编译器编译成了runtime包下的函数\n\n   | 关键字       | 函数                 |\n   | ------------ | -------------------- |\n   | go           | newproc              |\n   | new          | newobject            |\n   | <-        -> | chansend1，chanrecv1 |\n\n### 协程结构体和切换函数\n\n```go\ntype g struct {\n\tgoid   int64  // 协程id\n\tstatus uint32 // 协程状态\n\tstack  struct {\n\t\tlo uintptr // 该协程拥有的栈低位\n\t\thi uintptr // 该协程拥有的栈高位\n\t}\n\tsched     gobuf   // 切换时保存的上下文信息\n\tstartfunc uintptr // 程序地址\n}\ntype gobuf struct {\n\tsp uintptr // 栈指针位置\n\tpc uintptr // 运行到的程序位置\n}\n```\n\n","tags":["go"],"categories":["编程语言","GO"]},{"title":"ini配置库评析","url":"/2019/12/13/ini配置库评析/"},{"title":"cuda多版本切换可能会出现的问题","url":"/2019/12/11/cuda多版本切换可能会出现的问题/","content":"\n@[TOC]\n\n## Q&A\n\n### 1. 找不到libcuda.so.1\n\n> error while loading shared libraries: libcuda.so.1: cannot open shared object file: No such file or director\n\nsolution：\n\n```bash\nfind / -name libcuda.so.1 #寻找该动态库的位置\n\n# Ubuntu 下一般会在/usr/lib/x86_64-linux-gnu/libcuda.so.1\n\n# 添加路径\nsudo echo '/usr/lib/x86_64-linux-gnu/libcuda.so.1' >> /etc/ld.so.conf.d/cuda.conf\nsudo ldconfig\n```\n\n### 2. 不同版本之间的切换\n\n> ​\tfatal error: cuda.h: No such file or directory\n>\n> **<font color=red>可能是要切换版本的环境变量没有添加，所以首先添加环境变量</font>**\n\nsolution：\n\n```bash\n#添加环境变量 \nexport PATH=/usr/local/cuda-8.0/bin:/usr/local/cuda-10.0/bin:/usr/local/cuda/bin:$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64/:/usr/local/cuda-8.0/lib64/:/usr/local/cuda-10.0/lib64/:$LD_LIBRARY_PATH\n\n#在切换cuda版本时\nrm -rf /usr/local/cuda#删除之前创建的软链接\nsudo ln -s /usr/local/cuda-8.0/ /usr/local/cuda/\nnvcc --version #查看当前 cuda 版本\n\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2016 NVIDIA Corporation\nBuilt on Mon_Jan_23_12:24:11_CST_2017\nCuda compilation tools, release 8.0, V8.0.62\n\n#cuda8.0 切换到 cuda9.0 \nrm -rf /usr/local/cuda\nsudo ln -s /usr/local/cuda-9.0/ /usr/local/cuda/\nnvcc --version\n```\n\n\n\n","tags":["CUDA"],"categories":["Linux","NVIDIA"]},{"title":"程序员的自我修养--注重时效的哲学","url":"/2019/12/10/程序员的自我修养01/","content":"\n@[TOC]\n\n","tags":["编程"],"categories":["阅读","编程"]},{"title":"git commit 规范","url":"/2019/12/10/git_commit规范/","content":"\n@[TOC]\n\n# Git commit message 规范\n\n\n\n![img](../img/16b.jepg)\n\n\n\n> git是现在市面上最流行的版本控制工具，书写良好的commit message能大大提高代码维护的效率。但是在日常开发中由于缺少对于commit message的约束，导致填写内容随意、质量参差不齐，可读性低亦难以维护。在项目中引入commit message规范已是迫在眉睫。\n\n## 用什么规范？\n\n现在市面上比较流行的方案是`约定式提交规范`（`Conventional Commits`），它受到了`Angular提交准则`的启发，并在很大程度上以其为依据。`约定式提交规范`是一种基于提交消息的轻量级约定。 它提供了一组用于创建清晰的提交历史的简单规则；这使得编写基于规范的自动化工具变得更容易。这个约定与`SemVer`相吻合，在提交信息中描述新特性、bug 修复和破坏性变更。它的 message 格式如下:\n\n```\n<类型>[可选的作用域]: <描述>\n\n[可选的正文]\n\n[可选的脚注]\n复制代码\n```\n\n## Quick Start\n\n### 1. 全局安装commitizen & cz-conventional-changelog\n\n`commitizen`是一个撰写合格`commit message`的工具，用于代替`git commit` 指令，而`cz-conventional-changelog`适配器提供[conventional-changelog](https://github.com/conventional-changelog/conventional-changelog)标准（约定式提交标准）。基于不同需求，也可以使用不同适配器。\n\n```\nnpm install -g commitizen cz-conventional-changelog\necho '{ \"path\": \"cz-conventional-changelog\" }' > ~/.czrc\n复制代码\n```\n\n安装完毕后，可直接使用`git cz`来取代`git commit`。\n\n全局模式下，需要 `~/.czrc` 配置文件, 为`commitizen`指定`Adapter`。\n\n### 2. 项目内安装commitlint & husky\n\n`commitlint`负责用于对`commit message`进行格式校验，`husky`负责提供更易用的`git hook`。\n\n```\nUse npm\nnpm i -D husky @commitlint/config-conventional @commitlint/cli\n复制代码\nUse yarn\nyarn add husky @commitlint/config-conventional @commitlint/cli -D\n复制代码\n```\n\n`commitlint`只能做格式规范，无法触及内容。对于内容质量的把控只能靠我们自己。\n\n### 3. 添加相应配置\n\n创建`commitlint.config.js`\n\n```\n# In the same path as package.json\n\necho 'module.exports = {extends: [\"@commitlint/config-conventional\"]};' > ./commitlint.config.js\n复制代码\n```\n\n引入`husky`\n\n```\n# package.json\n\n...,\n\"husky\": {\n    \"hooks\": {\n      \"commit-msg\": \"commitlint -e $GIT_PARAMS\"\n    }\n}\n复制代码\n```\n\n### 4. 使用\n\n执行`git cz`进入interactive模式，根据提示依次填写\n\n```\n1.Select the type of change that you're committing 选择改动类型 (<type>)\n\n2.What is the scope of this change (e.g. component or file name)? 填写改动范围 (<scope>)\n\n3.Write a short, imperative tense description of the change: 写一个精简的描述 (<subject>)\n\n4.Provide a longer description of the change: (press enter to skip) 对于改动写一段长描述 (<body>)\n\n5.Are there any breaking changes? (y/n) 是破坏性修改吗？默认n (<footer>)\n\n6.Does this change affect any openreve issues? (y/n) 改动修复了哪个问题？默认n (<footer>)\n复制代码\n```\n\n生成的commit message格式如下：\n\n```\n<type>(<scope>): <subject>\n<BLANK LINE>\n<body>\n<BLANK LINE>\n<footer>\n复制代码\n```\n\n填写完毕后，`husky`会调用`commitlint`对message进行格式校验，默认规定`type`及`subject`为必填项。\n\n任何`git commit`指令的`option`都能用在 `git cz`指令上, 例如`git cz -a`\n\n## Commit message规范在rrd-fe落地使用情况\n\n针对团队目前使用的情况，我们讨论后拟定了`commit message`每一部分的填写规则。\n\n### 1. type\n\n`type`为必填项，用于指定commit的类型，约定了`feat`、`fix`两个`主要type`，以及docs、style、build、refactor、revert五个`特殊type`，`其余type`暂不使用。\n\n```\n# 主要type\nfeat:     增加新功能\nfix:      修复bug\n\n# 特殊type\ndocs:     只改动了文档相关的内容\nstyle:    不影响代码含义的改动，例如去掉空格、改变缩进、增删分号\nbuild:    构造工具的或者外部依赖的改动，例如webpack，npm\nrefactor: 代码重构时使用\nrevert:   执行git revert打印的message\n\n# 暂不使用type\ntest:     添加测试或者修改现有测试\nperf:     提高性能的改动\nci:       与CI（持续集成服务）有关的改动\nchore:    不修改src或者test的其余修改，例如构建过程或辅助工具的变动\n复制代码\n```\n\n当一次改动包括`主要type`与`特殊type`时，统一采用`主要type`。\n\n### 2. scope\n\n`scope`也为必填项，用于描述改动的范围，格式为项目名/模块名，例如： `node-pc/common` `rrd-h5/activity`，而`we-sdk`不需指定模块名。如果一次commit修改多个模块，建议拆分成多次commit，以便更好追踪和维护。\n\n### 3. body\n\n`body`填写详细描述，主要描述`改动之前的情况`及`修改动机`，对于小的修改不作要求，但是重大需求、更新等必须添加body来作说明。\n\n### 4. break changes\n\n`break changes`指明是否产生了破坏性修改，涉及break changes的改动必须指明该项，类似版本升级、接口参数减少、接口删除、迁移等。\n\n### 5. affect issues\n\n`affect issues`指明是否影响了某个问题。例如我们使用jira时，我们在`commit message`中可以填写其影响的`JIRA_ID`，若要开启该功能需要先打通`jira`与`gitlab`。参考文档：[docs.gitlab.com/ee/user/pro…](https://docs.gitlab.com/ee/user/project/integrations/jira.html)\n\n填写方式例如：\n\n```\nre #JIRA_ID\nfix #JIRA_ID\n复制代码\n```\n\n## 示例\n\n- 完整的commit message示例\n\n  ![img](../img/16b7.jepg)\n\n- 相应的git log\n\n  ![img](../img/16b73.jepg)\n\n## 扩展阅读\n\n[conventional commits](https://www.conventionalcommits.org/zh/v1.0.0-beta.3/) `必读` 介绍约定式提交标准。\n\n[Angular规范](https://github.com/angular/angular/blob/22b96b9/CONTRIBUTING.md#-commit-message-guidelines) `必读` 介绍Angular标准每个部分该写什么、该怎么写。\n\n[@commitlint/config-conventional](https://github.com/conventional-changelog/commitlint/tree/master/%40commitlint/config-conventional#type-enum) `必读` 介绍commitlint的校验规则config-conventional，以及一些常见passes/fails情况。","tags":["git"],"categories":["工具","git"]},{"title":"毒丸计划：防止恶意收购","url":"/2019/12/10/毒丸计划/","content":"\n@[TOC]\n\n","tags":["金融"],"categories":["阅读","金融"]},{"title":"杠杆收购：华尔街黄金游戏","url":"/2019/12/10/杠杆收购/","content":"\n@[TOC]\n\n","tags":["金融"],"categories":["阅读","金融"]},{"title":"Ubuntu 16.04 安装 CUDA","url":"/2019/12/09/Ubuntu_16.04安装cuda不同版本/","content":"\n@[TOC]\n\n## **一、操作系统:**\n\n研发工程师默认都是台式机，安装ubuntu16.04操作系统，默认我们安装好cuda和显卡驱动相关软件。如果需要重装系统请联系各属地IT，目前采用USB自动安装的方式，10分钟内可以安装完成\n\n## **二、卸载原有的驱动和cuda:**\n\nsudo su root\n\nservice lightdm stop\n\nnvidia-uninstall\n\napt-get install autoremove --purge nvidia*\n\n/usr/local/cuda-8.0/bin/uninstall_cuda-8.0.pl(根据版本号有差别，此处以8.0为例子)\n\nrm -rf /usr/local/cuda-8.0(!!!执行这一步时切勿误操作，否则容易导致系统崩溃)\n\n## **三、cuda安装：包含显卡驱动和相关软件包**\n\n### 1.下载cuda软件\n\n**（8.0版本）** wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda_8.0.61_375.26_linux-run\n\n**（9.0版本）** wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run\n\n**（10.0版本）**wget https://developer.nvidia.com/compute/cuda/10.0/Prod/local_installers/cuda_10.0.130_410.48_linux\n\n**（10.1版本）** \n\n​\t\twget http://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.243_418.87.00_linux.run\n\n**（10.2版本）**\n\n​\t\t wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run\n\n### 2.下载NVIDIA显卡驱动\n\nwget http://cn.download.nvidia.com/XFree86/Linux-x86_64/440.36/NVIDIA-Linux-x86_64-440.36.run\n\n### 3.添加安装程序的可执行权限：\n\nchmod +x *.run\n\n### 4.禁用默认的nouveau开源显卡驱动：\n\necho \"blacklist nouveau\" >> /etc/modprobe.d/blacklist-nouveau.conf\n\n之后建议重启下系统\n\n### 5.关闭系统图形界面，显卡驱动安装过程需要在命令行模式下进行（Ctrl + Alt + F2 进入命令行模式）\n\n```\nsudo su root\n\nservice lightdm stop\n```\n\n### 6.安装显卡驱动程序，命令：\n\n```\n./NVIDIA-Linux-x86_64-410.78.run -a -s -Z --no-opengl-files\n```\n\n### 7.安装CUDA-9.0 驱动（请把cuda安装程序和安装目标目录替换为自己需要安装的对应版本）\n\n```\n./cuda_9.0.176_384.81_linux.run --no-opengl-libs --toolkit --samples --samplespath=/usr/local/cuda-9.0 -silent\n```\n\n### 8.添加安装的环境变量（将红色部分替换为自己安装的对应版本）:\n\n```\necho 'export LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64/:/usr/local/cuda-9.0/lib:/usr/local/cuda-9.0/lib64/:$LD_LIBRARY_PATH' >> /etc/profile\necho 'export PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/cuda-9.0/bin:/usr/local/cuda/bin:$PATH' >> /etc/profile\necho '/usr/local/cuda/lib64' >> /etc/ld.so.conf.d/cuda.conf\n\nldconfig\n```\n\n### 9.下载cudnn\n\n- **Download cuDNN v7.6.5 (November 18th, 2019), for CUDA 10.2**\n\n  ```bash\n   wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/7.6.5.32/Production/10.2_20191118/cudnn-10.2-linux-x64-v7.6.5.32.tgz\n  ```\n\n- **Download cuDNN v7.6.5 (November 5th, 2019), for CUDA 10.1**\n\n  ```\n  wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/7.6.5.32/Production/10.1_20191031/cudnn-10.1-linux-x64-v7.6.5.32.tgz\n  ```\n\n- **Download cuDNN v7.6.4 (September 27, 2019), for CUDA 10.0**\n\n  ```\n  wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/7.6.4.38/Production/10.0_20190923/cudnn-10.0-linux-x64-v7.6.4.38.tgz\n  ```\n\n- **Download cuDNN v7.6.3 (August 23, 2019), for CUDA 9.0**\n\n  ```\n  wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/7.6.3.30/Production/9.0_20190822/cudnn-9.0-linux-x64-v7.6.3.30.tgz\n  ```\n\n- **Download cuDNN v7.1.3 (April 17, 2018), for CUDA 8.0**\n\n  ```\n  wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.1.3/prod/8.0_20180414/cudnn-8.0-linux-x64-v7.1\n  ```\n\n### 10.安装cudnn\n\n```\ntar xf cudnn-9.0-linux-x64-v7.tar\nmv cuda/lib64/libcudnn* /usr/local/cuda-9.0/lib64/\nmv cuda/include/cudnn.h /usr/local/cuda-9.0/include/\n```","tags":["ubuntu","CUDA"],"categories":["Linux","NVIDIA"]},{"title":"go mod 基础篇","url":"/2019/12/09/go_mod基础篇/","content":"\n@[TOC]\n\n## 准备\n\n### 开启go mod\n\n1. 把 golang 升级到 1.11（现在1.13 已经发布了，建议使用1.13）\n2. 设置 `GO111MODULE`\n\nGO111MODULE\n\n`GO111MODULE` 有三个值：`off`, `on`和`auto（默认值）`。\n\n- `GO111MODULE=off`，go命令行将不会支持module功能，寻找依赖包的方式将会沿用旧版本那种通过vendor目录或者GOPATH模式来查找。\n- `GO111MODULE=on`，go命令行会使用modules，而一点也不会去GOPATH目录下查找。\n- `GO111MODULE=auto`，默认值，go命令行将会根据当前目录来决定是否启用module功能。这种情况下可以分为两种情形：\n  - 当前目录在GOPATH/src之外且该目录包含go.mod文件\n  - 当前文件在包含go.mod文件的目录下面。\n\n> 当modules 功能启用时，依赖包的存放位置变更为`$GOPATH/pkg`，允许同一个package多个版本并存，且多个项目可以共享缓存的 module。\n\n```bash\nexport GO111MODULE=on\n```\n\n### go mod常用命令\n\ngolang 提供了 `go mod`命令来管理包。\n\ngo mod 有以下命令：\n\n| 命令     | 说明                                                         |\n| -------- | ------------------------------------------------------------ |\n| download | download modules to local cache(下载依赖包)                  |\n| edit     | edit go.mod from tools or scripts（编辑go.mod                |\n| graph    | print module requirement graph (打印模块依赖图)              |\n| init     | initialize new module in current directory（在当前目录初始化mod） |\n| tidy     | add missing and remove unused modules(拉取缺少的模块，移除不用的模块) |\n| vendor   | make vendored copy of dependencies(将依赖复制到vendor下)     |\n| verify   | verify dependencies have expected content (验证依赖是否正确） |\n| why      | explain why packages or modules are needed(解释为什么需要依赖) |\n\n## 在项目中使用\n\n### 示例一：创建一个新项目\n\n1. 在`GOPATH 目录之外`新建一个目录，并使用`go mod init` 初始化生成`go.mod` 文件\n\n```\n➜  ~ mkdir hello\n➜  ~ cd hello\n➜  hello go mod init hello\ngo: creating new go.mod: module hello\n➜  hello ls\ngo.mod\n➜  hello cat go.mod\nmodule hello\n\ngo 1.12\n```\n\n> go.mod文件一旦创建后，它的内容将会被go toolchain全面掌控。go toolchain会在各类命令执行时，比如go get、go build、go mod等修改和维护go.mod文件。\n\ngo.mod 提供了`module`, `require`、`replace`和`exclude` 四个命令\n\n- `module` 语句指定包的名字（路径）\n- `require` 语句指定的依赖项模块\n- `replace` 语句可以替换依赖项模块\n- `exclude` 语句可以忽略依赖项模块\n\n1. 添加依赖\n\n新建一个 server.go 文件，写入以下代码：\n\n```\npackage main\n\nimport (\n    \"net/http\"\n    \n    \"github.com/labstack/echo\"\n)\n\nfunc main() {\n    e := echo.New()\n    e.GET(\"/\", func(c echo.Context) error {\n        return c.String(http.StatusOK, \"Hello, World!\")\n    })\n    e.Logger.Fatal(e.Start(\":1323\"))\n}\n```\n\n执行 `go run server.go` 运行代码会发现 go mod 会自动查找依赖自动下载：\n\n```\n$ go run server.go\ngo: finding github.com/labstack/echo v3.3.10+incompatible\ngo: downloading github.com/labstack/echo v3.3.10+incompatible\ngo: extracting github.com/labstack/echo v3.3.10+incompatible\ngo: finding github.com/labstack/gommon/color latest\ngo: finding github.com/labstack/gommon/log latest\ngo: finding github.com/labstack/gommon v0.2.8\n# 此处省略很多行\n...\n\n   ____    __\n  / __/___/ /  ___\n / _// __/ _ \\/ _ \\\n/___/\\__/_//_/\\___/ v3.3.10-dev\nHigh performance, minimalist Go web framework\nhttps://echo.labstack.com\n____________________________________O/_______\n                                    O\\\n⇨ http server started on [::]:1323\n```\n\n现在查看go.mod 内容：\n\n```\n$ cat go.mod\n\nmodule hello\n\ngo 1.12\n\nrequire (\n    github.com/labstack/echo v3.3.10+incompatible // indirect\n    github.com/labstack/gommon v0.2.8 // indirect\n    github.com/mattn/go-colorable v0.1.1 // indirect\n    github.com/mattn/go-isatty v0.0.7 // indirect\n    github.com/valyala/fasttemplate v1.0.0 // indirect\n    golang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a // indirect\n)\n```\n\ngo module 安装 package 的原則是先拉最新的 release tag，若无tag则拉最新的commit，详见 [Modules官方介绍](https://github.com/golang/go/wiki/Modules)。 go 会自动生成一个 go.sum 文件来记录 dependency tree：\n\n```\n$ cat go.sum\ngithub.com/labstack/echo v3.3.10+incompatible h1:pGRcYk231ExFAyoAjAfD85kQzRJCRI8bbnE7CX5OEgg=\ngithub.com/labstack/echo v3.3.10+incompatible/go.mod h1:0INS7j/VjnFxD4E2wkz67b8cVwCLbBmJyDaka6Cmk1s=\ngithub.com/labstack/gommon v0.2.8 h1:JvRqmeZcfrHC5u6uVleB4NxxNbzx6gpbJiQknDbKQu0=\ngithub.com/labstack/gommon v0.2.8/go.mod h1:/tj9csK2iPSBvn+3NLM9e52usepMtrd5ilFYA+wQNJ4=\ngithub.com/mattn/go-colorable v0.1.1 h1:G1f5SKeVxmagw/IyvzvtZE4Gybcc4Tr1tf7I8z0XgOg=\ngithub.com/mattn/go-colorable v0.1.1/go.mod h1:FuOcm+DKB9mbwrcAfNl7/TZVBZ6rcnceauSikq3lYCQ=\n... 省略很多行\n```\n\n1. 再次执行脚本 `go run server.go` 发现跳过了检查并安装依赖的步骤。\n2. 可以使用命令 `go list -m -u all` 来检查可以升级的package，使用`go get -u need-upgrade-package` 升级后会将新的依赖版本更新到go.mod\n   - 也可以使用 `go get -u` 升级所有依赖\n\n#### go get 升级\n\n- 运行 go get -u 将会升级到最新的次要版本或者修订版本(x.y.z, z是修订版本号， y是次要版本号)\n- 运行 go get -u=patch 将会升级到最新的修订版本\n- 运行 go get package@version 将会升级到指定的版本号version\n- 运行go get如果有版本的更改，那么go.mod文件也会更改\n\n### 示例二：改造现有项目(helloword)\n\n项目目录为：\n\n```\n$ tree\n.\n├── api\n│   └── apis.go\n└── server.go\n\n1 directory, 2 files\n```\n\nserver.go 源码为：\n\n```\npackage main\n\nimport (\n    api \"./api\"  // 这里使用的是相对路径\n    \"github.com/labstack/echo\"\n)\n\nfunc main() {\n    e := echo.New()\n    e.GET(\"/\", api.HelloWorld)\n    e.Logger.Fatal(e.Start(\":1323\"))\n}\n```\n\napi/apis.go 源码为：\n\n```\npackage api\n\nimport (\n    \"net/http\"\n\n    \"github.com/labstack/echo\"\n)\n\nfunc HelloWorld(c echo.Context) error {\n    return c.JSON(http.StatusOK, \"hello world\")\n}\n```\n\n1. 使用 `go mod init ***` 初始化go.mod\n\n```\n$ go mod init helloworld\ngo: creating new go.mod: module helloworld\n```\n\n1. 运行 `go run server.go`\n\n```\ngo: finding github.com/labstack/gommon/color latest\ngo: finding github.com/labstack/gommon/log latest\ngo: finding golang.org/x/crypto/acme/autocert latest\ngo: finding golang.org/x/crypto/acme latest\ngo: finding golang.org/x/crypto latest\nbuild command-line-arguments: cannot find module for path _/home/gs/helloworld/api\n```\n\n首先还是会查找并下载安装依赖，然后运行脚本 `server.go`，这里会抛出一个错误：\n\n```\nbuild command-line-arguments: cannot find module for path _/home/gs/helloworld/api\n```\n\n但是`go.mod` 已经更新：\n\n```\n$ cat go.mod\nmodule helloworld\n\ngo 1.12\n\nrequire (\n        github.com/labstack/echo v3.3.10+incompatible // indirect\n        github.com/labstack/gommon v0.2.8 // indirect\n        github.com/mattn/go-colorable v0.1.1 // indirect\n        github.com/mattn/go-isatty v0.0.7 // indirect\n        github.com/valyala/fasttemplate v1.0.0 // indirect\n        golang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a // indirect\n)\n```\n\n#### 那为什么会抛出这个错误呢？\n\n这是因为 server.go 中使用 internal package 的方法跟以前已经不同了，由于 go.mod会扫描同工作目录下所有 package 并且`变更引入方法`，必须将 helloworld当成路径的前缀，也就是需要写成 import helloworld/api，以往 GOPATH/dep 模式允许的 import ./api 已经失效，详情可以查看这个 [issue](https://github.com/golang/go/issues/26645)。\n\n1. 更新旧的package import 方式\n\n所以server.go 需要改写成：\n\n```\npackage main\n\nimport (\n    api \"helloworld/api\"  // 这是更新后的引入方法\n    \"github.com/labstack/echo\"\n)\n\nfunc main() {\n    e := echo.New()\n    e.GET(\"/\", api.HelloWorld)\n    e.Logger.Fatal(e.Start(\":1323\"))\n}\n```\n\n> `一个小坑`：开始在golang1.11 下使用go mod 遇到过 `go build github.com/valyala/fasttemplate: module requires go 1.12` [这种错误](https://github.com/golang/go/issues/27565)，遇到类似这种需要升级到1.12 的问题，直接升级golang1.12 就好了。幸亏是在1.12 发布后才尝试的`go mod` 🤷‍♂️\n\n1. 到这里就和新创建一个项目没什么区别了\n\n#### 使用replace替换无法直接获取的package\n\n由于某些已知的原因，并不是所有的package都能成功下载，比如：`golang.org`下的包。\n\nmodules 可以通过在 go.mod 文件中使用 replace 指令替换成github上对应的库，比如：\n\n```\nreplace (\n    golang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a => github.com/golang/crypto v0.0.0-20190313024323-a1f597ede03a\n)\n```\n\n或者\n\n```\nreplace golang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a => github.com/golang/crypto v0.0.0-20190313024323-a1f597ede03a\n```\n\n## 参考链接\n\n- [Modules官方介绍](https://github.com/golang/go/wiki/Modules)\n- [Golang 1.11 新功能介紹 – Modules](https://www.lightblue.asia/golang-1-11-new-festures-modules/?doing_wp_cron=1552464864.6369309425354003906250)\n- [What are Go modules and how do I use them?](https://talks.godoc.org/github.com/myitcv/talks/2018-08-15-glug-modules/main.slide#1)\n- [go mod doesn't work for github.com/gomarkdown/markdown/html](https://github.com/golang/go/issues/27565)\n- [再探go modules：使用与细节](https://www.cnblogs.com/apocelipes/p/10295096.html)\n- [初窥Go module](https://tonybai.com/2018/07/15/hello-go-module/)\n\n#### References\n\n[1] Modules官方介绍: [https://github.com/golang/go/...](https://github.com/golang/go/wiki/Modules)\n[2] issue: [https://github.com/golang/go/...](https://github.com/golang/go/issues/26645)\n[3] 这种错误: [https://github.com/golang/go/...](https://github.com/golang/go/issues/27565)\n[4] Modules官方介绍: [https://github.com/golang/go/...](https://github.com/golang/go/wiki/Modules)\n[5] Golang 1.11 新功能介紹 – Modules: [https://www.lightblue.asia/go...](https://www.lightblue.asia/golang-1-11-new-festures-modules/?doing_wp_cron=1552464864.6369309425354003906250)\n[6] What are Go modules and how do I use them?: [https://talks.godoc.org/githu...](https://talks.godoc.org/github.com/myitcv/talks/2018-08-15-glug-modules/main.slide#1)\n[7] go mod doesn't work for github.com/gomarkdown/markdown/html : [https://github.com/golang/go/...](https://github.com/golang/go/issues/27565)\n[8] 再探go modules：使用与细节: [https://www.cnblogs.com/apoce...](https://www.cnblogs.com/apocelipes/p/10295096.html)\n[9] 初窥Go module: [https://tonybai.com/2018/07/1...](https://tonybai.com/2018/07/15/hello-go-module/)","tags":["go","go mod"],"categories":["编程语言","GO"]},{"title":"git 新建仓库，添加远程分之到本地","url":"/2019/12/09/git新建仓库/","content":"\n@[TOC]\n\n### 本地不存在仓库拉取远程分之\n\n\n\n```bash\n$ echo \"# gin-web\" >> README.md\n$ git init\n$ git add README.md\n$ git commit -m \"first commit\"\n$ git remote add origin https://github.com/AlexBruceLu/gin-web.git\n$ git push -u origin master\n```\n\n### 本地已有的仓库添加到远程\n\n\n\n```bash\n$ git remote add origin https://github.com/AlexBruceLu/gin-web.git\n$ git push -u origin master\n```\n\n### git本地分支和远程分支改名\n\n```bash\n#1 将本地分支进行改名\n$ git branch -m old_branch new_branch\n \n#2 将远程分支的老分支删除\n$ git push origin :old_branch\n \n#3 将改名后的分支push到远程\n$ git push origin new_branch\n```\n\n","tags":["git"],"categories":["工具","git"]},{"title":"Ubuntu 16.04 升级最新版本 nvidia-docker","url":"/2019/12/09/Ubuntu16.04升级最新版本nvidia-docker/","content":"\n@[TOC]\n\n### Uninstall old versions\n\nOlder versions of Docker were called `docker`, `docker.io `, or `docker-engine`. If these are installed, uninstall them:\n\n```\n$ sudo apt-get remove docker docker-engine docker.io containerd runc\n```\n\nIt’s OK if `apt-get` reports that none of these packages are installed.\n\nThe contents of `/var/lib/docker/`, including images, containers, volumes, and networks, are preserved. The Docker Engine - Community package is now called `docker-ce`.\n\n### Supported storage drivers\n\nDocker Engine - Community on Ubuntu supports `overlay2`, `aufs` and `btrfs` storage drivers.\n\n> **Note**: In Docker Engine - Enterprise, `btrfs` is only supported on SLES. See the documentation on [btrfs](https://docs.docker.com/engine/userguide/storagedriver/btrfs-driver/) for more details.\n\nFor new installations on version 4 and higher of the Linux kernel, `overlay2` is supported and preferred over `aufs`. Docker Engine - Community uses the `overlay2` storage driver by default. If you need to use `aufs` instead, you need to configure it manually. See [aufs](https://docs.docker.com/engine/userguide/storagedriver/aufs-driver/)\n\n### Install Docker Engine - Community\n\nYou can install Docker Engine - Community in different ways, depending on your needs:\n\n- Most users [set up Docker’s repositories](https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-using-the-repository) and install from them, for ease of installation and upgrade tasks. This is the recommended approach.\n- Some users download the DEB package and [install it manually](https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-from-a-package) and manage upgrades completely manually. This is useful in situations such as installing Docker on air-gapped systems with no access to the internet.\n- In testing and development environments, some users choose to use automated [convenience scripts](https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-using-the-convenience-script) to install Docker.\n\n### Install using the repository\n\nBefore you install Docker Engine - Community for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.\n\n#### SET UP THE REPOSITORY\n\n1. Update the `apt` package index:\n\n   ```\n   $ sudo apt-get update\n   ```\n\n2. Install packages to allow `apt` to use a repository over HTTPS:\n\n   ```\n   $ sudo apt-get install \\\n       apt-transport-https \\\n       ca-certificates \\\n       curl \\\n       gnupg-agent \\\n       software-properties-common\n   ```\n\n3. Add Docker’s official GPG key:\n\n   ```\n   $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n   ```\n\n   Verify that you now have the key with the fingerprint `9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88`, by searching for the last 8 characters of the fingerprint.\n\n   ```\n   $ sudo apt-key fingerprint 0EBFCD88\n\n   pub   rsa4096 2017-02-22 [SCEA]\n         9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88\n   uid           [ unknown] Docker Release (CE deb) <docker@docker.com>\n   sub   rsa4096 2017-02-22 [S]\n   ```\n\n4. Use the following command to set up the **stable** repository. To add the **nightly** or **test** repository, add the word `nightly` or `test` (or both) after the word `stable` in the commands below. [Learn about **nightly** and **test** channels](https://docs.docker.com/install/).\n\n   > **Note**: The `lsb_release -cs` sub-command below returns the name of your Ubuntu distribution, such as `xenial`. Sometimes, in a distribution like Linux Mint, you might need to change `$(lsb_release -cs)` to your parent Ubuntu distribution. For example, if you are using `Linux Mint Tessa`, you could use `bionic`. Docker does not offer any guarantees on untested and unsupported Ubuntu distributions.\n\n\n\n   - - x86_64 / amd64\n     - armhf\n     - arm64\n     - ppc64le (IBM Power)\n     - s390x (IBM Z)\n\n\n\n   ```\n   $ sudo add-apt-repository \\\n      \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n      $(lsb_release -cs) \\\n      stable\"\n   ```\n\n\n\n#### INSTALL DOCKER ENGINE - COMMUNITY\n\n1. Update the `apt` package index.\n\n   ```\n   $ sudo apt-get update\n   ```\n\n2. Install the *latest version* of Docker Engine - Community and containerd, or go to the next step to install a specific version:\n\n   ```\n   $ sudo apt-get install docker-ce docker-ce-cli containerd.io\n   ```\n\n   > **** Got multiple Docker repositories?\n   >\n   > If you have multiple Docker repositories enabled, installing or updating without specifying a version in the `apt-get install` or `apt-get update` command always installs the highest possible version, which may not be appropriate for your stability needs.\n\n3. To install a *specific version* of Docker Engine - Community, list the available versions in the repo, then select and install:\n\n   a. List the versions available in your repo:\n\n   ```\n   $ apt-cache madison docker-ce\n\n     docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu  xenial/stable amd64 Packages\n     docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu  xenial/stable amd64 Packages\n     docker-ce | 18.06.1~ce~3-0~ubuntu       | https://download.docker.com/linux/ubuntu  xenial/stable amd64 Packages\n     docker-ce | 18.06.0~ce~3-0~ubuntu       | https://download.docker.com/linux/ubuntu  xenial/stable amd64 Packages\n     ...\n   ```\n\n   b. Install a specific version using the version string from the second column, for example, `5:18.09.1~3-0~ubuntu-xenial`.\n\n   ```\n   $ sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io\n   ```\n\n4. Verify that Docker Engine - Community is installed correctly by running the `hello-world` image.\n\n   ```shell\n   $ sudo docker run hello-world\n   ```","tags":["ubuntu","nvidia-docker"],"categories":["Linux","docker"]}]