[{"title":"函数和方法的区别","url":"/2018/12/19/go中函数和方法的区别/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之函数和方法的区别\n\n<!-- more -->\n\n[TOC]\n\n在接触到`go`之前，我认为函数和方法只是同一个东西的两个名字而已（在我熟悉的`c/c++`，`python`，`java`中没有明显的区别），但是在`golang`中者完全是两个不同的东西。官方的解释是，方法是包含了接收者的函数。到底什么意思呢。\n\n## 函数\n\n首先函数的格式是固定的，func＋函数名＋ 参数 ＋ 返回值（可选） ＋ 函数体。例:\n\n```go\nfunc main() {\n    fmt.Println(\"hello golang\")\n}\n```\n\n在golang中有两个特殊的函数，`main`函数和`init`函数，`main`函数不用介绍在所有语言中都一样，它作为一个程序的入口，只能有一个。`init`函数在每个package是可选的，可有可无，甚至可以有多个(但是强烈建议一个package中一个init函数)，init函数在你导入该package时程序会自动调用init函数，所以init函数不用我们手动调用,l另外它只会被调用一次，因为当一个package被多次引用时，它只会被导入一次。\n\n```go\npackage my\n\nimport \"fmt\"\n\nvar I int\n\nfunc init() {\n    I = 0\n    fmt.Println(\"Call my init1\")\n}\n\nfunc init() {\n    I = 1\n    fmt.Println(\"Call my init2\")\n}\n```\n\n```go\npackage main\n\nimport (\n    \"my\"\n\t\"fmt\"\n)\n\nfunc main() {\n    fmt.Println(\"hello go .... I =\",my.I)\n}\n```\n\n**执行结果：**\n\n```bash\nCall my init1\nCall my init2\nhello go .... I = 1\n```\n\n## 方法\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype myint int\n\nfunc (m *myint) double() int {\n\t*m = *m * 2\n\treturn 0\n}\n\nfunc (m myint) square() int {\n\tm = m * m\n\tfmt.Printf(\"square is %d\\n\", m)\n\treturn 0\n}\n\nfunc main() {\n\tvar i myint = 2\n\ti.double()\n\tfmt.Println(\"i = \",i)\n\ti.square()\n\tfmt.Println(\"i = \",i)\n}\n```\n\n**执行结果：**\n\n```bash\ni = 4\nsquare is 16\ni = 4\n```\n\n我们可以看到方法和函数的区别，方法在`func`关键字后是接收者而不是函数名，接收者可以是自己定义的一个类型，这个类型可以是`struct`，`interface`，甚至我们可以重定义基本数据类型。我们可以给他一些我们想要的方法来满足我们的实际工程中的需求，就像上面一样我重定义了int并给了它一个乘2和平法的方法，这里我们要注意一个细节，接收者是指针和非指针的区别，我们可以看到当接收者为指针式，我们可以通过方法改变该接收者的属性，但是非指针类型缺做不到。\n\n这里的接收者和c++中的this指针有一些相似，我们可以把接受者当作一个class，而这些方法就是类的成员函数，当接收者为指针类型是就是c++中的非const成员函数，为非指针时就是const成员函数，不能通过此方法改变累的成员变量。","tags":["golang"],"categories":["golang"]},{"title":"go操作Redis","url":"/2018/12/18/go操作redis/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nRedis的简介及golang简易操作redis\n\n<!-- more -->\n\n[TOC]\n\n## redis简介\n\nredis（REmote DIctionary Server）是一个由Salvatore Sanfilippo 写的`Key-value`存储系统，由`C`语言编写、遵守`BSD协议`、支持网络、可基于内存亦可持久化的日志型、`Key-Value`类型的数据库，并提供多种语言的API。和Memcached类似，它支持存储的value类型相对更多，包括`string(字符串)`、`list(链表)`、`set(集合)`、`zset(sorted set --有序集合)`和`hash（哈希类型）`。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步，redis在3.0版本推出集群模式。\n\n官方网站：https://redis.io/\n\n## 源码部署\n\n```bash\n$ yum install gcc -y  #安装C依赖\n$ wget http://download.redis.io/redis-stable.tar.gz  #下载稳定版本\n$ tar zxvf redis-stable.tar.gz  #解压\n$ cd redis-stable\n$ make PREFIX=/opt/app/redis install   #指定目录编译\n$ make install\n$ mkdir /etc/redis   #建立配置目录\n$ cp redis.conf /etc/redis/6379.conf # 拷贝配置文件\n$ cp utils/redis_init_script /etc/init.d/redis  #拷贝init启动脚本针对6.X系统\n$ chmod a+x  /etc/init.d/redis  #添加执行权限\n\n# 修改配置文件：\n$ vi /etc/redis/6379.conf\nbind 0.0.0.0      #监听地址\nmaxmemory 4294967296   #限制最大内存（4G）：\ndaemonize yes   #后台运行\n```\n\n### 启动与停止\n\n```bash\n####启动与停止\n$ /etc/init.d/redis start\n$ /etc/init.d/redis stop\n```\n\n### 查看版本信息\n\n```bash\n#执行客户端工具\n$ redis-cli \n#输入命令info\n127.0.0.1:6379> info\n# Server\nredis_version:4.0.10\nredis_git_sha1:00000000\nredis_git_dirty:0\nredis_build_id:cf83e9c690dbed33\nredis_mode:standalone\nos:Linux 2.6.32-642.el6.x86_64 x86_64\narch_bits:64\nmultiplexing_api:epoll\n```\n\n## golang操作redis\n\n### 安装\n\ngolang操作redis的客户端包有多个比如`redigo`、`go-redis`，github上Star最多的莫属`redigo`。\n\ngithub地址：https://github.com/garyburd/redigo  \n\n目前已经迁移到：https://github.com/gomodule/redigo \n\n文档：https://godoc.org/github.com/garyburd/redigo/redis\n\n```bash\n$ go get github.com/garyburd/redigo/redis\n```\n\n```go\nimport \"github.com/garyburd/redigo/redis\"\n```\n\n### 连接\n\n`Conn`接口是与`Redis`协作的主要接口，可以使用`Dial`,`DialWithTimeout`或者`NewConn`函数来创建连接，当任务完成时，应用程序必须调用`Close`函数来完成操作。\n\n```go\npackage main\n\nimport (\n\t\"github.com/garyburd/redigo/redis\"\n\t\"fmt\"\n)\n\nfunc main()  {\n    conn,err := redis.Dial(\"tcp\",\"10.1.210.69:6379\")\n    if err != nil {\n        fmt.Println(\"connect redis error :\",err)\n        return\n    }\n    defer conn.Close()\n}\n```\n\n### 命令操作\n\n通过使用Conn接口中的do方法执行redis命令，redis命令大全参考：http://doc.redisfans.com/\n\ngo中发送与响应对应类型：\n\n`Do`函数会必要时将参数转化为二进制字符串\n\n| **Go Type**     |           **Conversion**            |\n| :-------------- | :---------------------------------: |\n| []byte          |             Sent as is              |\n| string          |             Sent as is              |\n| int, int64      |        strconv.FormatInt(v)         |\n| float64         | strconv.FormatFloat(v, 'g', -1, 64) |\n| bool            |      true -> \"1\", false -> \"0\"      |\n| nil             |                 \"\"                  |\n| all other types |            fmt.Print(v)             |\n\nRedis 命令响应会用以下Go类型表示：\n\n| Redis Type    | Go Type                                   |\n| ------------- | ----------------------------------------- |\n| error         | redis.Error                               |\n| interger      | int64                                     |\n| simple string | string                                    |\n| bulk string   | []byte or nil if value not present        |\n| arrary        | []interface{} or nil if value not present |\n\n可以使用GO的类型断言或者`reply`辅助函数将返回的`interface{}`转换为对应类型。\n\n#### 操作示例：**`get`、`set`**\n\n```go\npackage main\n\nimport (\n\t\"github.com/garyburd/redigo/redis\"\n\t\"fmt\"\n)\n\nfunc main()  {\n    conn,err := redis.Dial(\"tcp\",\"10.1.210.69:6379\")\n    if err != nil {\n        fmt.Println(\"connect redis error :\",err)\n        return\n    }\n    defer conn.Close()\n    _, err = conn.Do(\"SET\", \"name\", \"wd\")\n    if err != nil {\n        fmt.Println(\"redis set error:\", err)\n    }\n    name, err := redis.String(conn.Do(\"GET\", \"name\"))\n    if err != nil {\n        fmt.Println(\"redis get error:\", err)\n    } else {\n        fmt.Printf(\"Got name: %s \\n\", name)\n    }\n}\n```\n\n#### 设置key过期时间\n\n```go\n_, err = conn.Do(\"expire\", \"name\", 10) //10秒过期\n    if err != nil {\n        fmt.Println(\"set expire error: \", err)\n        return\n    }\n```\n\n#### 批量获取mget、批量设置mset\n\n```go\n_, err = conn.Do(\"MSET\", \"name\", \"wd\",\"age\",22)\n    if err != nil {\n        fmt.Println(\"redis mset error:\", err)\n    }\n    res, err := redis.Strings(conn.Do(\"MGET\", \"name\",\"age\"))\n    if err != nil {\n        fmt.Println(\"redis get error:\", err)\n    } else {\n        res_type := reflect.TypeOf(res)\n        fmt.Printf(\"res type : %s \\n\", res_type)\n        fmt.Printf(\"MGET name: %s \\n\", res)\n        fmt.Println(len(res))\n    }\n//结果：\n//res type : []string \n//MGET name: [wd 22] \n//2\n```\n\n#### 列表操作\n\n```go\npackage main\n\nimport (\n\t\"github.com/garyburd/redigo/redis\"\n\t\"fmt\"\n    \"reflect\"\n)\n\n\nfunc main()  {\n    conn,err := redis.Dial(\"tcp\",\"10.1.210.69:6379\")\n    if err != nil {\n        fmt.Println(\"connect redis error :\",err)\n        return\n    }\n    defer conn.Close()\n    _, err = conn.Do(\"LPUSH\", \"list1\", \"ele1\",\"ele2\",\"ele3\")\n    if err != nil {\n        fmt.Println(\"redis mset error:\", err)\n    }\n    res, err := redis.String(conn.Do(\"LPOP\", \"list1\"))\n    if err != nil {\n        fmt.Println(\"redis POP error:\", err)\n    } else {\n        res_type := reflect.TypeOf(res)\n        fmt.Printf(\"res type : %s \\n\", res_type)\n        fmt.Printf(\"res  : %s \\n\", res)\n    }\n}\n//res type : string \n//res  : ele3 \n```\n\n#### hash操作\n\n```go\npackage main\n\nimport (\n\t\"github.com/garyburd/redigo/redis\"\n\t\"fmt\"\n    \"reflect\"\n)\n\nfunc main()  {\n    conn,err := redis.Dial(\"tcp\",\"10.1.210.69:6379\")\n    if err != nil {\n        fmt.Println(\"connect redis error :\",err)\n        return\n    }\n    defer conn.Close()\n    _, err = conn.Do(\"HSET\", \"student\",\"name\", \"wd\",\"age\",22)\n    if err != nil {\n        fmt.Println(\"redis mset error:\", err)\n    }\n    res, err := redis.Int64(conn.Do(\"HGET\", \"student\",\"age\"))\n    if err != nil {\n        fmt.Println(\"redis HGET error:\", err)\n    } else {\n        res_type := reflect.TypeOf(res)\n        fmt.Printf(\"res type : %s \\n\", res_type)\n        fmt.Printf(\"res  : %d \\n\", res)\n    }\n}\n//res type : int64 \n//res  : 22 \n```\n\n#### Pipelining(管道)\n\n管道操作可以理解为并发操作，并通过`Send()`，`Flush()`，`Receive()`三个方法实现。客户端可以使用`send()`方法一次性向服务器发送一个或多个命令，命令发送完毕时，使用`flush()`方法将缓冲区的命令输入一次性发送到服务器，客户端再使用`Receive()`方法依次按照先进先出的顺序读取所有命令操作结果。\n\n```go\nSend(commandName string, args ...interface{}) error\nFlush() error\nReceive() (reply interface{}, err error)\n```\n\n- `Send`：发送命令至缓冲区\n- `Flush`:  清空缓冲区，将命令一次性发送至服务器\n- `Recevie`:  依次读取服务器响应结果，当读取的命令未响应时，该操作会阻塞\n\n```go\npackage main\n\nimport (\n\t\"github.com/garyburd/redigo/redis\"\n\t\"fmt\"\n)\n\nfunc main()  {\n    conn,err := redis.Dial(\"tcp\",\"10.1.210.69:6379\")\n    if err != nil {\n        fmt.Println(\"connect redis error :\",err)\n        return\n    }\n    defer conn.Close()\n    conn.Send(\"HSET\", \"student\",\"name\", \"wd\",\"age\",\"22\")\n    conn.Send(\"HSET\", \"student\",\"Score\",\"100\")\n    conn.Send(\"HGET\", \"student\",\"age\")\n    conn.Flush()\n\n    res1, err := conn.Receive()\n    fmt.Printf(\"Receive res1:%v \\n\", res1)\n    res2, err := conn.Receive()\n    fmt.Printf(\"Receive res2:%v\\n\",res2)\n    res3, err := conn.Receive()\n    fmt.Printf(\"Receive res3:%s\\n\",res3)\n}\n//Receive res1:0 \n//Receive res2:0\n//Receive res3:22\n```\n\n#### 发布/订阅\n\nredis本身具有发布订阅的功能，其发布订阅功能通过命令SUBSCRIBE(订阅)／PUBLISH(发布)实现，并且发布订阅模式可以是多对多模式还可支持正则表达式，发布者可以向一个或多个频道发送消息，订阅者可订阅一个或者多个频道接受消息。\n\n> - 示意图：\n>\n>   - 发布者：\n>\n>     ![](https://github.com/AlexBruceLu/DAPP/wiki/rd1.png)\n>\n>   - 订阅者：\n>\n>     ![](https://github.com/AlexBruceLu/DAPP/wiki/rd2.png)\n>\n>\n\n操作示例，示例中将使用两个`goroutine`分别担任发布者和订阅者角色进行演示：\n\n```go\npackage main\n\nimport (\n    \"github.com/garyburd/redigo/redis\"\n    \"fmt\"\n    \"time\"\n)\n\nfunc Subs() {  //订阅者\n    conn, err := redis.Dial(\"tcp\", \"10.1.210.69:6379\")\n    if err != nil {\n        fmt.Println(\"connect redis error :\", err)\n        return\n    }\n    defer conn.Close()\n    psc := redis.PubSubConn{conn}\n    psc.Subscribe(\"channel1\") //订阅channel1频道\n    for {\n        switch v := psc.Receive().(type) {\n        case redis.Message:\n            fmt.Printf(\"%s: message: %s\\n\", v.Channel, v.Data)\n        case redis.Subscription:\n            fmt.Printf(\"%s: %s %d\\n\", v.Channel, v.Kind, v.Count)\n        case error:\n            fmt.Println(v)\n            return\n        }\n    }\n}\n\nfunc Push(message string)  { //发布者\n    conn, _ := redis.Dial(\"tcp\", \"10.1.210.69:6379\")\n    _,err1 := conn.Do(\"PUBLISH\", \"channel1\", message)\n    if err1 != nil {\n    \tfmt.Println(\"pub err: \", err1)\n        return\n    }\n}\n\nfunc main()  {\n    go Subs()\n    go Push(\"this is wd\")\n    time.Sleep(time.Second*3)\n}\n//channel1: subscribe 1\n//channel1: message: this is wd\n```\n\n#### 事务操作\n\n`MULTI`, `EXEC`,`DISCARD`和`WATCH`是构成Redis事务的基础，当然我们使用go语言对redis进行事务操作的时候本质也是使用这些命令。\n\n`MULTI`：开启事务\n\n`EXEC`：执行事务\n\n`DISCARD`：取消事务\n\n`WATCH`：监视事务中的键变化，一旦有改变则取消事务\n\n<font color=\"red\">**示例：**</font>\n\n```go\npackage main\n\nimport (\n\t\"github.com/garyburd/redigo/redis\"\n\t\"fmt\"\n)\n\nfunc main()  {\n    conn,err := redis.Dial(\"tcp\",\"10.1.210.69:6379\")\n    if err != nil {\n        fmt.Println(\"connect redis error :\",err)\n        return\n    }\n    defer conn.Close()\n    conn.Send(\"MULTI\")\n    conn.Send(\"INCR\", \"foo\")\n    conn.Send(\"INCR\", \"bar\")\n    r, err := conn.Do(\"EXEC\")\n    fmt.Println(r)\n}\n//[1, 1]\n```\n\n#### 连接池使用\n\n`redis`连接池是通过`pool`结构体实现，以下是源码定义，相关参数说明已经备注：\n\n```go\ntype Pool struct {\n    // Dial is an application supplied function for creating and configuring a\n    // connection.\n    //\n    // The connection returned from Dial must not be in a special state\n    // (subscribed to pubsub channel, transaction started, ...).\n    Dial func() (Conn, error) //连接方法\n\n    // TestOnBorrow is an optional application supplied function for checking\n    // the health of an idle connection before the connection is used again by\n\t// the application. Argument t is the time that the connection was returned\n    // to the pool. If the function returns an error, then the connection is\n    // closed.\n    TestOnBorrow func(c Conn, t time.Time) error\n\n    // Maximum number of idle connections in the pool.\n    MaxIdle int  //最大的空闲连接数，即使没有redis连接时依然可以保持N个空闲的连接，而不被清除，随时处于待命状态\n\n    // Maximum number of connections allocated by the pool at a given time.\n    // When zero, there is no limit on the number of connections in the pool.\n    MaxActive int //最大的激活连接数，同时最多有N个连接\n\n    // Close connections after remaining idle for this duration. If the value\n    // is zero, then idle connections are not closed. Applications should set\n    // the timeout to a value less than the server's timeout.\n    IdleTimeout time.Duration  //空闲连接等待时间，超过此时间后，空闲连接将被关闭\n\n    // If Wait is true and the pool is at the MaxActive limit, then Get() waits\n    // for a connection to be returned to the pool before returning.\n    Wait bool  //当配置项为true并且MaxActive参数有限制时候，使用Get方法等待一个连接返回给连接池\n\n    // Close connections older than this duration. If the value is zero, then\n    // the pool does not close connections based on age.\n    MaxConnLifetime time.Duration\n    // contains filtered or unexported fields\n}\n```\n\n<font color=\"red\">**示例：**</font>\n\n```go\npackage main\n\nimport (\n    \"github.com/garyburd/redigo/redis\"\n    \"fmt\"\n)\n\nvar Pool redis.Pool\nfunc init()  {      //init 用于初始化一些参数，先于main执行\n    Pool = redis.Pool{\n        MaxIdle:     16,\n        MaxActive:   32,\n        IdleTimeout: 120,\n        Dial: func() (redis.Conn, error) {\n            return redis.Dial(\"tcp\", \"10.1.210.69:6379\")\n        },\n    }\n}\n\nfunc main()  {\n\n    conn :=Pool.Get()\n    res,err := conn.Do(\"HSET\",\"student\",\"name\",\"jack\")\n    fmt.Println(res,err)\n    res1,err := redis.String(conn.Do(\"HGET\",\"student\",\"name\"))\n    fmt.Printf(\"res:%s,error:%v\",res1,err)\n\n}\n//0 <nil>\n//res:jack,error:<nil>\n```\n\n","tags":["Redis"],"categories":["database"]},{"title":"MySQL的常用命令与简介","url":"/2018/12/16/MySQL的常用命令/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nMySQL养成记之常用命令\n\n<!-- more -->\n\n[TOC]\n\n## 数据库简介\n\n当前使用的数据库，主要分为两类：\n\n- 文档型：sqlite，就是一个文件，通过对文件的复制完成数据库的复制\n- 服务型：mysql、postgre，数据存储在一个物理文件中，但是需要使用终端以tcp/ip协议连接，进行数据库的读写操作\n\n## E-R模式\n\n- 当前物理的数据库都是按照E-R模型设计的\n  - E表示entry，实体\n  - R表示relationship，关系\n- 一个实体转换为数据库中的一个表\n- 关系描述两个实体之间的对应规则，包括\n  - 一对一\n  - 一对多\n  - 多对多\n- 关系转换为数据库表中的一个列 `*`在关系型数据库中一行就是一个对象\n\n## 三范式\n\n经过研究和对使用中问题的总结，对于数据库提出了一些规范\n\n> - 第一范式（1NF）：列不可拆分\n> - 第二范式（2NF）：唯一标识\n> - 第三范式（3NF）：引用主键\n>\n> **<font color=\"red\">说明：后一个范式，都是基于前一个范式的基础建立的</font>**","tags":["MySQL"],"categories":["database"]},{"url":"/2018/12/12/gRPC官方文档/"},{"title":"常见的共识算法","url":"/2018/12/10/常见共识算法/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nPoS、PoW、DPoS\n\n<!-- more -->\n\n本文是对区块链技术中涉及的共识算法的学习总结整理。 其中PBFT和Raft是联盟链和私有链常用的共识算法，而PoW（比特币采用）和PoS是公有链常用的共识算法。\n\n> 建议对区块链的学习，要分成是公有链还是联盟链，这两种链中一般采用的共识算法是有较大不同的，P2P网络等也有较大的不同。传统的共识算法一般不适用于公有链，而一定程度上适用于联盟链。\n\n## 实用拜占庭容错系统PBFT（联盟链中常用）\n\n拜占庭容错技术（Byzantine Fault Tolerance,BFT）是一类分布式计算领域的容错技术，是一种解决分布式系统容错问题的通用方案。实用拜占庭容错系统（Practical Byzantine Fault Tolerance，PBFT）使拜占庭协议的运行复杂度从指数级别降低到多项式级别，使拜占庭协议在分布式系统中应用成为可能。\n\n### 拜占庭将军问题\n\n拜占庭将军（Byzantine Generals Problem）问题，是 Leslie Lamport 1982 年提出用来解释一致性问题的一个虚构模型。拜占庭是古代东罗马帝国的首都，由于地域宽广，守卫边境的多个将军（系统中的多个节点）需要通过信使来传递消息，达成某些一致的决定。但由于将军中可能存在叛徒（系统中节点出错），这些叛徒将努力向不同的将军发送不同的消息，试图会干扰一致性的达成。拜占庭问题即为在此情况下，如何让忠诚的将军们能达成行动的一致。\n\n### 拜占庭容错系统\n\n拜占庭容错系统是指：在一个拥有nn台节点的系统，整个系统，对每个请求满足如下条件：\n\n所有非拜占庭节点使用相同的输入信息，产生同样的结果；\n如果输入的信息正确，那么所有非拜占庭节点必须接收这个信息，并计算相应的结果。\n与此同时,在拜占庭系统的实际运行过程中一般假设系统中拜占庭节点不超过mm台，并且对每个请求满足2个指标：\n\n安全性——任何已经完成的请求都不会被更改，它可以在以后请求看到；\n活性——可以接受并且执行非拜占庭客户端的请求，不会被任何因素影响而导致非拜占庭客户端的请求不能执行。\n拜占庭系统目前普遍采用的假设条件包括: \n1) 拜占庭节点的行为可以是任意的，拜占庭节点之间可以共谋； \n2) 节点之间的错误是不相关的； \n3) 节点之间通过异步网络连接，网络中的消息可能丢失、乱序、延时到达； \n4) 服务器之间传递的信息,第三方可以知晓 ,但是不能窜改、伪造信息的内容和验证信息的完整性；\n\n（发生故障的节点称为拜占庭节点；正常的节点为非拜占庭节点。）\n\n### 状态机拜占庭系统\n\n#### 状态机拜占庭系统的特点\n\n状态机拜占庭系统的特点是整个系统共同维护一个状态,所有节点采取一致的行动,一般包括 3 种协议：一致性协议、 检查点协议和视图更换协议。系统正常运行在一致性协议和检查点协议下，视图更换协议则是只有在主节点出错或者运行缓慢的情况下才会启动，负责维系系统继续执行客户端请求的能力。\n\n#### 状态机拜占庭系统的核心协议\n\n##### 一、一致性协议 \n\n一致性协议的目标是使来自客户端的请求在每个服务器上都按照一个确定的顺序执行。在协议中，一般有一个服务器被称作主节点，负责将客户端的请求排序；其余的服务器称作从节点，按照主节点提供的顺序执行请求。所有的服务器都在相同的配置信息下工作，这个配置信息称作view，每更换一次主节点，view就会随之变化。\n\n一致性协议至少包含3个阶段：发送请求、序号分配和返回结果。根据协议设计的不同，可能包含相互交互、序号确认等阶段。\n\n一致性协议解决一致性的方法主要有： \n1）服务器之间两两交互，服务器通过将自己获得的信息传递给其他的服务器； \n2）由客户端收集服务器的信息，将收集的信息制作成证明文件再发送给服务器。对于一个包含3m+13m+1台服务器的拜占庭系统，需要收集到2m+12m+1台服务器发送的一致信息，才能保证达成一致的非拜占庭服务器数量大于拜占庭服务器数量。\n\n引申思考： \n1. 部署一个采用PBFT共识算法的区块链，至少需要几个节点呢？ \n2. PBFT共识算法的区块链，最佳节点数量问题，采用PBFT共识算法的区块链系统节点数量的下限和上限？\n\n##### 二、检查点协议 \n\n拜占庭系统每执行一个请求，服务器需要记录日志。如果日志得不到及时的清理，就会导致系统资源被大量的日志所占用，影响系统性能及可用性。另一方面，由于拜占庭服务器的存在，一致性协议并不能保证每一台服务器都执行了相同的请求，所以，不同服务器状态可能不一致。例如，某些服务器可能由于网络延时导致从某个序号开始，之后的请求都没有执行。因此，拜占庭系统中设置周期性的检查点协议，将系统中的服务器同步到某一个相同的状态。因此，周期性的检查点协议可以定期地处理日志，节约资源，同时及时纠正服务器状态。\n\n处理日志主要解决的问题就是区分那些日志可以清理，那些日志仍然需要保留。如果一个请求已经被m+1m+1台非拜占庭服务器执行，并且某一服务器ii能够向其他的服务器证明这一点，那么ii就可以将关于这个请求的日志删除。目前，协议普遍采用的方式是服务器每执行一定数量的请求，就将自己的状态发送给所有服务器并且执行一个该协议，如果某台服务器接收到2m+12m+1台服务器的状态，那么其中一致的部分就是至少有m+1m+1非拜占庭服务器经历过的状态，因此，这部分的日志就可以删除，同时将自己状态更新只较新状态。\n\n##### 三、视图更换 \n\n在一致性协议里，已经知道主节点在整个系统中拥有序号分配，请求转发等核心能力，支配着这个系统的运行行为。然而一旦主节点自身发生错误，就可能导致从节点接收到具有相同序号的不同请求，或者同一个请求被分配多个序号等问题，这将直接导致请求不能被正确执行。视图更换协议的作用就是在主节点不能继续履行职责时，将其用一个从节点替换掉，并且保证已经被非拜占庭服务器执行的请求不会被篡改。\n\n视图更换协议一般有两种触发方式： \n1）只由服务器触发，这一类触发方式中，判断服务器一致性是否达成的工作是由服务器自身负责，客户端不能从请求的整个执行过程中获得服务器运行状况的信息； \n2）客户端触发，这一类触发方式中，客户端一般负责判断服务器是否达成一致，如果不达成一致，那么就能判断服务器运行出现问题，如果是主节点的问题就会要求服务器更换主节点。\n\n视图更换协议需要解决的问题是如何保证已经被非拜占庭服务器执行的请求不被更改。由于系统达成一致性之后至少有m+1m+1台非拜占庭服务器执行了请求，所以目前采用的方法是：由新的主节点收集至少2m+12m+1台服务器的状态信息，这些状态信息中一定包含所有执行过的请求；然后，新主节点将这些状态信息发送给所有的服务器，服务器按照相同的原则将在上一个主节点完成的请求同步一遍.同步之后,所有的节点都处于相同的状态,这时就可以开始执行新的请求。\n\n#### 实用拜占庭容错系统PBFT详解\n\n实用拜占庭容错系统（Practical Byzantine Fault Tolerance，PBFT），是一类状态机拜占庭系统。\n\nPBFT的一致性协议如下：PBFT系统通常假设故障节点数为mm个，而整个服务节点数为3m+13m+1个。每一个客户端的请求需要经过5个阶段，通过采用两次两两交互的方式在服务器达成一致之后再执行客户端的请求。由于客户端不能从服务器端获取任何服务器运行的状态信息，PBFT中主节点是否发生错误只能由服务器监测。如果服务器在一段时间内都不能完成客户端的请求，则会触发视图更换协议。 \n\n![](https://github.com/AlexBruceLu/DAPP/wiki/ddd.png)\n\n上图显示了一个简化的PBFT的协议通信模式，其中CC为客户端，N0N0~N3N3表示服务节点，特别的，N0N0为主节点，N3N3为故障节点。整个协议的基本过程如下： \n1）客户端发送请求，激活主节点的服务操作； \n2）当主节点接收请求后，启动三阶段的协议以向各从节点广播请求；\n\n序号分配阶段，主节点给请求赋值一个序号nn，广播序号分配消息和客户端的请求消息mm，并将构造pre-prepare消息给各从节点；\n交互阶段，从节点接收pre-prepare消息，向其他服务节点广播prepare消息；\n序号确认阶段，各节点对视图内的请求和次序进行验证后，广播commit消息，执行收到的客户端的请求并给客户端响应。\n3）客户端等待来自不同节点的响应，若有m+1m+1个响应相同，则该响应即为运算的结果；\n\n### Raft协议\n\nRaft是在非拜占庭故障下达成共识的强一致协议。在区块链系统中，使用Raft实现记账共识的过程可以描述如下：首先选举一个leader，接着赋予leader完全的权利管理记账。leader从客户端接收记账请求，完成记账操作，生成区块，并复制到其他记账节点。有了leader简化了记账操作的管理。如果leader失效或与其他节点失去联系，这时，系统就会选出新的leader。\n\n#### Raft基础\n\n一个Raft集群通常包含5个服务器，允许系统有2个故障服务器。每个服务器处于3个状态之一：leader、follower或candidate。正常操作状态下，仅有一个leader，其他的服务器均为follower。follower是被动的，不会对自身发出的请求而是对来自leader和candidate的请求做出响应。leader处理所有的客户端请求（若客户端联系follower，则该follower将转发给leader)。candidate状态用来选举leader。\n\nRaft阶段主要分为两个，首先是leader选举过程，然后在选举出来的leader基础上进行正常操作，比如日志复制、记账等。\n\n#### leader选举\n\n当follower在选举超时时间内未收到leader的心跳消息，则转换为candidate状态。为了避免选举冲突，这个超时时间是一个150~300ms之间的随机数。\n\n一般而言，在Raft系统中： \n1）任何一个服务器都可以成为一个候选者candidate，它向其他服务器follower发出要求选举自己的请求。 \n2）其他服务器同意了，发出OK。如果在这个过程中，有一个follower宕机，没有收到请求选举的要求，此时候选者可以自己选自己，只要达到N/2+1N/2+1的大多数票，候选人还是可以成为leader。 \n3）这样这个候选者就成为了leader领导人，它可以向follower发出指令，比如进行记账。 \n4）以后可以通过心跳进行记账的通知。 \n5）一旦这个leader崩溃了，那么follower中有一个成为候选者，并发出邀票选举。 \n6）follower同意后，其成为leader，继续承担记账等指导工作。\n\n#### 记账过程\n\nRaft的记账过程按以下步骤完成： \n1）假设leader领导人已经选出，这时客户端发出增加一个日志的要求； \n2）leader要求follower遵从他的指令，都将这个新的日志内容追加到他们各自日志中； \n3）大多数follower服务器将交易记录写入账本后，确认追加成功，发出确认成功消息； \n4）在下一个心跳中，leader会通知所有follower更新确认的项目。 \n对于每个新的交易记录，重复上述过程。\n\n如果在这一过程中，发生了网络通信故障，使得leader不能访问大多数follower，那么leader只能正常更新它能访问的那些follower服务器。而大多数的服务器follower因为没有了leader，它们将重新选举一个候选者作为leader，然后这个leader作为代表与外界打交道，如果外界要求其添加新的交易记录，这个新的leader就按上述步骤通知大多数follower，如果这时网络故障修复了，那么原先的leader就变成follower，在失联阶段，这个老leader的任何更新都不能算确认，都回滚，接收新的leader的新更新。\n\n如果想更直观的理解Raft协议，可以看动画演示。 \n论文原文：In Search of an Understandable Consensus Algorithm \n学习参考：The Raft Consensus Algorithm\n\n## PoW\n\nPoW的原理可参看这篇博文中哈希函数难题友好性这一节：http://blog.csdn.net/s_lisheng/article/details/77937202，理解了难题友好性，就基本理解了PoW机制的原理。结合比特币去理解PoW。比特币PoW的过程，就是将不同的nonce值作为输入，尝试进行SHA256哈希运算，找出满足给定数量前导0的哈希值的过程。要求的前导0的个数越多，代表难度越大。比特币节点求解工作量证明问题的步骤归纳如下：\n\n1）生成铸币交易，并与其他所有准备打包进区块的交易组成交易列表，通过Merkle树算法生成Merkle跟哈希； \n2）把Merkle根哈希及其他相关字段组装成区块头，将区块头的80字节数据作为工作量证明的输入； \n3）不停地变更区块头中的随机数nonce，并对每次变更后的区块头做双重SHA256运算，将结果值与当前网络的目标难度做比对，如果满足难度条件，则解题成功，工作量证明完成。\n\n## PoS\n\nPoW存在以下弊端：\n\n矿池的出现，一定程度上违背了去中心化的初衷，同时也使得51%攻击成为可能，影响其安全性。\nPoW存在巨大的算力浪费，看看矿池用掉多少电就知道了。\nPoS（权益证明，Proof of Stake）的出现很大程度上是因为PoW的缺陷而提出的。采用PoS的币中不同币的PoS不完全相同，权益证明要求用户证明拥有某些数量的货币（即对货币的权益），下面以点点币为例，理解PoS的思想。\n\n点点币在SHA-256的哈希运算的难度方便引入了币龄的概念，使得难度与交易输入的币龄成反比。在点点币中，币龄被定义为币的数量与币所拥有的天数的乘积。点点币的权益证明机制结合了随机化与币龄的概念，未使用至少30天的币可以参与竞争下一区块，越久和越大的币集有更大的可能去签名下一区块。而一旦币的权益被用于签名一个区块，则币龄将清为零，这样必须等待至少30日才能签署另一个区块。同时，为防止非常老或非常大的权益控制区块链，寻找下一区块的最大概率在90天后达到最大值，这一过程保护了网络，并随着时间逐渐成为新的币而无需消耗大量的计算能力。\n\n## DPoS\n\nPoS机制虽然考虑了PoW的不足，但也有缺点：依据权益结余来选择，会导致首富账户的权力更大，有可能支配记账权。股份授权证明机制（Delegated Proof of Stake，DPoS），是对PoW、PoS不足的提出的。下面以比特股为例，理解DPoS的思想。\n\n比特股引入了见证人这个概念，见证人可以生成区块，每一个持有比特股的人都可以投票选举见证人。得到总同意票数中的前NN个（NN通常定义为101）候选者可以当选为见证人，当选见证人的个数需满足：至少一半的参与投票者相信NN已经充分地去中心化。见证人的候选名单每个维护周期（1天）更新一次。见证人然后随机排列，每个见证人按序有2秒的权限时间生成区块，若见证人在给定的时间片不能生成区块，区块生成权限交给下一时间片对应的见证人。如果见证人提供的算力不稳定或计算机宕机等，持股人可以随时通过投票更换这些见证人。\n\n可以看到，其核心思想是通过缩小参与核心共识过程的节点数量，以提高共识效率。（这里可以认为选举见证人的过程为非核心共识过程，而见证人按序生成区块可以认为是核心共识过程）\n\n","tags":["共识算法"],"categories":["others"]},{"title":"数据结构入门","url":"/2018/12/09/数据结构/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n常见的数据结构基础\n\n<!-- more -->\n\n## 数据结构基础理论\n\n### 什么是数据？\n\n数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合。数据不仅仅包括整型、实型等数值类型，还包括字符及声音、图像、视频等非数值类型。 \n\n### 数据结构的概念\n\n数据结构是计算机存储、组织数据的方式。数据结构是指相互之间存在一种或多种特定关系的数据元素的集合。通常情况下，精心选择的数据结构可以带来更高的运行或者存储效率。数据结构往往同高效的检索算法和索引技术有关。 \n\n> <font color=\"red\">数据结构是计算机存储、组织数据的方式。是相互之间存在一种或多种特定关系的数据元素集合 </font>\n\n### 算法的概念\n\n算法：<font color=\"red\">特定问题求解不走的描述，</font>在计算机中表现为**指令的有限序列**，算法是独立存在的一种解决问题的方法和思想。**对于算法来说，语言不重要，重要的是思想。**\n\n#### 算法和数据结构的区别\n\n数据结构只是静态的描述了数据元素之间的关系，高效的程序需要在数据结构的基础上设计和选择算法。\n\n- <font color=\"red\">算法是为了解决实际问题而设计的</font>\n- <font color=\"red\">数据结构是算法需要处理的问题的载体</font>\n- 数据结构与算法相符相成\n\n#### 算法的比较\n\n假设求解1 + 2 + ... + 100 的结果，写程序会怎么写\n\n- **方法一：**\n\n  ```go\n  sum := 0\n  n := 100\n  for i := 0; i < n; i++ {\n      sum += i\n  }\n  fmt.Println(\"%d\",sum)\n  ```\n\n- **方法二：**\n\n  ```go\n  sum := 0\n  n := 100\n  sum = (1 + n) * n / 2\n  fmt.Println(\"%d\",sum)\n  ```\n\n**上述两段代码，第二种算法会比较高效，这就是一个好的算法对程序高效性的体现。**\n\n#### 算法的特性\n\n算法的五大基本特性：**输入、输出、有穷性、确定性和可行性。**\n\n**输入、输出：**算法具有零个或多个输入，至少有一个或多个输出。\n\n**有穷性：**指算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且每一个步骤在可接受的时间内完成。\n\n**确定性：**算法的每一步骤都有确定的含义，不会出现二义性。\n\n**可行性：**算法的每一步都必须是可行的，换言之，每一步都能通过执行有限次数完成。\n\n### 数据结构分类\n\n按照视点的不同，可以把数据结构分为**逻辑结构、物理结构。**\n\n#### 逻辑结构\n\n##### 集合结构\n\n集合结构中的数据元素除了同属于一个集合外，它们本身之间并没有关系。各个数据元素是平等的。它们共同属于同一个集合，数据结构中的集合关系类似于数学中的集合，如下图：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/data1.png)\n\n##### 线性结构\n\n线性结构中的数据元素之间是一一对应关系。如下图：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/data2.png)\n\n##### 树形结构\n\n树形结构中是数据元素之间存在一种一对多的层次关系，如下图：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/data3.png)\n\n##### 图形结构\n\n图形结构中的数据元素之间是存在多对多的关系，如图：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/data4.png)\n\n#### 物理结构\n\n**物理结构：**是指数据的逻辑结构在计算机中的存储形式，共分为两种：顺序存储和链式存储。\n\n##### 顺序存储\n\n是把数据元素存放在地址连续的存储单元里，其数据的逻辑关系和物理关系是一致的，如图：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/data5.png)\n\n> 如果所有的数据结构都很简单且有规律，就比较易于操作。可往往实际情况，数据结构中的元素总会遇到增、删、改、查的操作。面对市场变化的数据结构，运用以上顺序存储是不科学的。\n\n##### 链式存储\n\n是把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的。数据存储的关系并不能反映其逻辑关系，因此需要用一个指针存放数据元素的地址，这样通过地址就可以找到相关数据的位置，如下图：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/data6.png)\n\n## 线性表\n\n### 线性表基础概念\n\n线性表是一种最简单的且常用的数据结构。数据结构的基本特点是节点之间满足线性关系。动态数组、栈、队列都属于线性结构。它们的共同之处，是节点中有且只有一个开始节点和终端节点。这种关系，可以把它们的所有节点排成一个线性序列。但是，它们分别属于几种不同的抽象数据类型实现，它们之间的区别，主要就是操作的不同。\n\n线性表是零个或多个数据元素的有限序列，数据元素之间是有顺序的，数据元素个数是有限的，数据元素的类型必须相同。\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/data7.png)\n\n线性表的性质：\n\n- a0 为线性表的第一个元素，只有一个后继；\n\n- an 为线性表的最后一个元素，只有一个前驱；\n\n- 除了 a0 和 an 外的其他元素 ai ，既有一个前驱又有一个后继；\n\n- 线性表能够逐项访问和顺序存取；\n\n  > **线性表的抽象数据类型定义：** \n  >\n  > ADT 线性表（ List） \n  >\n  > Data\n  > 线性表的数据对象集合为{ a0, a1, ……, an }，每个元素的类型均为 DataType。其中，除第一个元素 a0外，每个元素有且只有一个直接前驱元素，除了最后一个元素 an 外，每个元素有且只有一个直接后继元素。数据元素之间的关系是一一对应的。 \n  >\n  > peration（操作）\n  > // 初始化，建立一个空的线性表 L。\n  > InitList(*L);\n  > // 若线性表为空，返回 true，否则返回 false\n  > ListEmpty(L);\n  > // 将线性表清空 \n  >\n  > ClearList(*L);\n  > // 将线性表 L 中的第 i 个位置的元素返回给 e\n  > GetElem(L, i, *e);\n  > // 在线性表 L 中的第 i 个位置插入新元素 e\n  > ListInsert(*L, i, e);\n  > // 删除线性表 L 中的第 i 个位置元素，并用 e 返回其值\n  > ListDelete(*L, i, *e);\n  > // 返回线性表 L 的元素个数\n  > ListLength(L);\n  > // 销毁线性表\n  > DestroyList(*L); \n\n### 线性表的顺序存储\n\n通常线性表可以采用顺序存储和链式存储。\n\n采用顺序存储是表示线性表最简单的方法，具体做法是：将线性表中的元素一个接一个的存储在一块连续的存储区域中，这种顺序表示的线性表也称为顺序表。\n\n#### 线性表顺内需存储（动态数组）的设计与实现\n\n<font color=\"red\">**操作要点：**</font>\n\n- 插入元素操作\n\n  - 判断线性表是否合法\n  - 判断插入位置是否合法\n  - 判断空间是否满足\n  - 把最后一个与元素到插入位置的元素后移一位\n  - 将新元素插入\n  - 线性表长度加1\n\n- 获取元素操作\n\n  - 判断线性表是否合法\n  - 判断位置是否合法\n  - 直接通过元素的下表方式获取元素\n\n- 删除元素的操作\n\n  - 判断线性表是否合法\n  - 判断删除位置是否合法\n  - 将元素取出\n  - 将删除位置后的元素分别向前移动一个位置\n  - 线性表长度减1\n\n- 元素的插入\n\n  ![](![](https://github.com/AlexBruceLu/DAPP/wiki/data8.png)\n\n- 元素的删除\n\n  ![](![](https://github.com/AlexBruceLu/DAPP/wiki/data9.png)\n\n  <font color=\"red\">**注意：**</font>链表的容量和链表的长度是两个不同的概念\n\n#### 优点和缺点\n\n<font color=\"red\">**优点**</font>\n\n- 无需为线性表中的逻辑关系增加额外的空间\n- 可以快速的获取表中合法位置的元素\n\n<font color=\"red\">**缺点**</font>\n\n- 插入和删除操作需要移动大量的元素\n\n### 线性表的链式存储\n\n链表为了表示每个元素与其直接后继元素之间的逻辑关系，每个元素除了存储本身的信息外，还需要存储指示其直接后继的信息。\n\n![](![](https://github.com/AlexBruceLu/DAPP/wiki/data10.png)\n\n- 单链表\n\n  - 线性表的链式存储结构中，每个节点中只包含一个指针域，这样的链表叫做单链表\n\n  - 通过每个节点的指针域将线性表的数据元素按其逻辑次序链接在一起\n\n    ![](![](https://github.com/AlexBruceLu/DAPP/wiki/data11.png)\n\n- 概念解释\n\n  - 表头节点\n\n    - 链表中的第一个节点，包含指向第一个数据元素的指针以及链表自身的一些信息\n\n  - 数据节点\n\n    - 链表中代表数据元素的节点，包含指向下一个数据元素的指针和数据元素的信息\n\n  - 尾节点\n\n    - 链表中的最后一个数据节点，下一个元素指针为空，表示无后继元素\n\n    ![](https://github.com/AlexBruceLu/DAPP/wiki/data12.png)\n\n#### 线性表的链式存储（单项链表）的设计与实现\n\n- **插入操作**\n\n  ![](https://github.com/AlexBruceLu/DAPP/wiki/data13.png)\n\n```\nnode -> next = current -> next;\ncurrent -> next = node;\n```\n\n- 删除操作\n\n  ![](https://github.com/AlexBruceLu/DAPP/wiki/data14.png)\n\n  ```\n  current->next = ret->next;\n  ```\n\n#### 优点和缺点\n\n- <font color=\"red\">**优点**</font>\n  - 无需一次性定制链表的容量 \n  - 插入和删除操作无需移动数据元素 \n- <font color=\"red\">**缺点**</font>\n  - 数据元素必须保存后继元素的位置信息 \n  - 获取指定数据的元素操作需要顺序访问之前的元素 \n\n","tags":["数据结构"],"categories":["others"]},{"title":"详解TCP/IP协议","url":"/2018/12/05/详解TCPIP协议/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nTCP/IP网络协议的详解概述\n\n<!-- more -->\n\n[TOC]\n\n![img](https://upload-images.jianshu.io/upload_images/1856419-168b63033e3a808d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)\n\n### 计算机网络体系结构分层\n\n\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-efd361484c60d785.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/581/format/webp)\n\n计算机网络体系结构分层\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-c69d60eeeebadd37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)\n\n计算机网络体系结构分层\n\n不难看出，TCP/IP 与 OSI 在分层模块上稍有区别。OSI 参考模型注重“通信协议必要的功能是什么”，而 TCP/IP 则更强调“在计算机上实现协议应该开发哪种程序”。\n\n\n\n### TCP/IP 基础\n\n#### TCP/IP 的具体含义\n\n从字面意义上讲，有人可能会认为 TCP/IP 是指 TCP 和 IP 两种协议。实际生活当中有时也确实就是指这两种协议。然而在很多情况下，它只是利用 IP 进行通信时所必须用到的协议群的统称。具体来说，IP 或 ICMP、TCP 或 UDP、TELNET 或 FTP、以及 HTTP 等都属于 TCP/IP 协议。他们与 TCP 或 IP 的关系紧密，是互联网必不可少的组成部分。TCP/IP 一词泛指这些协议，因此，有时也称 TCP/IP 为网际协议群。\n 互联网进行通信时，需要相应的网络协议，TCP/IP 原本就是为使用互联网而开发制定的协议族。因此，互联网的协议就是 TCP/IP，TCP/IP 就是互联网的协议。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-ca4aba22c1f7a217.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/768/format/webp)\n\n网际协议群\n\n#### 数据包\n\n**包、帧、数据包、段、消息**\n 以上五个术语都用来表述数据的单位，大致区分如下：\n\n- 包可以说是全能性术语；\n- 帧用于表示数据链路层中包的单位；\n- 数据包是 IP 和 UDP 等网络层以上的分层中包的单位；\n- 段则表示 TCP 数据流中的信息；\n- 消息是指应用协议中数据的单位。\n\n每个分层中，都会对所发送的数据附加一个首部，在这个首部中包含了该层必要的信息，如发送的目标地址以及协议相关信息。通常，为协议提供的信息为包首部，所要发送的内容为数据。在下一层的角度看，从上一层收到的包全部都被认为是本层的数据。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-dfd044f1ccc5c752.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/560/format/webp)\n\n数据包首部\n\n网络中传输的数据包由两部分组成：一部分是协议所要用到的首部，另一部分是上一层传过来的数据。首部的结构由协议的具体规范详细定义。在数据包的首部，明确标明了协议应该如何读取数据。反过来说，看到首部，也就能够了解该协议必要的信息以及所要处理的数据。**包首部就像协议的脸。**\n\n#### 数据处理流程\n\n下图以用户 a 向用户 b 发送邮件为例子：\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-2051967a4e85d719.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/772/format/webp)\n\n数据处理流程\n\n- ① 应用程序处理\n   首先应用程序会进行编码处理，这些编码相当于 OSI 的表示层功能；\n   编码转化后，邮件不一定马上被发送出去，这种何时建立通信连接何时发送数据的管理功能，相当于 OSI 的会话层功能。\n- ② TCP 模块的处理\n   TCP 根据应用的指示，负责建立连接、发送数据以及断开连接。TCP 提供将应用层发来的数据顺利发送至对端的可靠传输。为了实现这一功能，需要在应用层数据的前端附加一个 TCP 首部。\n- ③ IP 模块的处理\n   IP 将 TCP 传过来的 TCP 首部和 TCP 数据合起来当做自己的数据，并在 TCP 首部的前端加上自己的 IP 首部。IP 包生成后，参考路由控制表决定接受此 IP 包的路由或主机。\n- ④ 网络接口（以太网驱动）的处理\n   从 IP 传过来的 IP 包对于以太网来说就是数据。给这些数据附加上以太网首部并进行发送处理，生成的以太网数据包将通过物理层传输给接收端。\n- ⑤ 网络接口（以太网驱动）的处理\n   主机收到以太网包后，首先从以太网包首部找到 MAC 地址判断是否为发送给自己的包，若不是则丢弃数据。\n   如果是发送给自己的包，则从以太网包首部中的类型确定数据类型，再传给相应的模块，如 IP、ARP 等。这里的例子则是 IP 。\n- ⑥ IP 模块的处理\n   IP 模块接收到 数据后也做类似的处理。从包首部中判断此 IP 地址是否与自己的 IP 地址匹配，如果匹配则根据首部的协议类型将数据发送给对应的模块，如 TCP、UDP。这里的例子则是 TCP。\n   另外吗，对于有路由器的情况，接收端地址往往不是自己的地址，此时，需要借助路由控制表，在调查应该送往的主机或路由器之后再进行转发数据。\n- ⑦ TCP 模块的处理\n   在 TCP 模块中，首先会计算一下校验和，判断数据是否被破坏。然后检查是否在按照序号接收数据。最后检查端口号，确定具体的应用程序。数据被完整地接收以后，会传给由端口号识别的应用程序。\n- ⑧ 应用程序的处理\n   接收端应用程序会直接接收发送端发送的数据。通过解析数据，展示相应的内容。\n\n### 传输层中的 TCP 和 UDP\n\nTCP/IP 中有两个具有代表性的传输层协议，分别是 TCP 和 UDP。\n\n- TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，当应用程序采用 TCP 发送消息时，虽然可以保证发送的顺序，但还是犹如没有任何间隔的数据流发送给接收端。TCP 为提供可靠性传输，实行“顺序控制”或“重发控制”机制。此外还具备“流控制（流量控制）”、“拥塞控制”、提高网络利用率等众多功能。\n- UDP 是不具有可靠性的数据报协议。细微的处理它会交给上层的应用去完成。在 UDP 的情况下，虽然可以确保发送消息的大小，却不能保证消息一定会到达。因此，应用有时会根据自己的需要进行重发处理。\n- TCP 和 UDP 的优缺点无法简单地、绝对地去做比较：TCP 用于在传输层有必要实现可靠传输的情况；而在一方面，UDP 主要用于那些对高速传输和实时性有较高要求的通信或广播通信。TCP 和 UDP 应该根据应用的目的按需使用。\n\n#### 端口号\n\n数据链路和 IP 中的地址，分别指的是 MAC 地址和 IP 地址。前者用来识别同一链路中不同的计算机，后者用来识别 TCP/IP  网络中互连的主机和路由器。在传输层也有这种类似于地址的概念，那就是端口号。端口号用来识别同一台计算机中进行通信的不同应用程序。因此，它也被称为程序地址。\n\n##### 根据端口号识别应用\n\n一台计算机上同时可以运行多个程序。传输层协议正是利用这些端口号识别本机中正在进行通信的应用程序，并准确地将数据传输。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-aee529e8e598ec48.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/500/format/webp)\n\n通过端口号识别应用\n\n##### 通过 IP 地址、端口号、协议号进行通信识别\n\n- 仅凭目标端口号识别某一个通信是远远不够的。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-96457c6ddbe3157f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/763/format/webp)\n\n\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-47a50ea9428c29fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/748/format/webp)\n\n通过端口号、IP地址、协议号进行通信识别\n\n- ① 和② 的通信是在两台计算机上进行的。它们的目标端口号相同，都是80。这里可以根据源端口号加以区分。\n- ③ 和 ① 的目标端口号和源端口号完全相同，但它们各自的源 IP 地址不同。\n- 此外，当 IP 地址和端口号全都一样时，我们还可以通过协议号来区分（TCP 和 UDP）。\n\n##### 端口号的确定\n\n- 标准既定的端口号：这种方法也叫静态方法。它是指每个应用程序都有其指定的端口号。但并不是说可以随意使用任何一个端口号。例如 HTTP、FTP、TELNET 等广为使用的应用协议中所使用的端口号就是固定的。这些端口号被称为知名端口号，分布在 0~1023 之间；除知名端口号之外，还有一些端口号被正式注册，它们分布在 1024~49151 之间，不过这些端口号可用于任何通信用途。\n- 时序分配法：服务器有必要确定监听端口号，但是接受服务的客户端没必要确定端口号。在这种方法下，客户端应用程序完全可以不用自己设置端口号，而全权交给操作系统进行分配。动态分配的端口号范围在 49152~65535 之间。\n\n##### 端口号与协议\n\n- 端口号由其使用的传输层协议决定。因此，不同的传输层协议可以使用相同的端口号。\n- 此外，那些知名端口号与传输层协议并无关系。只要端口一致都将分配同一种应用程序进行处理。\n\n#### UDP\n\n- UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务。\n- 并且它是将应用程序发来的数据在收到的那一刻，立即按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况，UDP 也无法进行流量控制等避免网络拥塞行为。\n- 此外，传输途中出现丢包，UDP 也不负责重发。\n- 甚至当包的到达顺序出现乱序时也没有纠正的功能。\n- 如果需要以上的细节控制，不得不交由采用 UDP 的应用程序去处理。\n- UDP 常用于一下几个方面：1.包总量较少的通信（DNS、SNMP等）；2.视频、音频等多媒体通信（即时通信）；3.限定于 LAN 等特定网络中的应用通信；4.广播通信（广播、多播）。\n\n#### TCP\n\n- TCP 与 UDP 的区别相当大。它充分地实现了数据传输时各种控制功能，可以进行丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在 UDP 中都没有。\n- 此外，TCP 作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。\n- 根据 TCP 的这些机制，在 IP 这种无连接的网络上也能够实现高可靠性的通信（ 主要通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现）。\n\n##### 三次握手（重点）\n\n- TCP 提供面向有连接的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作。\n- 所谓三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发。\n\n下面来看看三次握手的流程图：\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-52baa0818e1bd1c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/602/format/webp)\n\n三次握手\n\n- 第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。\n- 第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。\n- 第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。\n\n##### 四次挥手（重点）\n\n- 四次挥手即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发。\n- 由于TCP连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。\n\n下面来看看四次挥手的流程图：\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-8787d7fb9fc4e802.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/596/format/webp)\n\n四次挥手\n\n- 中断连接端可以是客户端，也可以是服务器端。\n- 第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说\"我客户端没有数据要发给你了\"，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。\n- 第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。\n- 第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。\n- 第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。\n\n**上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况，**\n 具体流程如下图：\n \n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-baf89c213c19d3bd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/619/format/webp)\n\n同时挥手\n\n\n\n##### 通过序列号与确认应答提高可靠性\n\n- 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个已收到消息的通知。这个消息叫做确认应答（ACK）。当发送端将数据发出之后会等待对端的确认应答。如果有确认应答，说明数据已经成功到达对端。**反之，则数据丢失的可能性很大**。\n- 在一定时间内没有等待到确认应答，发送端就可以认为数据已经丢失，并进行重发。由此，即使产生了丢包，仍然能够保证数据能够到达对端，实现可靠传输。\n- 未收到确认应答并不意味着数据一定丢失。也有可能是数据对方已经收到，只是返回的确认应答在途中丢失。这种情况也会导致发送端误以为数据没有到达目的地而重发数据。\n- 此外，也有可能因为一些其他原因导致确认应答延迟到达，在源主机重发数据以后才到达的情况也屡见不鲜。此时，源主机只要按照机制重发数据即可。\n- 对于目标主机来说，反复收到相同的数据是不可取的。为了对上层应用提供可靠的传输，目标主机必须放弃重复的数据包。为此我们引入了序列号。\n- **序列号是按照顺序给发送数据的每一个字节（8位字节）都标上号码的编号。接收端查询接收数据 TCP 首部中的序列号和数据的长度，将自己下一步应该接收的序列号作为确认应答返送回去。通过序列号和确认应答号，TCP 能够识别是否已经接收数据，又能够判断是否需要接收，从而实现可靠传输。**\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-9221af60624ef403.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)\n\n序列号和确认应答\n\n##### 重发超时的确定\n\n-  **重发超时是指在重发数据之前，等待确认应答到来的那个特定时间间隔。**如果超过这个时间仍未收到确认应答，发送端将进行数据重发。最理想的是，找到一个最小时间，它能保证“确认应答一定能在这个时间内返回”。\n- TCP 要求不论处在何种网络环境下都要提供高性能通信，并且无论网络拥堵情况发生何种变化，都必须保持这一特性。为此，它在每次发包时都会计算往返时间及其偏差。将这个往返时间和偏差时间相加，重发超时的时间就是比这个总和要稍大一点的值。\n- 在 BSD 的 Unix 以及 Windows 系统中，超时都以0.5秒为单位进行控制，因此重发超时都是0.5秒的整数倍。不过，最初其重发超时的默认值一般设置为6秒左右。\n- 数据被重发之后若还是收不到确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长。\n- 此外，**数据也不会被无限、反复地重发。达到一定重发次数之后，如果仍没有任何确认应答返回，就会判断为网络或对端主机发生了异常，强制关闭连接。并且通知应用通信异常强行终止。** \n\n##### 以段为单位发送数据\n\n- 在建立 TCP 连接的同时，也可以确定发送数据包的单位，我们也可以称其为“最大消息长度”（MSS）。最理想的情况是，最大消息长度正好是 IP 中不会被分片处理的最大数据长度。\n- TCP 在传送大量数据时，是以 MSS 的大小将数据进行分割发送。进行重发时也是以 MSS  为单位。\n- MSS 在三次握手的时候，在两端主机之间被计算得出。两端的主机在发出建立连接的请求时，会在 TCP 首部中写入 MSS  选项，告诉对方自己的接口能够适应的 MSS 的大小。然后会在两者之间选择一个较小的值投入使用。\n\n##### 利用窗口控制提高速度\n\n- TCP 以1个段为单位，每发送一个段进行一次确认应答的处理。这样的传输方式有一个缺点，就是包的往返时间越长通信性能就越低。\n\n- 为解决这个问题，TCP 引入了窗口这个概念。确认应答不再是以每个分段，而是以更大的单位进行确认，转发时间将会被大幅地缩短。也就是说，发送端主机，在发送了一个段以后不必要一直等待确认应答，而是继续发送。如下图所示：\n\n\n\n  ![img](https:////upload-images.jianshu.io/upload_images/1856419-3883cce343404099.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/605/format/webp)\n\n  窗口控制\n\n- 窗口大小就是指无需等待确认应答而可以继续发送数据的最大值。上图中窗口大小为4个段。这个机制实现了使用大量的缓冲区，通过对多个段同时进行确认应答的功能。\n\n##### 滑动窗口控制\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-7919bd12b5b2917b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/859/format/webp)\n\n滑动窗口\n\n- 上图中的窗口内的数据即便没有收到确认应答也可以被发送出去。不过，在整个窗口的确认应答没有到达之前，如果其中部分数据出现丢包，那么发送端仍然要负责重传。为此，发送端主机需要设置缓存保留这些待被重传的数据，直到收到他们的确认应答。\n- 在滑动窗口以外的部分包括未发送的数据以及已经确认对端已收到的数据。当数据发出后若如期收到确认应答就可以不用再进行重发，此时数据就可以从缓存区清除。\n- 收到确认应答的情况下，将窗口滑动到确认应答中的序列号的位置。这样可以顺序地将多个段同时发送提高通信性能。这种机制也别称为滑动窗口控制。\n\n##### 窗口控制中的重发控制\n\n在使用窗口控制中， 出现丢包一般分为两种情况：\n\n- ① 确认应答未能返回的情况。在这种情况下，数据已经到达对端，是不需要再进行重发的，如下图：\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-f17380d7afc3bb73.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/595/format/webp)\n\n部分确认应答丢失\n\n- ② 某个报文段丢失的情况。接收主机如果收到一个自己应该接收的序列号以外的数据时，会针对当前为止收到数据返回确认应答。如下图所示，当某一报文段丢失后，发送端会一直收到序号为1001的确认应答，因此，在窗口比较大，又出现报文段丢失的情况下，同一个序列号的确认应答将会被重复不断地返回。而发送端主机如果连续3次收到同一个确认应答，就会将其对应的数据进行重发。这种机制比之前提到的超时管理更加高效，因此也被称为高速重发控制。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-0732e3d90fea80c8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/884/format/webp)\n\n高速重发控制\n\n### 网络层中的 IP 协议\n\n- IP（IPv4、IPv6）相当于 OSI 参考模型中的第3层——网络层。网络层的主要作用是“实现终端节点之间的通信”。这种终端节点之间的通信也叫“点对点通信”。\n- 网络的下一层——数据链路层的主要作用是在互连同一种数据链路的节点之间进行包传递。而一旦跨越多种数据链路，就需要借助网络层。网络层可以跨越不同的数据链路，即使是在不同的数据链路上也能实现两端节点之间的数据包传输。\n- **IP 大致分为三大作用模块，它们是 IP 寻址、路由（最终节点为止的转发）以及 IP 分包与组包。**\n\n#### IP 地址\n\n##### IP 地址概述\n\n- 在计算机通信中，为了识别通信对端，必须要有一个类似于地址的识别码进行标识。在数据链路中的 MAC 地址正是用来标识同一个链路中不同计算机的一种识别码。\n- 作为网络层的 IP ,也有这种地址信息，一般叫做 IP 地址。IP 地址用于在“连接到网络中的所有主机中识别出进行通信的目标地址”。因此，在 TCP/IP 通信中所有主机或路由器必须设定自己的 IP 地址。\n- 不论一台主机与哪种数据链路连接，其 IP 地址的形式都保持不变。\n- IP 地址（IPv4 地址）由32位正整数来表示。IP 地址在计算机内部以二进制方式被处理。然而，由于我们并不习惯于采用二进制方式，我们将32位的 IP 地址以每8位为一组，分成4组，每组以 “.” 隔开，再将每组数转换成十进制数。如下：\n\n| 28        | 28        | 28        | 28       |            |\n| --------- | --------- | --------- | -------- | ---------- |\n| 10101100  | 00010100  | 00000001  | 00000001 | （2进制）  |\n| 10101100. | 00010100. | 00000001. | 00000001 | （2进制）  |\n| 172.      | 20.       | 1.        | 1        | （10进制） |\n\n##### IP 地址由网络和主机两部分标识组成\n\n- 如下图，网络标识在数据链路的每个段配置不同的值。网络标识必须保证相互连接的每个段的地址不相重复。而相同段内相连的主机必须有相同的网络地址。IP 地址的“主机标识”则不允许在同一个网段内重复出现。由此，可以通过设置网络地址和主机地址，在相互连接的整个网络中保证每台主机的 IP 地址都不会相互重叠。即 IP 地址具有了唯一性。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-d653f38b146f5f9f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/728/format/webp)\n\nIP地址的主机标识\n\n- 如下图，IP 包被转发到途中某个路由器时，正是利用目标 IP 地址的网络标识进行路由。因为即使不看主机标识，只要一见到网络标识就能判断出是否为该网段内的主机。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-98e99ce9135f6eeb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/724/format/webp)\n\nIP地址的网络标识\n\n##### IP 地址的分类\n\n- **IP 地址分为四个级别，分别为A类、B类、C类、D类。它根据 IP 地址中从第 1 位到第 4 位的比特列对其网络标识和主机标识进行区分。**\n-  **A 类 IP 地址是首位以 “0” 开头的地址。**从第 1 位到第 8 位是它的网络标识。用十进制表示的话，0.0.0.0~127.0.0.0 是 A 类的网络地址。A 类地址的后 24 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为16,777,214个。\n-  **B 类 IP 地址是前两位 “10” 的地址。**从第 1 位到第 16 位是它的网络标识。用十进制表示的话，128.0.0.0~191.255.0.0 是 B 类的网络地址。B 类地址的后 16 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为65,534个。\n-  **C 类 IP 地址是前三位为 “110” 的地址。**从第 1 位到第 24 位是它的网络标识。用十进制表示的话，192.0.0.0~223.255.255.0 是 C 类的网络地址。C 类地址的后 8 位相当于主机标识。因此，一个网段内可容纳的主机地址上限为254个。\n-  **D 类 IP 地址是前四位为 “1110” 的地址。**从第 1 位到第 32 位是它的网络标识。用十进制表示的话，224.0.0.0~239.255.255.255 是 D 类的网络地址。D 类地址没有主机标识，常用于多播。\n- 在分配 IP 地址时关于主机标识有一点需要注意。即要用比特位表示主机地址时，不可以全部为 0 或全部为 1。因为全部为 0 只有在表示对应的网络地址或 IP 地址不可以获知的情况下才使用。而全部为 1 的主机通常作为广播地址。因此，在分配过程中，应该去掉这两种情况。这也是为什么 C 类地址每个网段最多只能有 254（ 28 - 2 = 254）个主机地址的原因。\n\n##### 广播地址\n\n- 广播地址用于在同一个链路中相互连接的主机之间发送数据包。将 IP 地址中的主机地址部分全部设置为 1，就成了广播地址。\n- 广播分为本地广播和直接广播两种。在本网络内的广播叫做本地广播；在不同网络之间的广播叫做直接广播。\n\n##### IP 多播\n\n- 多播用于将包发送给特定组内的所有主机。由于其直接使用 IP 地址，因此也不存在可靠传输。\n\n- 相比于广播，多播既可以穿透路由器，又可以实现只给那些必要的组发送数据包。请看下图：\n\n\n\n  ![img](https:////upload-images.jianshu.io/upload_images/1856419-18d212851da62909.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/547/format/webp)\n\n  IP 多播\n\n- 多播使用 D 类地址。因此，如果从首位开始到第 4 位是 “1110”，就可以认为是多播地址。而剩下的 28 位可以成为多播的组编号。\n\n- 此外， 对于多播，所有的主机（路由器以外的主机和终端主机）必须属于 224.0.0.1 的组，所有的路由器必须属于 224.0.0.2 的组。\n\n##### 子网掩码\n\n- 现在一个 IP 地址的网络标识和主机标识已不再受限于该地址的类别，而是由一个叫做“子网掩码”的识别码通过子网网络地址细分出比 A 类、B 类、C 类更小粒度的网络。这种方式实际上就是将原来 A 类、B 类、C 类等分类中的主机地址部分用作子网地址，可以将原网络分为多个物理网络的一种机制。\n- 子网掩码用二进制方式表示的话，也是一个 32 位的数字。它对应 IP 地址网络标识部分的位全部为 “1”，对应 IP 地址主机标识的部分则全部为 “0”。由此，一个 IP 地址可以不再受限于自己的类别，而是可以用这样的子网掩码自由地定位自己的网络标识长度。当然，子网掩码必须是 IP 地址的首位开始连续的 “1”。\n- 对于子网掩码，目前有两种表示方式。第一种是，将 IP 地址与子网掩码的地址分别用两行来表示。以 172.20.100.52 的前 26 位是网络地址的情况为例，如下：\n\n| IP 地址  | 172. | 20.  | 100. | 52   |\n| -------- | ---- | ---- | ---- | ---- |\n| 子网掩码 | 255. | 255. | 255. | 192  |\n|          |      |      |      |      |\n| 网络地址 | 172. | 20.  | 100. | 0    |\n| 子网掩码 | 255. | 255. | 255. | 192  |\n|          |      |      |      |      |\n| 广播地址 | 172. | 20.  | 100. | 63   |\n| 子网掩码 | 255. | 255. | 255. | 192  |\n\n- 第二种表示方式是，在每个 IP 地址后面追加网络地址的位数用 “/ ” 隔开，如下：\n\n| IP 地址  | 172. | 20.  | 100. | 52   | / 26 |\n| -------- | ---- | ---- | ---- | ---- | ---- |\n| 网络地址 | 172. | 20.  | 100. | 0    | / 26 |\n| 广播地址 | 172. | 20.  | 100. | 63   | / 26 |\n\n- 另外，在第二种方式下记述网络地址时可以省略后面的 “0” 。例如：172.20.0.0/26 跟 172.20/26 其实是一个意思。\n\n#### 路由\n\n- 发送数据包时所使用的地址是网络层的地址，即 IP 地址。然而仅仅有 IP 地址还不足以实现将数据包发送到对端目标地址，在数据发送过程中还需要类似于“指明路由器或主机”的信息，以便真正发往目标地址。保存这种信息的就是路由控制表。\n- 该路由控制表的形成方式有两种：一种是管理员手动设置，另一种是路由器与其他路由器相互交换信息时自动刷新。前者也叫做静态路由控制，而后者叫做动态路由控制。\n- IP 协议始终认为路由表是正确的。然后，IP 本身并没有定义制作路由控制表的协议。即 IP 没有制作路由控制表的机制。该表示由一个叫做“路由协议”的协议制作而成。\n\n##### IP 地址与路由控制\n\n- IP 地址的网络地址部分用于进行路由控制。\n- 路由控制表中记录着网络地址与下一步应该发送至路由器的地址。\n- 在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择一个最为吻合的网络地址。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-cd4c3759c61abb38.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/730/format/webp)\n\n路由控制表与 IP 包发送\n\n#### IP 分包与组包\n\n- 每种数据链路的最大传输单元（MTU）都不尽相同，因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。\n- 任何一台主机都有必要对 IP 分片进行相应的处理。分片往往在网络上遇到比较大的报文无法一下子发送出去时才会进行处理。\n- 经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行。路由器虽然做分片但不会进行重组。\n\n##### 路径 MTU 发现\n\n- 分片机制也有它的不足。如路由器的处理负荷加重之类。因此，只要允许，是不希望由路由器进行 IP 数据包的分片处理的。\n- 为了应对分片机制的不足，“路径 MTU 发现” 技术应运而生。路径 MTU 指的是，从发送端主机到接收端主机之间不需要分片是最大 MTU 的大小。即路径中存在的所有数据链路中最小的 MTU 。\n- 进行路径 MTU 发现，就可以避免在中途的路由器上进行分片处理，也可以在 TCP 中发送更大的包。\n\n#### IPv6\n\n- IPv6（IP version 6）是为了根本解决 IPv4 地址耗尽的问题而被标准化的网际协议。IPv4 的地址长度为 4 个 8 位字节，即 32 比特。而 IPv6 的地址长度则是原来的 4 倍，即 128 比特，一般写成 8 个 16 位字节。\n\n##### IPv6 的特点\n\n- IP 得知的扩大与路由控制表的聚合。\n- 性能提升。包首部长度采用固定的值（40字节），不再采用首部检验码。简化首部结构，减轻路由器负担。路由器不再做分片处理。\n- 支持即插即用功能。即使没有DHCP服务器也可以实现自动分配 IP 地址。\n- 采用认证与加密功能。应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能。\n- 多播、Mobile IP 成为扩展功能。\n\n##### IPv6 中 IP 地址的标记方法\n\n- 一般人们将 128 比特 IP 地址以每 16 比特为一组，每组用冒号（“：”）隔开进行标记。\n- 而且如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号（“：：”）隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号。\n\n##### IPv6 地址的结构\n\n- IPv6 类似 IPv4，也是通过 IP 地址的前几位标识 IP 地址的种类。\n- 在互联网通信中，使用一种全局的单播地址。它是互联网中唯一的一个地址，不需要正式分配 IP 地址。\n\n| 未定义           | 0000 ... 0000（128比特） | ：：/ 128    |\n| ---------------- | ------------------------ | ------------ |\n| 环回地址         | 0000 ... 0001（128比特） | ：：1 / 128  |\n| 唯一本地地址     | 1111 110                 | FC00：/ 7    |\n| 链路本地单播地址 | 1111 1110 10             | FE80：：/ 10 |\n| 多播地址         | 1111 1111                | FF00：：/ 8  |\n| 全局单播地址     | （其他）                 |              |\n\n##### 全局单播地址\n\n- 全局单播地址是指世界上唯一的一个地址。它是互联网通信以及各个域内部通信中最为常用的一个 IPv6 地址。\n- 格式如下图所示，现在 IPv6 的网络中所使用的格式为，n = 48，m = 16 以及 128 - n - m = 64。即前 64 比特为网络标识，后 64 比特为主机标识。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-3cd8f2d1fae94dcf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/785/format/webp)\n\n全局单播地址\n\n##### 链路本地单播地址\n\n- 链路本地单播地址是指在同一个数据链路内唯一的地址。它用于不经过路由器，在同一个链路中的通信。通常接口 ID 保存 64 比特版的 MAC 地址。\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-dca23d5bfda77579.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/772/format/webp)\n\n链路本地单播地址\n\n##### 唯一本地地址\n\n- 唯一本地地址是不进行互联网通信时所用的地址。\n- 唯一本地地址虽然不会与互联网连接，但是也会尽可能地随机生成一个唯一的全局 ID。\n- L 通常被置为 1\n- 全局 ID 的值随机决定\n- 子网 ID 是指该域子网地址\n- 接口 ID 即为接口的 ID\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-baee1dd0cd9d16a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/820/format/webp)\n\n唯一本地地址\n\n##### IPv6 分段处理\n\n- IPv6 的分片处理只在作为起点的发送端主机上进行，路由器不参与分片。\n- IPv6 中最小 MTU 为 1280 字节，因此，在嵌入式系统中对于那些有一定系统资源限制的设备来说，不需要进行“路径 MTU 发现”，而是在发送 IP 包时直接以 1280 字节为单位分片送出。\n\n##### IP 首部（暂略）\n\n#### IP 协议相关技术\n\n- IP 旨在让最终目标主机收到数据包，但是在这一过程中仅仅有 IP 是无法实现通信的。必须还有能够解析主机名称和 MAC 地址的功能，以及数据包在发送过程中异常情况处理的功能。\n\n##### DNS\n\n- 我们平常在访问某个网站时不适用 IP 地址，而是用一串由罗马字和点号组成的字符串。而一般用户在使用 TCP/IP 进行通信时也不使用 IP 地址。能够这样做是因为有了 DNS （Domain Name System）功能的支持。DNS 可以将那串字符串自动转换为具体的 IP 地址。\n- 这种 DNS 不仅适用于 IPv4，还适用于 IPv6。\n\n##### ARP\n\n- 只要确定了 IP 地址，就可以向这个目标地址发送 IP 数据报。然而，在底层数据链路层，进行实际通信时却有必要了解每个 IP 地址所对应的 MAC 地址。\n- ARP 是一种解决地址问题的协议。以目标 IP 地址为线索，用来定位下一个应该接收数据分包的网络设备对应的 MAC 地址。不过 ARP 只适用于 IPv4，不能用于 IPv6。IPv6 中可以用 ICMPv6 替代 ARP 发送邻居探索消息。\n- RARP 是将 ARP 反过来，从 MAC 地址定位 IP 地址的一种协议。\n\n##### 5.3 ICMP\n\n- ICMP 的主要功能包括，确认 IP 包是否成功送达目标地址，通知在发送过程当中 IP 包被废弃的具体原因，改善网络设置等。\n- IPv4 中 ICMP 仅作为一个辅助作用支持 IPv4。也就是说，在 IPv4 时期，即使没有 ICMP，仍然可以实现 IP 通信。然而，在 IPv6 中，ICMP 的作用被扩大，如果没有 ICMPv6，IPv6 就无法进行正常通信。\n\n##### DHCP\n\n- 如果逐一为每一台主机设置 IP 地址会是非常繁琐的事情。特别是在移动使用笔记本电脑、只能终端以及平板电脑等设备时，每移动到一个新的地方，都要重新设置 IP 地址。\n- 于是，为了实现自动设置 IP 地址、统一管理 IP 地址分配，就产生了 DHCP（Dynamic Host Configuration Protocol）协议。有了 DHCP，计算机只要连接到网络，就可以进行 TCP/IP 通信。也就是说，DHCP 让即插即用变得可能。\n- DHCP 不仅在 IPv4 中，在 IPv6 中也可以使用。\n\n##### NAT\n\n- NAT（Network Address Translator）是用于在本地网络中使用私有地址，在连接互联网时转而使用全局 IP 地址的技术。\n- 除转换 IP 地址外，还出现了可以转换 TCP、UDP 端口号的 NAPT（Network Address Ports Translator）技术，由此可以实现用一个全局 IP 地址与多个主机的通信。\n- NAT（NAPT）实际上是为正在面临地址枯竭的 IPv4 而开发的技术。不过，在 IPv6 中为了提高网络安全也在使用 NAT，在 IPv4 和 IPv6 之间的相互通信当中常常使用 NAT-PT。\n\n##### IP 隧道\n\n\n\n![img](https:////upload-images.jianshu.io/upload_images/1856419-d45032d360259d59.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/641/format/webp)\n\n夹着 IPv4 网络的两个 IPv6 网络\n\n- 如上图的网络环境中，网络 A 与网络 B 之间无法直接进行通信，为了让它们之间正常通信，这时必须得采用 IP 隧道的功能。\n- IP 隧道可以将那些从网络 A 发过来的 IPv6 的包统合为一个数据，再为之追加一个 IPv4 的首部以后转发给网络 C。\n- 一般情况下，紧接着 IP 首部的是 TCP 或 UDP 的首部。然而，现在的应用当中“ IP 首部的后面还是 IP 首部”或者“ IP 首部的后面是 IPv6 的首部”等情况与日俱增。这种在网络层的首部后面追加网络层首部的通信方法就叫做“ IP 隧道”。\n\n","tags":["TCP/IP"],"categories":["others"]},{"title":"详解http协议","url":"/2018/12/05/详解http协议/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nhttp网络协议的详解概述\n\n<!-- more -->\n\n[TOC]\n\n![一张图带你看完本篇文章](https://github.com/AlexBruceLu/DAPP/wiki/http3.webp)\n\n### 概述\n\n#### 计算机网络体系结构分层\n\n![计算机网络体系结构分层](https://github.com/AlexBruceLu/DAPP/wiki/http2.webp)\n\n#### TCP/IP 通信传输流\n\n利用 TCP/IP 协议族进行网络通信时，会通过分层顺序与对方进行通信。发送端从应用层往下走，接收端则从链路层往上走。如下：\n\n![TCP/IP 通信传输流](https://github.com/AlexBruceLu/DAPP/wiki/http4.webp)\n\n- 首先作为发送端的客户端在应用层（HTTP 协议）发出一个想看某个 Web 页面的 HTTP 请求。\n- 接着，为了传输方便，在传输层（TCP 协议）把从应用层处收到的数据（HTTP 请求报文）进行分割，并在各个报文上打上标记序号及端口号后转发给网络层。\n- 在网络层（IP 协议），增加作为通信目的地的 MAC 地址后转发给链路层。这样一来，发往网络的通信请求就准备齐全了。\n- 接收端的服务器在链路层接收到数据，按序往上层发送，一直到应用层。当传输到应用层，才能算真正接收到由客户端发送过来的 HTTP请求。\n\n如下图所示：\n\n![HTTP 请求](https://github.com/AlexBruceLu/DAPP/wiki/http5.webp)\n\n在网络体系结构中，包含了众多的网络协议，这篇文章主要围绕 HTTP 协议（HTTP/1.1版本）展开。\n\n> HTTP协议（HyperText Transfer Protocol，超文本传输协议）是用于从WWW服务器传输超文本到本地浏览器的传输协议。它可以使浏览器更加高效，使网络传输减少。它不仅保证计算机正确快速地传输超文本文档，还确定传输文档中的哪一部分，以及哪部分内容首先显示(如文本先于图形)等。\n>  HTTP是客户端浏览器或其他程序与Web服务器之间的应用层通信协议。在Internet上的Web服务器上存放的都是超文本信息，客户机需要通过HTTP协议传输所要访问的超文本信息。HTTP包含命令和传输信息，不仅可用于Web访问，也可以用于其他因特网/内联网应用系统之间的通信，从而实现各类应用资源超媒体访问的集成。\n>  我们在浏览器的地址栏里输入的网站地址叫做URL (Uniform Resource Locator，统一资源定位符)。就像每家每户都有一个门牌地址一样，每个网页也都有一个Internet地址。当你在浏览器的地址框中输入一个URL或是单击一个超级链接时，URL就确定了要浏览的地址。浏览器通过超文本传输协议(HTTP)，将Web服务器上站点的网页代码提取出来，并翻译成漂亮的网页。\n\n### HTTP 工作过程\n\n![HTTP请求响应模型](https://github.com/AlexBruceLu/DAPP/wiki/http6.webp)\n\nHTTP通信机制是在一次完整的 HTTP 通信过程中，客户端与服务器之间将完成下列7个步骤：\n\n#### **建立 TCP 连接**\n\n在HTTP工作开始之前，客户端首先要通过网络与服务器建立连接，该连接是通过 TCP 来完成的，该协议与 IP 协议共同构建 Internet，即著名的 TCP/IP 协议族，因此 Internet 又被称作是 TCP/IP 网络。HTTP 是比 TCP 更高层次的应用层协议，根据规则，只有低层协议建立之后，才能进行高层协议的连接，因此，首先要建立 TCP 连接，一般 TCP 连接的端口号是80；\n\n#### **客户端向服务器发送请求命令**\n\n 一旦建立了TCP连接，客户端就会向服务器发送请求命令；\n 例如：`GET/sample/hello.jsp HTTP/1.1` \n\n#### **客户端发送请求头信息**\n\n 客户端发送其请求命令之后，还要以头信息的形式向服务器发送一些别的信息，之后客户端发送了一空白行来通知服务器，它已经结束了该头信息的发送；\n\n#### **服务器应答**\n\n 客户端向服务器发出请求后，服务器会客户端返回响应；\n 例如： `HTTP/1.1 200 OK`\n 响应的第一部分是协议的版本号和响应状态码\n\n#### **服务器返回响应头信息**\n\n 正如客户端会随同请求发送关于自身的信息一样，服务器也会随同响应向用户发送关于它自己的数据及被请求的文档；\n\n#### **服务器向客户端发送数据**\n\n 服务器向客户端发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以 Content-Type 响应头信息所描述的格式发送用户所请求的实际数据；\n\n#### **服务器关闭 TCP 连接**\n\n 一般情况下，一旦服务器向客户端返回了请求数据，它就要关闭 TCP 连接，然后如果客户端或者服务器在其头信息加入了这行代码 `Connection:keep-alive` ，TCP 连接在发送后将仍然保持打开状态，于是，客户端可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。\n\n### HTTP 协议基础\n\n#### 通过请求和响应的交换达成通信\n\n应用 HTTP 协议时，必定是一端担任客户端角色，另一端担任服务器端角色。仅从一条通信线路来说，服务器端和客服端的角色是确定的。HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。**换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。**\n\n#### HTTP 是不保存状态的协议\n\nHTTP 是一种无状态协议。协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。\n可是随着 Web 的不断发展，我们的很多业务都需要对通信状态进行保存。于是我们引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。\n\n#### 使用 Cookie 的状态管理\n\nCookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。\n\n![Cookie 的流程](https://github.com/AlexBruceLu/DAPP/wiki/http7.webp)\n\n#### 请求 URI 定位资源\n\nHTTP 协议使用 URI 定位互联网上的资源。正是因为 URI 的特定功能，在互联网上任意位置的资源都能访问到。\n\n#### 告知服务器意图的 HTTP 方法（HTTP/1.1）\n\n![HTTP 方法](https://github.com/AlexBruceLu/DAPP/wiki/http8.webp)\n\n#### 持久连接\n\nHTTP 协议的初始版本中，每进行一个 HTTP 通信都要断开一次 TCP 连接。比如使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求访问 HTML 页面资源的同时，也会请求该 HTML 页面里包含的其他资源。因此，每次的请求都会造成无畏的 TCP 连接建立和断开，增加通信量的开销。\n 为了解决上述 TCP 连接的问题，HTTP/1.1 和部分 HTTP/1.0 想出了持久连接的方法。**其特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。旨在建立一次 TCP 连接后进行多次请求和响应的交互。**在 HTTP/1.1 中，所有的连接默认都是持久连接。\n\n#### 管线化\n\n持久连接使得多数请求以管线化方式发送成为可能。以前发送请求后需等待并接收到响应，才能发送下一个请求。管线化技术出现后，不用等待亦可发送下一个请求。这样就能做到同时并行发送多个请求，而不需要一个接一个地等待响应了。\n 比如，当请求一个包含多张图片的 HTML 页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术要比持久连接速度更快。请求数越多，时间差就越明显。\n\n### HTTP 协议报文结构\n\n#### HTTP 报文\n\n用于 HTTP 协议交互的信息被称为 HTTP 报文。请求端（客户端）的 HTTP 报文叫做请求报文；响应端（服务器端）的叫做响应报文。HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。\n\n#### HTTP 报文结构\n\nHTTP 报文大致可分为报文首部和报文主体两部分。两者由最初出现的空行（CR+LF）来划分。通常，并不一定有报文主体。如下：\n\n![HTTP 报文结构](https://github.com/AlexBruceLu/DAPP/wiki/http.webp)\n\n![HTTP 报文结构](https://github.com/AlexBruceLu/DAPP/wiki/http901.webp)\n\n##### 请求报文结构\n\n![请求报文结构](https://github.com/AlexBruceLu/DAPP/wiki/http10.webp)\n\n请求报文的首部内容由以下数据组成：\n\n- **请求行** —— 包含用于请求的方法、请求 URI 和 HTTP 版本。\n- **首部字段** —— 包含表示请求的各种条件和属性的各类首部。（通用首部、请求首部、实体首部以及RFC里未定义的首部如 Cookie 等）\n\n请求报文的示例，如下：\n\n![请求报文示例](https://github.com/AlexBruceLu/DAPP/wiki/http11.webp)\n\n##### 响应报文结构\n\n![响应报文结构](https://github.com/AlexBruceLu/DAPP/wiki/http12.webp)\n\n响应报文的首部内容由以下数据组成：\n\n- **状态行** —— 包含表明响应结果的状态码、原因短语和 HTTP 版本。\n- **首部字段** —— 包含表示请求的各种条件和属性的各类首部。（通用首部、响应首部、实体首部以及RFC里未定义的首部如 Cookie 等）\n\n响应报文的示例，如下：\n\n![响应报文结构](https://github.com/AlexBruceLu/DAPP/wiki/http13.webp)\n\n### HTTP 报文首部之请求行、状态行\n\n#### 请求行\n\n举个栗子，下面是一个 HTTP 请求的报文：\n\n```bash\nGET  /index.htm  HTTP/1.1\nHost: sample.com\n```\n\n其中，下面的这行就是请求行，\n\n```shell\nGET  /index.htm  HTTP/1.1\n```\n\n- 开头的 GET 表示请求访问服务器的类型，称为方法；\n- 随后的字符串  `/index.htm` 指明了请求访问的资源对象，也叫做请求 URI；\n- 最后的 `HTTP/1.1`，即 HTTP 的版本号，用来提示客户端使用的 HTTP 协议功能。\n\n综合来看，大意是请求访问某台 HTTP 服务器上的 `/index.htm` 页面资源。\n\n#### 状态行\n\n同样举个栗子，下面是一个 HTTP 响应的报文：\n\n```bash\nHTTP/1.1  200  OK\nDate: Mon, 10 Jul 2017 15:50:06 GMT\nContent-Length: 256\nContent-Type: text/html\n    \n<html>\n...\n```\n\n其中，下面的这行就是状态行，\n\n```bash\nHTTP/1.1  200  OK\n```\n\n- 开头的 `HTTP/1.1` 表示服务器对应的 HTTP 版本；\n- 紧挨着的 `200 OK` 表示请求的处理结果的状态码和原因短语。\n\n### HTTP 报文首部之首部字段（重点分析）\n\n#### 首部字段概述\n\n先来回顾一下首部字段在报文的位置，HTTP 报文包含报文首部和报文主体，报文首部包含请求行（或状态行）和首部字段。\n 在报文众多的字段当中，HTTP 首部字段包含的信息最为丰富。首部字段同时存在于请求和响应报文内，并涵盖 HTTP 报文相关的内容信息。使用首部字段是为了给客服端和服务器端提供报文主体大小、所使用的语言、认证信息等内容。\n\n#### 首部字段结构\n\n- HTTP 首部字段是由首部字段名和字段值构成的，中间用冒号“：”分隔。\n- 另外，字段值对应单个 HTTP 首部字段可以有多个值。\n- 当 HTTP 报文首部中出现了两个或以上具有相同首部字段名的首部字段时，这种情况在规范内尚未明确，根据浏览器内部处理逻辑的不同，优先处理的顺序可能不同，结果可能并不一致。\n\n| 首部字段名   | 冒号 | 字段值              |\n| ------------ | ---- | ------------------- |\n| Content-Type | ：   | text/html           |\n| Keep-Alive   | ：   | timeout=30, max=120 |\n\n#### 首部字段类型\n\n首部字段根据实际用途被分为以下4种类型：\n\n| 类型         | 描述                                                         |\n| ------------ | ------------------------------------------------------------ |\n| 通用首部字段 | 请求报文和响应报文两方都会使用的首部                         |\n| 请求首部字段 | 从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息 |\n| 响应首部字段 | 从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。 |\n| 实体首部字段 | 针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的的信息。 |\n\n#### 通用首部字段（HTTP/1.1）\n\n| 首部字段名        | 说明                       |\n| ----------------- | -------------------------- |\n| Cache-Control     | 控制缓存的行为             |\n| Connection        | 逐挑首部、连接的管理       |\n| Date              | 创建报文的日期时间         |\n| Pragma            | 报文指令                   |\n| Trailer           | 报文末端的首部一览         |\n| Transfer-Encoding | 指定报文主体的传输编码方式 |\n| Upgrade           | 升级为其他协议             |\n| Via               | 代理服务器的相关信息       |\n| Warning           | 错误通知                   |\n\n##### Cache-Control\n\n通过指定首部字段 Cache-Control 的指令，就能操作缓存的工作机制。\n\n##### 可用的指令一览\n\n可用的指令按请求和响应分类如下：\n\n##### **缓存请求指令**\n\n| 指令              | 参数   | 说明                         |\n| ----------------- | ------ | ---------------------------- |\n| no-cache          | 无     | 强制向服务器再次验证         |\n| no-store          | 无     | 不缓存请求或响应的任何内容   |\n| max-age = [秒]    | 必需   | 响应的最大Age值              |\n| max-stale( =[秒]) | 可省略 | 接收已过期的响应             |\n| min-fresh = [秒]  | 必需   | 期望在指定时间内的响应仍有效 |\n| no-transform      | 无     | 代理不可更改媒体类型         |\n| only-if-cached    | 无     | 从缓存获取资源               |\n| cache-extension   | -      | 新指令标记（token）          |\n\n##### **缓存响应指令**\n\n| 指令             | 参数   | 说明                                           |\n| ---------------- | ------ | ---------------------------------------------- |\n| public           | 无     | 可向任意方提供响应的缓存                       |\n| private          | 可省略 | 仅向特定用户返回响应                           |\n| no-cache         | 可省略 | 缓存前必须先确认其有效性                       |\n| no-store         | 无     | 不缓存请求或响应的任何内容                     |\n| no-transform     | 无     | 代理不可更改媒体类型                           |\n| must-revalidate  | 无     | 可缓存但必须再向源服务器进行确认               |\n| proxy-revalidate | 无     | 要求中间缓存服务器对缓存的响应有效性再进行确认 |\n| max-age = [秒]   | 必需   | 响应的最大Age值                                |\n| s-maxage = [秒]  | 必需   | 公共缓存服务器响应的最大Age值                  |\n| cache-extension  | -      | 新指令标记（token）                            |\n\n##### **表示能否缓存的指令**\n\n**public 指令**\n `Cache-Control: public`\n 当指定使用 public 指令时，则明确表明其他用户也可利用缓存。\n\n**private 指令**\n `Cache-Control: private`\n 当指定 private 指令后，响应只以特定的用户作为对象，这与 public 指令的行为相反。缓存服务器会对该特定用户提供资源缓存的服务，对于其他用户发送过来的请求，代理服务器则不会返回缓存。\n\n**no-cache 指令**\n `Cache-Control: no-cache`\n\n- 使用 no-cache 指令是为了防止从缓存中返回过期的资源。\n- 客户端发送的请求中如果包含 no-cache 指令，则表示客户端将不会接收缓存过的响应。于是，“中间”的缓存服务器必须把客户端请求转发给源服务器。\n- 如果服务器中返回的响应包含 no-cache 指令，那么缓存服务器不能对资源进行缓存。源服务器以后也将不再对缓存服务器请求中提出的资源有效性进行确认，且禁止其对响应资源进行缓存操作。\n\n`Cache-Control: no-cache=Location`\n 由服务器返回的响应中，若报文首部字段 Cache-Control 中对 no-cache 字段名具体指定参数值，那么客户端在接收到这个被指定参数值的首部字段对应的响应报文后，就不能使用缓存。换言之，无参数值的首部字段可以使用缓存。只能在响应指令中指定该参数。\n\n**no-store 指令**\n `Cache-Control: no-store`\n 当使用 no-store 指令时，暗示请求（和对应的响应）或响应中包含机密信息。因此，该指令规定缓存不能在本地存储请求或响应的任一部分。\n 注意：no-cache 指令代表不缓存过期的指令，缓存会向源服务器进行有效期确认后处理资源；no-store 指令才是真正的不进行缓存。\n\n###### 指定缓存期限和认证的指令\n\n**s-maxage 指令**\n `Cache-Control: s-maxage=604800（单位：秒）`\n\n- s-maxage 指令的功能和 max-age 指令的相同，它们的不同点是 s-maxage 指令只适用于供多位用户使用的公共缓存服务器（一般指代理）。也就是说，对于向同一用户重复返回响应的服务器来说，这个指令没有任何作用。\n- 另外，当使用 s-maxage 指令后，则直接忽略对 Expires 首部字段及 max-age 指令的处理。\n\n**max-age 指令**\n `Cache-Control: max-age=604800（单位：秒）`\n\n- 当客户端发送的请求中包含 max-age 指令时，如果判定缓存资源的缓存时间数值比指定的时间更小，那么客户端就接收缓存的资源。另外，当指定 max-age 的值为0，那么缓存服务器通常需要将请求转发给源服务器。\n- 当服务器返回的响应中包含 max-age 指令时，缓存服务器将不对资源的有效性再作确认，而 max-age 数值代表资源保存为缓存的最长时间。\n- 应用 HTTP/1.1 版本的缓存服务器遇到同时存在 Expires 首部字段的情况时，会优先处理 max-age 指令，并忽略掉 Expires 首部字段；而 HTTP/1.0 版本的缓存服务器则相反。\n\n**min-fresh 指令**\n `Cache-Control: min-fresh=60（单位：秒）`\n min-fresh 指令要求缓存服务器返回至少还未过指定时间的缓存资源。\n\n**max-stale 指令**\n `Cache-Control: max-stale=3600（单位：秒）`\n\n- 使用 max-stale 可指示缓存资源，即使过期也照常接收。\n- 如果指令未指定参数值，那么无论经过多久，客户端都会接收响应；如果指定了具体参数值，那么即使过期，只要仍处于 max-stale 指定的时间内，仍旧会被客户端接收。\n\n**only-if-cached 指令**\n `Cache-Control: only-if-cached`\n 表示客户端仅在缓存服务器本地缓存目标资源的情况下才会要求其返回。换言之，该指令要求缓存服务器不重新加载响应，也不会再次确认资源的有效性。\n\n**must-revalidate 指令**\n `Cache-Control: must-revalidate`\n 使用 must-revalidate 指令，代理会向源服务器再次验证即将返回的响应缓存目前是否仍有效。另外，使用 must-revalidate 指令会忽略请求的 max-stale 指令。\n\n**proxy-revalidate 指令**\n `Cache-Control: proxy-revalidate`\n proxy-revalidate 指令要求所有的缓存服务器在接收到客户端带有该指令的请求返回响应之前，必须再次验证缓存的有效性。\n\n**no-transform 指令**\n `Cache-Control: no-transform`\n 使用 no-transform 指令规定无论是在请求还是响应中，缓存都不能改变实体主体的媒体类型。这样做可防止缓存或代理压缩图片等类似操作。\n\n###### Cache-Control 扩展\n\n`Cache-Control: private, community=\"UCI\"`\n 通过 cache-extension 标记（token），可以扩展 Cache-Control 首部字段内的指令。上述 community 指令即扩展的指令，如果缓存服务器不能理解这个新指令，就会直接忽略掉。\n\n##### Connection\n\nConnection 首部字段具备以下两个作用：\n\n**控制不再转发的首部字段**\n `Connection: Upgrade`\n 在客户端发送请求和服务器返回响应中，使用 Connection 首部字段，可控制不再转发给代理的首部字段，即删除后再转发（即Hop-by-hop首部）。\n\n**管理持久连接**\n `Connection: close`\n HTTP/1.1 版本的默认连接都是持久连接。当服务器端想明确断开连接时，则指定 Connection 首部字段的值为 close。\n `Connection: Keep-Alive`\n HTTP/1.1 之前的 HTTP 版本的默认连接都是非持久连接。为此，如果想在旧版本的 HTTP 协议上维持持续连接，则需要指定 Connection 首部字段的值为 Keep-Alive。\n\n##### Date\n\n表明创建 HTTP 报文的日期和时间。\n `Date: Mon, 10 Jul 2017 15:50:06 GMT`\n HTTP/1.1 协议使用在 RFC1123 中规定的日期时间的格式。\n\n##### Pragma\n\nPragma 首部字段是 HTTP/1.1 版本之前的历史遗留字段，仅作为与 HTTP/1.0 的向后兼容而定义。\n `Pragma: no-cache`\n\n- 该首部字段属于通用首部字段，但只用在客户端发送的请求中，要求所有的中间服务器不返回缓存的资源。\n- 所有的中间服务器如果都能以 HTTP/1.1 为基准，那直接采用 `Cache-Control: no-cache` 指定缓存的处理方式最为理想。但是要整体掌握所有中间服务器使用的 HTTP 协议版本却是不现实的，所以，发送的请求会同时包含下面两个首部字段：\n\n```\nCache-Control: no-cache\nPragma: no-cache\n```\n\n##### Trailer\n\n`Trailer: Expires`\n 首部字段 Trailer 会事先说明在报文主体后记录了哪些首部字段。可应用在 HTTP/1.1 版本分块传输编码时。\n\n##### Transfer-Encoding\n\n```\nTransfer-Encoding: chunked\n```\n\n- 规定了传输报文主体时采用的编码方式。\n- HTTP/1.1 的传输编码方式仅对分块传输编码有效。\n\n##### Upgrade\n\n`Upgrade: TSL/1.0`\n 用于检测 HTTP 协议及其他协议是否可使用更高的版本进行通信，其参数值可以用来指定一个完全不同的通信协议。\n\n##### Via\n\n```\nVia: 1.1 a1.sample.com(Squid/2.7)\n```\n\n- 为了追踪客户端和服务器端之间的请求和响应报文的传输路径。\n- 报文经过代理或网关时，会现在首部字段 Via 中附加该服务器的信息，然后再进行转发。\n- 首部字段 Via 不仅用于追踪报文的转发，还可避免请求回环的发生。\n\n##### Warning\n\n该首部字段通常会告知用户一些与缓存相关的问题的警告。\n Warning 首部字段的格式如下：\n `Warning：[警告码][警告的主机:端口号] \"[警告内容]\"([日期时间])`\n 最后的日期时间可省略。\n HTTP/1.1 中定义了7种警告，警告码对应的警告内容仅推荐参考，另外，警告码具备扩展性，今后有可能追加新的警告码。\n\n| 警告码 | 警告内容                                       | 说明                                                         |\n| ------ | ---------------------------------------------- | ------------------------------------------------------------ |\n| 110    | Response is stale(响应已过期)                  | 代理返回已过期的资源                                         |\n| 111    | Revalidation failed(再验证失败)                | 代理再验证资源有效性时失败（服务器无法到达等原因）           |\n| 112    | Disconnection operation(断开连接操作)          | 代理与互联网连接被故意切断                                   |\n| 113    | Heuristic expiration(试探性过期)               | 响应的试用期超过24小时(有效缓存的设定时间大于24小时的情况下) |\n| 199    | Miscellaneous warning(杂项警告)                | 任意的警告内容                                               |\n| 214    | Transformation applied(使用了转换)             | 代理对内容编码或媒体类型等执行了某些处理时                   |\n| 299    | Miscellaneous persistent warning(持久杂项警告) | 任意的警告内容                                               |\n\n#### 请求首部字段（HTTP/1.1）\n\n| 首部字段名          | 说明                                          |\n| ------------------- | --------------------------------------------- |\n| Accept              | 用户代理可处理的媒体类型                      |\n| Accept-Charset      | 优先的字符集                                  |\n| Accept-Encoding     | 优先的内容编码                                |\n| Accept-Language     | 优先的语言（自然语言）                        |\n| Authorization       | Web认证信息                                   |\n| Expect              | 期待服务器的特定行为                          |\n| From                | 用户的电子邮箱地址                            |\n| Host                | 请求资源所在服务器                            |\n| If-Match            | 比较实体标记（ETag）                          |\n| If-Modified-Since   | 比较资源的更新时间                            |\n| If-None-Match       | 比较实体标记（与 If-Macth 相反）              |\n| If-Range            | 资源未更新时发送实体 Byte 的范围请求          |\n| If-Unmodified-Since | 比较资源的更新时间(与 If-Modified-Since 相反) |\n| Max-Forwards        | 最大传输逐跳数                                |\n| Proxy-Authorization | 代理服务器要求客户端的认证信息                |\n| Range               | 实体的字节范围请求                            |\n| Referer             | 对请求中 URI 的原始获取方                     |\n| TE                  | 传输编码的优先级                              |\n| User-Agent          | HTTP 客户端程序的信息                         |\n\n##### Accept\n\n```\nAccept: text/html, application/xhtml+xml, application/xml; q=0.5\n```\n\n- Accept 首部字段可通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级。可使用 type/subtype 这种形式，一次指定多种媒体类型。\n- 若想要给显示的媒体类型增加优先级，则使用 `q=[数值]` 来表示权重值，用分号（;）进行分隔。权重值的范围 0~1（可精确到小数点后三位），且 1 为最大值。不指定权重值时，默认为 1。\n\n##### Accept-Charset\n\n`Accept-Charset: iso-8859-5, unicode-1-1; q=0.8`\n Accept-Charset 首部字段可用来通知服务器用户代理支持的字符集及字符集的相对优先顺序。另外，可一次性指定多种字符集。同样使用 `q=[数值]` 来表示相对优先级。\n\n##### Accept-Encoding\n\n`Accept-Encoding: gzip, deflate`\n Accept-Encoding 首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先顺序，并可一次性指定多种内容编码。同样使用 `q=[数值]` 来表示相对优先级。也可使用星号（*）作为通配符，指定任意的编码格式。\n\n##### Accept-Language\n\n`Accept-Lanuage: zh-cn,zh;q=0.7,en=us,en;q=0.3`\n 告知服务器用户代理能够处理的自然语言集（指中文或英文等），以及自然语言集的相对优先级，可一次性指定多种自然语言集。同样使用 `q=[数值]` 来表示相对优先级。\n\n##### Authorization\n\n`Authorization: Basic ldfKDHKfkDdasSAEdasd==`\n 告知服务器用户代理的认证信息（证书值）。通常，想要通过服务器认证的用户代理会在接收到返回的 401 状态码响应后，把首部字段 Authorization 加入请求中。共用缓存在接收到含有 Authorization 首部字段的请求时的操作处理会略有差异。\n\n##### Expect\n\n`Expect: 100-continue`\n 告知服务器客户端期望出现的某种特定行为。\n\n##### 5.7 From\n\n`From: Deeson_Woo@163.com`\n 告知服务器使用用户代理的电子邮件地址。\n\n##### Host\n\n```\nHost: www.jianshu.com\n```\n\n- 告知服务器，请求的资源所处的互联网主机和端口号。\n- **Host 首部字段是 HTTP/1.1 规范内唯一一个必须被包含在请求内的首部字段。**\n- 若服务器未设定主机名，那直接发送一个空值即可  `Host:` 。\n\n##### If-Match\n\n形如 If-xxx 这种样式的请求首部字段，都可称为条件请求。服务器接收到附带条件的请求后，只有判断指定条件为真时，才会执行请求。\n\n```\nIf-Match: \"123456\"\n```\n\n- 首部字段 If-Match，属附带条件之一，它会告知服务器匹配资源所用的实体标记（ETag）值。这时的服务器无法使用弱 ETag 值。\n- 服务器会比对 If-Match 的字段值和资源的 ETag 值，仅当两者一致时，才会执行请求。反之，则返回状态码 `412 Precondition Failed` 的响应。\n- 还可以使用星号（*）指定 If-Match 的字段值。针对这种情况，服务器将会忽略 ETag 的值，只要资源存在就处理请求。\n\n##### If-Modified-Since\n\n```\nIf-Modified-Since: Mon, 10 Jul 2017 15:50:06 GMT\n```\n\n- 首部字段 If-Modified-Since，属附带条件之一，用于确认代理或客户端拥有的本地资源的有效性。\n- 它会告知服务器若 If-Modified-Since 字段值早于资源的更新时间，则希望能处理该请求。而在指定 If-Modified-Since 字段值的日期时间之后，如果请求的资源都没有过更新，则返回状态码 `304 Not Modified` 的响应。\n\n##### If-None-Match\n\n`If-None-Match: \"123456\"`\n 首部字段 If-None-Match 属于附带条件之一。它和首部字段 If-Match 作用相反。用于指定 If-None-Match 字段值的实体标记（ETag）值与请求资源的 ETag 不一致时，它就告知服务器处理该请求。\n\n##### If-Range\n\n```\nIf-Range: \"123456\"\n```\n\n- 首部字段 If-Range 属于附带条件之一。它告知服务器若指定的 If-Range 字段值（ETag 值或者时间）和请求资源的 ETag 值或时间相一致时，则作为范围请求处理。反之，则返回全体资源。\n- 下面我们思考一下不使用首部字段 If-Range 发送请求的情况。服务器端的资源如果更新，那客户端持有资源中的一部分也会随之无效，当然，范围请求作为前提是无效的。这时，服务器会暂且以状态码 `412 Precondition Failed` 作为响应返回，其目的是催促客户端再次发送请求。这样一来，与使用首部字段 If-Range 比起来，就需要花费两倍的功夫。\n\n##### If-Unmodified-Since\n\n`If-Unmodified-Since: Mon, 10 Jul 2017 15:50:06 GMT`\n 首部字段 If-Unmodified-Since 和首部字段 If-Modified-Since 的作用相反。它的作用的是告知服务器，指定的请求资源只有在字段值内指定的日期时间之后，未发生更新的情况下，才能处理请求。如果在指定日期时间后发生了更新，则以状态码 `412 Precondition Failed` 作为响应返回。\n\n##### Max-Forwards\n\n`Max-Forwards: 10`\n 通过 TRACE 方法或 OPTIONS 方法，发送包含首部字段 Max-Forwards 的请求时，该字段以十进制整数形式指定可经过的服务器最大数目。服务器在往下一个服务器转发请求之前，Max-Forwards 的值减 1 后重新赋值。当服务器接收到 Max-Forwards 值为 0 的请求时，则不再进行转发，而是直接返回响应。\n\n##### Proxy-Authorization\n\n```\nProxy-Authorization: Basic dGlwOjkpNLAGfFY5\n```\n\n- 接收到从代理服务器发来的认证质询时，客户端会发送包含首部字段 Proxy-Authorization 的请求，以告知服务器认证所需要的信息。\n- 这个行为是与客户端和服务器之间的 HTTP 访问认证相类似的，不同之处在于，认证行为发生在客户端与代理之间。\n\n##### Range\n\n```\nRange: bytes=5001-10000\n```\n\n- 对于只需获取部分资源的范围请求，包含首部字段 Range 即可告知服务器资源的指定范围。\n- 接收到附带 Range 首部字段请求的服务器，会在处理请求之后返回状态码为 `206 Partial Content` 的响应。无法处理该范围请求时，则会返回状态码 `200 OK` 的响应及全部资源。\n\n##### Referer\n\n`Referer: http://www.sample.com/index.html`\n 首部字段 Referer 会告知服务器请求的原始资源的 URI。\n\n##### TE\n\n```\nTE: gzip, deflate; q=0.5\n```\n\n- 首部字段 TE 会告知服务器客户端能够处理响应的传输编码方式及相对优先级。它和首部字段 Accept-Encoding 的功能很相像，但是用于传输编码。\n- 首部字段 TE 除指定传输编码之外，还可以指定伴随 trailer 字段的分块传输编码的方式。应用后者时，只需把 trailers 赋值给该字段值。`TE: trailers` \n\n##### User-Agent\n\n```\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:13.0) Gecko/20100101\n```\n\n- 首部字段 User-Agent 会将创建请求的浏览器和用户代理名称等信息传达给服务器。\n- 由网络爬虫发起请求时，有可能会在字段内添加爬虫作者的电子邮件地址。此外，如果请求经过代理，那么中间也很可能被添加上代理服务器的名称。\n\n#### 响应首部字段（HTTP/1.1）\n\n| 首部字段名         | 说明                         |\n| ------------------ | ---------------------------- |\n| Accept-Ranges      | 是否接受字节范围请求         |\n| Age                | 推算资源创建经过时间         |\n| ETag               | 资源的匹配信息               |\n| Location           | 令客户端重定向至指定 URI     |\n| Proxy-Authenticate | 代理服务器对客户端的认证信息 |\n| Retry-After        | 对再次发起请求的时机要求     |\n| Server             | HTTP 服务器的安装信息        |\n| Vary               | 代理服务器缓存的管理信息     |\n| WWW-Authenticate   | 服务器对客户端的认证信息     |\n\n##### Accept-Ranges\n\n```\nAccept-Ranges: bytes\n```\n\n- 首部字段 Accept-Ranges 是用来告知客户端服务器是否能处理范围请求，以指定获取服务器端某个部分的资源。\n- 可指定的字段值有两种，可处理范围请求时指定其为 bytes，反之则指定其为 none。\n\n##### Age\n\n```\nAge: 1200\n```\n\n- 首部字段 Age 能告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。\n- 若创建该响应的服务器是缓存服务器，Age 值是指缓存后的响应再次发起认证到认证完成的时间值。代理创建响应时必须加上首部字段 Age。\n\n##### ETag\n\n```\nETag: \"usagi-1234\"\n```\n\n- 首部字段 ETag 能告知客户端实体标识。它是一种可将资源以字符串形式做唯一性标识的方式。服务器会为每份资源分配对应的 ETag 值。\n- 另外，当资源更新时，ETag 值也需要更新。生成 ETag 值时，并没有统一的算法规则，而仅仅是由服务器来分配。\n- ETag 中有强 ETag 值和弱 ETag 值之分。强 ETag 值，不论实体发生多么细微的变化都会改变其值；弱 ETag 值只用于提示资源是否相同。只有资源发生了根本改变，产生差异时才会改变 ETag 值。这时，会在字段值最开始处附加 W/： `ETag: W/\"usagi-1234\"`。\n\n##### Location\n\n```\nLocation: http://www.sample.com/sample.html\n```\n\n- 使用首部字段 Location 可以将响应接收方引导至某个与请求 URI 位置不同的资源。\n- 基本上，该字段会配合 3xx ：Redirection 的响应，提供重定向的 URI。\n- 几乎所有的浏览器在接收到包含首部字段 Location 的响应后，都会强制性地尝试对已提示的重定向资源的访问。\n\n##### Proxy-Authenticate\n\n```\nProxy-Authenticate: Basic realm=\"Usagidesign Auth\"\n```\n\n- 首部字段 Proxy-Authenticate 会把由代理服务器所要求的认证信息发送给客户端。\n- 它与客户端和服务器之间的 HTTP 访问认证的行为相似，不同之处在于其认证行为是在客户端与代理之间进行的。\n\n##### Retry-After\n\n```\nRetry-After: 180\n```\n\n- 首部字段 Retry-After 告知客户端应该在多久之后再次发送请求。主要配合状态码 `503 Service Unavailable` 响应，或 3xx Redirect 响应一起使用。\n- 字段值可以指定为具体的日期时间（Mon, 10 Jul 2017 15:50:06 GMT 等格式），也可以是创建响应后的秒数。\n\n##### Server\n\n`Server: Apache/2.2.6 (Unix) PHP/5.2.5`\n 首部字段 Server 告知客户端当前服务器上安装的 HTTP 服务器应用程序的信息。不单单会标出服务器上的软件应用名称，还有可能包括版本号和安装时启用的可选项。\n\n##### Vary\n\n```\nVary: Accept-Language\n```\n\n- 首部字段 Vary 可对缓存进行控制。源服务器会向代理服务器传达关于本地缓存使用方法的命令。\n- 从代理服务器接收到源服务器返回包含 Vary 指定项的响应之后，若再要进行缓存，仅对请求中含有相同 Vary 指定首部字段的请求返回缓存。即使对相同资源发起请求，但由于 Vary 指定的首部字段不相同，因此必须要从源服务器重新获取资源。\n\n##### WWW-Authenticate\n\n`WWW-Authenticate: Basic realm=\"Usagidesign Auth\"`\n 首部字段 WWW-Authenticate 用于 HTTP 访问认证。它会告知客户端适用于访问请求 URI 所指定资源的认证方案（Basic 或是 Digest）和带参数提示的质询（challenge）。\n\n#### 实体首部字段（HTTP/1.1）\n\n| 首部字段名       | 说明                         |\n| ---------------- | ---------------------------- |\n| Allow            | 资源可支持的 HTTP 方法       |\n| Content-Encoding | 实体主体适用的编码方式       |\n| Content-Language | 实体主体的自然语言           |\n| Content-Length   | 实体主体的大小（单位：字节） |\n| Content-Location | 替代对应资源的 URI           |\n| Content-MD5      | 实体主体的报文摘要           |\n| Content-Range    | 实体主体的位置范围           |\n| Content-Type     | 实体主体的媒体类型           |\n| Expires          | 实体主体过期的日期时间       |\n| Last-Modified    | 资源的最后修改日期时间       |\n\n##### Allow\n\n```\nAllow: GET, HEAD\n```\n\n- 首部字段 Allow 用于通知客户端能够支持 Request-URI 指定资源的所有 HTTP 方法。\n- 当服务器接收到不支持的 HTTP 方法时，会以状态码 `405 Method Not Allowed` 作为响应返回。与此同时，还会把所有能支持的 HTTP 方法写入首部字段 Allow 后返回。\n\n##### Content-Encoding\n\n```\nContent-Encoding: gzip\n```\n\n- 首部字段 Content-Encoding 会告知客户端服务器对实体的主体部分选用的内容编码方式。内容编码是指在不丢失实体信息的前提下所进行的压缩。\n- 主要采用这 4 种内容编码的方式（gzip、compress、deflate、identity）。\n\n##### Content-Language\n\n`Content-Language: zh-CN`\n 首部字段 Content-Language 会告知客户端，实体主体使用的自然语言（指中文或英文等语言）。\n\n##### Content-Length\n\n`Content-Length: 15000`\n 首部字段 Content-Length 表明了实体主体部分的大小（单位是字节）。对实体主体进行内容编码传输时，不能再使用 Content-Length首部字段。\n\n##### Content-Location\n\n`Content-Location: http://www.sample.com/index.html`\n 首部字段 Content-Location 给出与报文主体部分相对应的 URI。和首部字段 Location 不同，Content-Location 表示的是报文主体返回资源对应的 URI。\n\n##### Content-MD5\n\n`Content-MD5: OGFkZDUwNGVhNGY3N2MxMDIwZmQ4NTBmY2IyTY==`\n 首部字段 Content-MD5 是一串由 MD5 算法生成的值，其目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。\n\n##### Content-Range\n\n`Content-Range: bytes 5001-10000/10000`\n 针对范围请求，返回响应时使用的首部字段 Content-Range，能告知客户端作为响应返回的实体的哪个部分符合范围请求。字段值以字节为单位，表示当前发送部分及整个实体大小。\n\n##### Content-Type\n\n`Content-Type: text/html; charset=UTF-8`\n 首部字段 Content-Type 说明了实体主体内对象的媒体类型。和首部字段 Accept 一样，字段值用 type/subtype 形式赋值。参数 charset 使用 iso-8859-1 或 euc-jp 等字符集进行赋值。\n\n##### Expires\n\n```\nExpires: Mon, 10 Jul 2017 15:50:06 GMT\n```\n\n- 首部字段 Expires 会将资源失效的日期告知客户端。\n- 缓存服务器在接收到含有首部字段 Expires 的响应后，会以缓存来应答请求，在 Expires 字段值指定的时间之前，响应的副本会一直被保存。当超过指定的时间后，缓存服务器在请求发送过来时，会转向源服务器请求资源。\n- 源服务器不希望缓存服务器对资源缓存时，最好在 Expires 字段内写入与首部字段 Date 相同的时间值。\n\n##### Last-Modified\n\n`Last-Modified: Mon, 10 Jul 2017 15:50:06 GMT`\n 首部字段 Last-Modified 指明资源最终修改的时间。一般来说，这个值就是 Request-URI 指定资源被修改的时间。但类似使用 CGI 脚本进行动态数据处理时，该值有可能会变成数据最终修改时的时间。\n\n#### 为 Cookie 服务的首部字段\n\n| 首部字段名 | 说明                             | 首部类型     |\n| ---------- | -------------------------------- | ------------ |\n| Set-Cookie | 开始状态管理所使用的 Cookie 信息 | 响应首部字段 |\n| Cookie     | 服务器接收到的 Cookie 信息       | 请求首部字段 |\n\n##### Set-Cookie\n\n```\nSet-Cookie: status=enable; expires=Mon, 10 Jul 2017 15:50:06 GMT; path=/;\n```\n\n下面的表格列举了 Set-Cookie 的字段值。\n\n| 属性         | 说明                                                         |\n| ------------ | ------------------------------------------------------------ |\n| NAME=VALUE   | 赋予 Cookie 的名称和其值（必需项）                           |\n| expires=DATE | Cookie 的有效期（若不明确指定则默认为浏览器关闭前为止）      |\n| path=PATH    | 将服务器上的文件目录作为Cookie的适用对象（若不指定则默认为文档所在的文件目录） |\n| domain=域名  | 作为 Cookie 适用对象的域名 （若不指定则默认为创建 Cookie的服务器的域名） |\n| Secure       | 仅在 HTTPS 安全通信时才会发送 Cookie                         |\n| HttpOnly     | 加以限制，使 Cookie 不能被 JavaScript 脚本访问               |\n\n###### expires 属性\n\n- Cookie 的 expires 属性指定浏览器可发送 Cookie 的有效期。\n- 当省略 expires 属性时，其有效期仅限于维持浏览器会话（Session）时间段内。这通常限于浏览器应用程序被关闭之前。\n- 另外，一旦 Cookie 从服务器端发送至客户端，服务器端就不存在可以显式删除 Cookie 的方法。但可通过覆盖已过期的 Cookie，实现对客户端 Cookie 的实质性删除操作。\n\n###### path 属性\n\nCookie 的 path 属性可用于限制指定 Cookie 的发送范围的文件目录。\n\n###### domain 属性\n\n- 通过 Cookie 的 domain 属性指定的域名可做到与结尾匹配一致。比如，当指定 [example.com](https://link.jianshu.com?t=http://example.com) 后，除[example.com](https://link.jianshu.com?t=http://example.com) 以外，[www.example.com](https://link.jianshu.com?t=http://www.example.com) 或 [www2.example.com](https://link.jianshu.com?t=http://www2.example.com) 等都可以发送 Cookie。\n- 因此，除了针对具体指定的多个域名发送 Cookie 之 外，不指定 domain 属性显得更安全。\n\n###### secure 属性\n\nCookie 的 secure 属性用于限制 Web 页面仅在 HTTPS 安全连接时，才可以发送 Cookie。\n\n###### HttpOnly 属性\n\n- Cookie 的 HttpOnly 属性是 Cookie 的扩展功能，它使 JavaScript 脚本无法获得 Cookie。其主要目的为防止跨站脚本攻击（Cross-site scripting，XSS）对 Cookie 的信息窃取。\n- 通过上述设置，通常从 Web 页面内还可以对 Cookie 进行读取操作。但使用 JavaScript 的 document.cookie 就无法读取附加 HttpOnly 属性后的 Cookie 的内容了。因此，也就无法在 XSS 中利用 JavaScript 劫持 Cookie 了。\n\n##### Cookie\n\n`Cookie: status=enable`\n 首部字段 Cookie 会告知服务器，当客户端想获得 HTTP 状态管理支持时，就会在请求中包含从服务器接收到的 Cookie。接收到多个 Cookie 时，同样可以以多个 Cookie 形式发送。\n\n#### 其他首部字段\n\nHTTP 首部字段是可以自行扩展的。所以在 Web 服务器和浏览器的应用上，会出现各种非标准的首部字段。\n 以下是最为常用的首部字段。\n\n##### X-Frame-Options\n\n`X-Frame-Options: DENY`\n 首部字段 X-Frame-Options 属于 HTTP 响应首部，用于控制网站内容在其他 Web 网站的 Frame 标签内的显示问题。其主要目的是为了防止点击劫持（clickjacking）攻击。首部字段 X-Frame-Options 有以下两个可指定的字段值：\n\n- DENY：拒绝\n- SAMEORIGIN：仅同源域名下的页面（Top-level-browsing-context）匹配时许可。（比如，当指定 [http://sample.com/sample.html](https://link.jianshu.com?t=http://sample.com/sample.html) 页面为 SAMEORIGIN 时，那么 [sample.com](https://link.jianshu.com?t=http://sample.com) 上所有页面的 frame 都被允许可加载该页面，而 [example.com](https://link.jianshu.com?t=http://example.com) 等其他域名的页面就不行了）\n\n##### X-XSS-Protection\n\n`X-XSS-Protection: 1`\n 首部字段 X-XSS-Protection 属于 HTTP 响应首部，它是针对跨站脚本攻击（XSS）的一种对策，用于控制浏览器 XSS 防护机制的开关。首部字段 X-XSS-Protection 可指定的字段值如下:\n\n- 0 ：将 XSS 过滤设置成无效状态\n- 1 ：将 XSS 过滤设置成有效状态\n\n##### DNT\n\n`DNT: 1`\n 首部字段 DNT 属于 HTTP 请求首部，其中 DNT 是 Do Not Track 的简称，意为拒绝个人信息被收集，是表示拒绝被精准广告追踪的一种方法。首部字段 DNT 可指定的字段值如下：\n\n- 0 ：同意被追踪\n- 1 ：拒绝被追踪\n\n由于首部字段 DNT 的功能具备有效性，所以 Web 服务器需要对 DNT做对应的支持。\n\n##### P3P\n\n`P3P: CP=\"CAO DSP LAW CURa ADMa DEVa TAIa PSAa PSDa IVAa IVDa OUR BUS IND`\n 首部字段 P3P 属于 HTTP 响应首部，通过利用 P3P（The Platform for Privacy Preferences，在线隐私偏好平台）技术，可以让 Web 网站上的个人隐私变成一种仅供程序可理解的形式，以达到保护用户隐私的目的。\n 要进行 P3P 的设定，需按以下操作步骤进行：\n\n- 步骤 1：创建 P3P 隐私\n- 步骤 2：创建 P3P 隐私对照文件后，保存命名在 /w3c/p3p.xml\n- 步骤 3：从 P3P 隐私中新建 Compact policies 后，输出到 HTTP 响应中\n\n### HTTP 响应状态码（重点分析）\n\n#### 状态码概述\n\n- HTTP 状态码负责表示客户端 HTTP 请求的返回结果、标记服务器端的处理是否正常、通知出现的错误等工作。\n- HTTP 状态码如 `200 OK` ，以 3 位数字和原因短语组成。数字中的第一位指定了响应类别，后两位无分类。\n- 不少返回的响应状态码都是错误的，但是用户可能察觉不到这点。比如 Web 应用程序内部发生错误，状态码依然返回 `200 OK`。\n\n#### 状态码类别\n\n|      | 类别                           | 原因短语                   |\n| ---- | ------------------------------ | -------------------------- |\n| 1xx  | Informational(信息性状态码)    | 接收的请求正在处理         |\n| 2xx  | Success(成功状态码)            | 请求正常处理完毕           |\n| 3xx  | Redirection(重定向状态码)      | 需要进行附加操作以完成请求 |\n| 4xx  | Client Error(客户端错误状态码) | 服务器无法处理请求         |\n| 5xx  | Server Error(服务器错误状态码) | 服务器处理请求出错         |\n\n我们可以自行改变 RFC2616 中定义的状态码或者服务器端自行创建状态码，只要遵守状态码的类别定义就可以了。\n\n#### 常用状态码解析\n\nHTTP 状态码种类繁多，数量达几十种。其中最常用的有以下 14 种，一起来看看。\n\n##### 200 OK\n\n表示从客户端发来的请求在服务器端被正常处理了。\n\n##### 204 No Content\n\n- 代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。\n- 一般在只需要从客户端向服务器端发送消息，而服务器端不需要向客户端发送新消息内容的情况下使用。\n\n#####  206 Partial Content\n\n表示客户端进行了范围请求，而服务器成功执行了这部分的 GET 请求。响应报文中包含由 Content-Range 首部字段指定范围的实体内容。\n\n##### 301 Moved Permanently\n\n永久性重定向。表示请求的资源已被分配了新的 URI。以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI 保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。\n\n##### 302 Found\n\n- 临时性重定向。表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。\n- 和 `301 Moved Permanently` 状态码相似，但 `302 Found` 状态码代表资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的 URI 将来还有可能发生改变。\n\n##### 303 See Other\n\n- 表示由于请求的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源。\n-  `303 See Othe`r 和 `302 Found` 状态码有着相同的功能，但 `303 See Other` 状态码明确表示客户端应采用 GET 方法获取资源，这点与 `302 Found` 状态码有区别。\n\n##### 304 Not Modified\n\n- 表示客户端发送附带条件的请求时，服务器端允许请求访问的资源，但未满足条件的情况。\n-  `304 Not Modified` 状态码返回时，不包含任何响应的主体部分。\n-  `304 Not Modified` 虽然被划分到 3xx 类别中，但和重定向没有关系。\n\n##### 307 Temporary Redirect\n\n临时重定向。该状态码与 `302 Found` 有着相同的含义。\n\n##### 400 Bad Request\n\n- 表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。\n- 另外，浏览器会像 `200 OK` 一样对待该状态码。\n\n##### 401 Unauthorized\n\n- 表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。\n- 另外，若之前已进行过 1 次请求，则表示用户认证失败。\n- 返回含有 `401 Unauthorized` 的响应必须包含一个适用于被请求资源的 WWW-Authenticate 首部用以质询（challenge）用户信息。\n\n##### 403 Forbidden\n\n表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出详细的拒绝理由，当然也可以在响应报文的实体主体部分对原因进行描述。\n\n##### 404 Not Found\n\n表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由的时候使用。\n\n##### 500 Internal Server Error\n\n表明服务器端在执行请求时发生了错误。也可能是 Web 应用存在的 bug 或某些临时的故障。\n\n##### 503 Service Unavailable\n\n表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入 Retry-After 首部字段再返回给客户端。\n\n### HTTP 报文实体\n\n#### HTTP 报文实体概述\n\n![HTTP 报文结构](https://github.com/AlexBruceLu/DAPP/wiki/http13_1.webp)\n\n大家请仔细看看上面示例中，各个组成部分对应的内容。\n 接着，我们来看看报文和实体的概念。如果把 HTTP 报文想象成因特网货运系统中的箱子，那么 HTTP 实体就是报文中实际的货物。\n\n- 报文：是网络中交换和传输的数据单元，即站点一次性要发送的数据块。报文包含了将要发送的完整的数据信息，其长短很不一致，长度不限且可变。\n- 实体：作为请求或响应的有效载荷数据（补充项）被传输，其内容由实体首部和实体主体组成。（实体首部相关内容在上面第六点中已有阐述。）\n\n我们可以看到，上面示例右图中深红色框的内容就是报文的实体部分，而蓝色框的两部分内容分别就是实体首部和实体主体。而左图中粉红框内容就是报文主体。\n **通常，报文主体等于实体主体。只有当传输中进行编码操作时，实体主体的内容发生变化，才导致它和报文主体产生差异。**\n\n#### 内容编码\n\n- HTTP 应用程序有时在发送之前需要对内容进行编码。例如，在把很大的 HTML 文档发送给通过慢速连接上来的客户端之前，服务器可能会对其进行压缩，这样有助于减少传输实体的时间。服务器还可以把内容搅乱或加密，以此来防止未授权的第三方看到文档的内容。\n- 这种类型的编码是在发送方应用到内容之上的。当内容经过内容编码后，编好码的数据就放在实体主体中，像往常一样发送给接收方。\n\n内容编码类型：\n\n| 编码方式 | 描述                                                         |\n| -------- | ------------------------------------------------------------ |\n| gzip     | 表明实体采用 GNU zip 编码                                    |\n| compress | 表明实体采用 Unix 的文件压缩程序                             |\n| deflate  | 表明实体采用 zlib 的格式压缩的                               |\n| identity | 表明没有对实体进行编码，当没有 Content-Encoding 首部字段时，默认采用此编码方式 |\n\n#### 传输编码\n\n内容编码是对报文的主体进行的可逆变换，是和内容的具体格式细节紧密相关的。\n 传输编码也是作用在实体主体上的可逆变换，但使用它们是由于架构方面的原因，同内容的格式无关。使用传输编码是为了改变报文中的数据在网络上传输的方式。\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_3.webp)\n\n#### 分块编码\n\n分块编码把报文分割成若干已知大小的块。块之间是紧挨着发送的，这样就不需要在发送之前知道整个报文的大小了。分块编码是一种传输编码，是报文的属性。\n\n##### **分块编码与持久连接**\n\n 若客户端与服务器端之间不是持久连接，客户端就不需要知道它在读取的主体的长度，而只需要读取到服务器关闭主体连接为止。\n 当使用持久连接时，在服务器写主体之前，必须知道它的大小并在 Content-Length 首部中发送。如果服务器动态创建内容，就可能在发送之前无法知道主体的长度。\n 分块编码为这种困难提供了解决方案，只要允许服务器把主体分块发送，说明每块的大小就可以了。因为主体是动态创建的，服务器可以缓冲它的一部分，发送其大小和相应的块，然后在主体发送完之前重复这个过程。服务器可以用大小为 0 的块作为主体结束的信号，这样就可以继续保持连接，为下一个响应做准备。\n 来看看一个分块编码的报文示例：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_2.webp)\n\n#### 多部分媒体类型\n\nMIME 中的 multipart（多部分）电子邮件报文中包含多个报文，它们合在一起作为单一的复杂报文发送。每一部分都是独立的，有各自的描述其内容的集，不同部分之间用分界字符串连接在一起。\n 相应得，HTTP 协议中也采纳了多部分对象集合，发送的一份报文主体内可包含多种类型实体。\n 多部分对象集合包含的对象如下：\n\n- multipart/form-data：在 Web 表单文件上传时使用。\n- multipart/byteranges：状态码 `206 Partial Content` 响应报文包含了多个范围的内容时使用。\n\n#### 范围请求\n\n假设你正在下载一个很大的文件，已经下了四分之三，忽然网络中断了，那下载就必须重头再来一遍。为了解决这个问题，需要一种可恢复的机制，即能从之前下载中断处恢复下载。要实现该功能，这就要用到范围请求。\n 有了范围请求， HTTP 客户端可以通过请求曾获取失败的实体的一个范围（或者说一部分），来恢复下载该实体。当然这有一个前提，那就是从客户端上一次请求该实体到这一次发出范围请求的时间段内，该对象没有改变过。例如：\n\n```\nGET  /bigfile.html  HTTP/1.1\nHost: www.sample.com\nRange: bytes=20224-\n···\n```\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_4.webp)\n\n上面示例中，客户端请求的是文档开头20224字节之后的部分。\n\n### 与 HTTP 协作的 Web 服务器\n\nHTTP 通信时，除客户端和服务器外，还有一些用于协助通信的应用程序。如下列出比较重要的几个：**代理、缓存、网关、隧道、Agent 代理**。\n\n#### 代理\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_5.webp)\n\nHTTP 代理服务器是 Web 安全、应用集成以及性能优化的重要组成模块。代理位于客户端和服务器端之间，接收客户端所有的 HTTP 请求，并将这些请求转发给服务器（可能会对请求进行修改之后再进行转发）。对用户来说，这些应用程序就是一个代理，代表用户访问服务器。\n 出于安全考虑，通常会将代理作为转发所有 Web 流量的可信任中间节点使用。代理还可以对请求和响应进行过滤，安全上网或绿色上网。\n\n#### 缓存\n\n**浏览器第一次请求：**\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_6.webp)\n\n**浏览器再次请求：**\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_7.webp)\n\nWeb 缓存或代理缓存是一种特殊的 HTTP 代理服务器，可以将经过代理传输的常用文档复制保存起来。下一个请求同一文档的客户端就可以享受缓存的私有副本所提供的服务了。客户端从附近的缓存下载文档会比从远程 Web 服务器下载快得多。\n\n#### 网关\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_8.webp)\n\n网关是一种特殊的服务器，作为其他服务器的中间实体使用。通常用于将 HTTP 流量转换成其他的协议。网关接收请求时就好像自己是资源的源服务器一样。客户端可能并不知道自己正在跟一个网关进行通信。\n\n#### 隧道\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_9.webp)\n\n隧道是会在建立起来之后，就会在两条连接之间对原始数据进行盲转发的 HTTP 应用程序。HTTP 隧道通常用来在一条或多条 HTTP 连接上转发非 HTTP 数据，转发时不会窥探数据。\n HTTP 隧道的一种常见用途就是通过 HTTP 连接承载加密的安全套接字层（SSL）流量，这样 SSL 流量就可以穿过只允许 Web 流量通过的防火墙了。\n\n#### Agent 代理\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http13_10.webp)\n\nAgent 代理是代表用户发起 HTTP 请求的客户端应用程序。所有发布 Web 请求的应用程序都是 HTTP Agent 代理。","tags":["http/https"],"categories":["others"]},{"title":"http与https协议的区别","url":"/2018/12/03/http网络/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n相关概念\n\n<!-- more -->\n\n[TOC]\n\n超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。\n\n　　为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。\n\n### **一、HTTP和HTTPS的基本概念**\n\n　　HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。\n\n　　HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。\n\n　　HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。\n\n### **二、HTTP与HTTPS有什么区别？**\n\n　　HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。\n\nHTTPS和HTTP的区别主要如下：\n\n　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。\n\n　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。\n\n　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。\n\n　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。\n\n### **三、HTTPS的工作原理**\n\n　　我们都知道HTTPS能够加密信息，以免敏感信息被第三方获取，所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/http1.jpg)\n\n客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。\n\n　　（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。\n\n　　（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。\n\n　　（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。\n\n　　（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。\n\n　　（5）Web服务器利用自己的私钥解密出会话密钥。\n\n　　（6）Web服务器利用会话密钥加密与客户端之间的通信。\n\n![](https://github.com/AlexBruceLU/DAPP/wiki/http2.gif)\n\n### **四、HTTPS的优点**\n\n　　尽管HTTPS并非绝对安全，掌握根证书的机构、掌握加密算法的组织同样可以进行中间人形式的攻击，但HTTPS仍是现行架构下最安全的解决方案，主要有以下几个好处：\n\n　　（1）使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；\n\n　　（2）HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。\n\n　　（3）HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。\n\n　　（4）谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。\n\n### **五、HTTPS的缺点**\n\n　　虽然说HTTPS有很大的优势，但其相对来说，还是存在不足之处的：\n\n　　（1）HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电；\n\n　　（2）HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；\n\n　　（3）SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。\n\n　   （4）SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。\n\n　　（5）HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。\n\n### **六、http切换到HTTPS**\n\n　　如果需要将网站从http切换到https到底该如何实现呢？\n\n​     这里需要将页面中所有的链接，例如js，css，图片等等链接都由http改为https。例如：http://www.baidu.com改为https://www.baidu.com\n\n　　BTW，这里虽然将http切换为了https，还是建议保留http。所以我们在切换的时候可以做http和https的兼容，具体实现方式是，去掉页面链接中的http头部，这样可以自动匹配http头和https头。例如：将http://www.baidu.com改为//www.baidu.com。然后当用户从http的入口进入访问页面时，页面就是http，如果用户是从https的入口进入访问页面，页面即使https的。","tags":["http/https"],"categories":["others"]},{"title":"Kubernetes（K8s）","url":"/2018/12/03/k8s/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nKubernetes 的简介和基本操作\n\n<!-- more -->\n\n[TOC]\n\n## 为什么叫k8s\n\nKubernetes（K8s）是Google在2014年发布的一个开源项目 。而且`k`和`s`之间有八个字母间隔，所以叫做k8s。\n\n## k8s 的基本概念\n\n- **Cluster（集群 )**\n\n  > Cluster是计算、存储和网络资源的集合，Kubernetes利用这些资源运行各种基于容器的应用。 \n\n- **Master（控制主节点）**\n\n  > Master是Cluster的大脑，它的主要职责是调度，即决定将应用放在哪里运行。Master运行Linux操作系统，可以是物理机或者虚拟机。为了实现高可用，可以运行多个Master。调度应用程序、维护应用程序的所需状态、扩展应用程序和滚动更新都是master的主要工作。 \n\n- **Node（节点）** \n\n  > Node的职责是运行容器应用。Node由Master管理，Node负责监控并汇报容器的状态，同时根据Master的要求管理容器的生命周期。\n  > Node是 Kubernetes 集群中的工作机器，可以是物理机或虚拟机。每个工作节点都有一个 kubelet，它是管理节点并与 Kubernetes Master 节点进行通信的代理。节点上还应具有处理容器操作的容器运行时，例如 Docker。\n  > 一个 Kubernetes 工作集群至少有三个节点。 Master 管理集群，而 Node（节点）用于托管正在运行的应用程序。\n  > 当你在 Kubernetes 上部署应用程序时，你可以告诉 master 启动应用程序容器。Master 调度容器在集群的节点上运行。 节点使用 Master 公开的 Kubernetes API 与 Master 通信。用户也可以直接使用 Kubernetes 的 API 与集群交互 。\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/k8s.png)\n\n- **Pod（资源对象） **\n\n  > Pod是Kubernetes的最小工作单元。每个Pod包含一个或多个容器。Pod中的容器会作为一个整体被Master调度到一个Node上运行。\n  > Kubernetes引入Pod主要基于下面两个目的： \n  >\n  > （1）可管理性。 有些容器天生就是需要紧密联系，一起工作。Pod提供了比容器更高层次的抽象，将它们封装到一个部署单元中。Kubernetes以Pod为最小单位进行调度、扩展、共享资源、管理生命周期。 \n  >\n  > （2）通信和资源共享。 Pod中的所有容器使用同一个网络namespace，即相同的IP地址和Port空间。它们可以直接用localhost通信。同样的，这些容器可以共享存储，当Kubernetes挂载volume到\n  > Pod，本质上是将volume挂载到 Pod中的每一个容器。Pods有两种使用方式：\n  > **（1）运行单一容器。**\n  > one-container-per-Pod是Kubernetes最常见的模型，这种情况下，只是将单个容器简单封装成Pod。即便是只有一个容器，Kubernetes管理的也是Pod而不是直接管理容器。\n  > **（2）运行多个容器。**\n  > 问题在于：哪些容器应该放到一个Pod中？ 答案是：这些容器联系必须非常紧密，而且需要直接共享资源。举个例子，如图 所示，这个Pod包含两个容器：一个是File Puller(文件拉取器)，一个是Web Server。 ","tags":["k8s"],"categories":["docker"]},{"title":"Solidity基础语法","url":"/2018/12/01/Solidity基础语法/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nsolidity 基础语法的介绍\n\n<!-- more -->","tags":["solidity"],"categories":["dapp"]},{"title":"HyperLedger Fabric","url":"/2018/12/01/HyperledgerFabric01/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nHyperLedger基础概念简介，以及核心模块的介绍\n\n<!-- more -->\n\n[TOC]\n\n# Fabric基本概念 \n\n## 1. 逻辑架构 \n\n![](https://github.com/AlexBruceLu/DAPP/wiki/fen.png)\n\n\n\n- **成员管理（MemberShip）**\n  - 会员注册\n    - 注册成功一个账号得到的不是用户名密码\n    - 使用证书作用身份认证的标志\n  - 身份保护\n  - 交易审计\n  - 内容保密\n    - 可以多条区块链, 通过通道来区分的\n- **账本管理**\n  - 区块链\n    - 保存所有的交易记录\n  - 世界状态\n    - 数据的最新状态\n    - 数据存储在当前节点的数据库中\n      - 自带的默认数据库: levelDB, 也可以使用couchdb\n      - 以键值对的方式进行存储 的\n\n- **交易管理**\n  - 部署交易\n    - 部署的是链码, 就是给节点安装链码 - chaincode\n  - 调用交易\n    - invoke\n- **智能合约**\n  - 一段代码， 处理网络成员所同意的业务逻辑\n  - 真正实现了链码和账本的分离（逻辑和数据分离）","tags":["Fabric"],"categories":["hyperledger"]},{"title":"Linux+Go装机笔记","url":"/2018/11/27/Linux装机笔记/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nLinux+Go装机笔记\n\n<!-- more -->\n\n[TOC]\n\n- 安装WMware时选择硬盘，一定要选择单一文件模式，后期好扩容，最好50G以上\n\n- 基本环境WMware 15 + Ubuntu 18.04\n\n- 点虚拟机菜单，安装WMware tools , cp WMware tools .tz ~/ ,sudo ./wm***.pl\n\n- 彩色命令行\n\n  ```shell\n  export PS1=\"\\[\\e[0;32;40m\\]-\\#-[\\[\\e[1;32;40m\\]\\u\\[\\e[0;32;40m\\]@\\h]\\[\\e[0;36;40m\\]\\A \\[\\e[1;35;40m\\]\\w \\[\\e[0;32;40m\\]\\[\\e[1;31;40m\\]$ \\[\\e[0;33;40m\\]\"\n  ```\n\n- 更新apt源\n\n  ```shell\n  $ sudo apt update\n  $ sudo apt upgrade\n  ```\n\n## 搜狗输入法的安装\n\n1. 官网下载Linux版搜狗输入法\n\n2. 打开ubuntu的应用商店，搜索**`fcitx`**,将搜到的**`fcitx`**程序也就是小企鹅图标的全部安装上\n\n   ```shell\n   $ sudo dpkg -i sogoupinyin_xxx_xxx.deb\n   # 会报错，接着执行下面命令\n   $ sudo apt --fix-broken install\n   ```\n\n3. 安装完成后，我们再双击刚下载的deb程序文件就可以安装了\n\n   ```shell\n   $ sudo dpkg -i sougoupinyin_xxx_xxx.deb\n   ```\n\n4. 搜狗输入法安装完毕后我们打开命令行\n\n   ```shell\n   $ sudo apt remove ibus*\n   ```\n\n1. 我们打开设置 -> 区域和语言 -> 管理已安装的语言 -> fcitx -> 应用到整个系统\n\n## MySQL 安装\n\n[https://dev.mysql.com/downloads/file/?id=482263](https://dev.mysql.com/downloads/file/?id=482263)\n\n下载一个mysql-apt-config_0.8.11-1_all.deb\n\n```shell\n$ sudo dpkg -i mysql-apt-config_0.8.11-1_all.deb\n$ sudo apt update\n$ sudo apt upgrade\n$ sudo apt-get install mysql-server\n```\n\n**中途会让设置密码**\n\n- 卸载\n\n  ```shell\n  $ sudo apt-get autoremove --purge mysql-server-5.0\n  $ sudo apt-get remove mysql-server\n  $ sudo apt-get autoremove mysql-server\n  $ sudo apt-get remove mysql-common \n  ```\n\n## Redis 安装\n\n```shell\n$ wget http://download.redis.io/releases/redis-4.0.9.tar.gz\n$ sudo tar zxvf redis-4.0.9.tar.gz\n$ sudo mv redis-4.0.9 /usr/local/redis\n$ wget http://downloads.sourceforge.net/tcl/tcl8.6.9-src.tar.gz\n$ sudo tar zxvf tcl8.6.9-src.tar.gz\n$ sudo mv tcl8.6.9 /usr/local/tcl\n$ cd  /usr/local/tcl/unix/\n$ sudo ./configure\n$ sudo make（时间比较长）\n$ sudo make install \n\n```\n\n## MongoDB 安装\n\n## golang 安装\n\n```shell\n$ sudo tar -C /usr/local -xzf go1.11.linux-amd64.tar.gz\n$ export PATH=$PATH:/usr/local/go/bin\n```\n\n\n\n\n\n## goland 安装\n\n127.0.0.1            account.jetbrains.com\n\n## sublime text3 安装\n\n- 直接应用商店安装\n- 安装控制台\n\n```shell\nimport urllib.request,os; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), 'wb').write(urllib.request.urlopen( 'http://sublime.wbond.net/' + pf.replace(' ','%20')).read())\n```\n\n- 常用插件\n\n  - #####  Emmet\n\n    > 一种快速编写html/css的方法\n    >\n    > 注意：安装Emmet的同时，也会自动安装其依赖PyV8 binary库，安装PyV8库会用较长时间，可以在Sublime左下角看到安装进程状态\n\n  - ##### html5\n\n    > 支持hmtl5规范的插件包\n    >\n    > 注意：与Emmet插件配合使用，效果更好\n    >\n    > 使用方法：新建html文档>输入html5>敲击Tab键>自动补全html5规范文档\n\n  - #####  jQuery\n\n    > 支持JQuery规范的插件包\n\n  - #####  SideBarEnhancements\n\n    > 侧栏右键功能增强，非常实用\n    >\n    > 使用方法(参考链接内容)：<http://www.w3cfuns.com/notes/13810/d9b9ed2fb80785dae88a5344ef0f30d4.html>\n\n  - ##### Ctags\n\n    > 函数跳转，我的电脑上是Alt+点击 函数名称，会跳转到相应的函数\n\n  - ##### Alignment\n\n    > 代码对齐，如写几个变量，选中这几行，Ctrl+Alt+A，哇，齐了\n\n  - ##### SublimeLinter\n\n    > 一个支持lint语法的插件，可以高亮linter认为有错误的代码行，也支持高亮一些特别的注释，比如“TODO”，这样就可以被快速定位。（IntelliJ IDEA的TODO功能很赞，这个插件虽然比不上，但是也够用了吧）\n\n  - ##### ChineseLocalizations\n\n    > 中文语言包\n\n  - ##### A File Icon\n\n    > 图标美化\n\n  - ##### BracketHighlighter\n\n    > 类似于代码匹配，可以匹配括号，引号等符号内的范围。\n    >\n    > 使用方法：系统默认为白色高亮，可以使用链接所述方法进行自定义配置\n    >\n    > <http://www.360doc.com/content/14/1111/15/15077656_424301780.shtml>\n\n> ```tx\n> 127.0.0.1       www.sublimetext.com\n> 127.0.0.1       license.sublimehq.com\n> Windows : c:/windows/system32/drivers/etc/hosts\n> \n> Linux : /etc/hosts\n> \n> Mac : /Private/etc\n> ----- BEGIN LICENSE -----\n> sgbteam\n> Single User License\n> EA7E-1153259\n> 8891CBB9 F1513E4F 1A3405C1 A865D53F\n> 115F202E 7B91AB2D 0D2A40ED 352B269B\n> 76E84F0B CD69BFC7 59F2DFEF E267328F\n> 215652A3 E88F9D8F 4C38E3BA 5B2DAAE4\n> 969624E7 DC9CD4D5 717FB40C 1B9738CF\n> 20B3C4F1 E917B5B3 87C38D9C ACCE7DD8\n> 5F7EF854 86B9743C FADC04AA FB0DA5C0\n> F913BE58 42FEA319 F954EFDD AE881E0B\n> ------ END LICENSE ------\n> ```\n\n## vim go语言插件\n\n## 安装OpenSSL\n\n## 安装Chrome\n\n1. 将下载源添加到系统源\n\n   ```shell\n   $ sudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/\n   ```\n\n2. 导入\n\n   ```shell\n   $ wget -q -O - https://dl.google.com/linux/linux_signing_key.pub  | sudo apt-key add -\n   $ sudo apt-get update\n   ```\n\n3. 稳定版的安装\n\n   ```shell\n   $ sudo apt-get install google-chrome-stable\n   ```\n\n4. 启动Chrome，添加收藏夹\n\n   ```shell\n   $ ./usr/bin/google-chrome-stable\n   ```\n\n\n\n\n\n\n","tags":["linux"],"categories":["others"]},{"title":"Micro","url":"/2018/11/26/房屋租赁/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n基于go-micro的微服务之房屋租赁\n\n<!-- more -->\n\n[TOC]\n\n# 房屋租赁\n\n## 1. 项目简述\n\n## 2. 项目启动\n\n### 2.1 拆分原则\n\n1. 单一职责\n2. 服务粒度适中\n3. 考虑团队结构\n4. 以业务模型切入\n5. 演进式拆分\n6. 避免环形依赖和双向依赖 \n\n### 2.2 前期准备工作\n\n#### 2.2.1 单机版的 consul 启动\n\n项目开始之前首先要启动单机版的consul \n\n```shell\n$ consul agent -dev\n```\n\n#### 2.2.2 数据库的创建\n\n在mysql中创建一个项目所用数据库 \n\n```shell\n$ mysql -uroot -p\nmysql> create database if not exists house default charset utf8 collate utf8_general_ci;\n# 查看数据库\nmysql> show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| cms                |\n| house              |\n| information_schema |\n| mysql              |\n| performance_schema |\n| sdrms              |\n| sys                |\n+--------------------+\n7 rows in set (0.85 sec)\n\n```\n\n- 创建表的关系逻辑图\n\n  ![](https://github.com/AlexBruceLu/DAPP/wiki/user.png)\n\n\n## 3. web 服务的创建\n\n```shell\n$ micro new --type \"web\" micro/houseWeb\n# 以GOPATH/src 问基准的局对路径 $GOPATH/src/micro/houseWeb\n.\n├── Dockerfile\n├── handler\n│   └── handler.go\n├── main.go\n├── Makefile\n├── plugin.go\n└── README.md\n```\n\n### 3.1 创建工具函数文件夹 \n\n```shell\n#创建工具函数文件夹\n$ mkdir utils\n# 进入文件夹创建文件\n$ cd utils\n# 配置文件读取函数文件\n$ touch config.go\n# 错误码文件\n$ touch error.go\n# 字符串拼接文件\n$ touch misc.go\n```\n\n### 3.2 创建数据库文件 \n\n```shell\n$ mkdir models\n#创建数据库文件\n$ vim models.go\n```\n\n### 3.3 运行服务并且创建表单 \n\n```shell\n#创建conf文件夹用来存放配置文件\n$ mkdir conf\n#创建data.sql文件\n$ vim data.sql\n```\n\ndata.sql 内容\n\n```sql\nINSERT INTO `area`(`name`) VALUES ('东城区'),('西城区'),('朝阳区'),('海淀区'),('昌平区'),('丰台区'),('房山区'),('通州区'),('顺义区'),('大兴区'),('怀柔区'),('平谷区'),('密云区'),('延庆区'),('石景山区'),('天津');\nINSERT INTO `facility`(`name`) VALUES('无线网络'),('热水淋浴'),('空调'),('暖气'),('允许吸烟'),('饮水设备'),('牙具'),('香皂'),('拖鞋'),('手纸'),('毛巾'),('沐浴露、洗发露'),('冰箱'),('洗衣机'),('电梯'),('允许做饭'),('允许带宠物'),('允许聚会'),('门禁系统'),('停车位'),('有线网络'),('电视'),('浴缸'),('吃鸡'),('打台球'),('游泳');\n```\n\n**`data.sql`**内容的导入\n\n```shell\n $ cd houseWeb/\n mysql> source ./conf/data.sql;\n```\n\n## 4. 获取地区信息 \n\n### 4.1 创建服务\n\n```shell\n$ micro new --type \"srv\" micro/getArea\n```\n\n### 4.2 业务逻辑示意图\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/area.png)\n\n","tags":["微服务"],"categories":["microServices"]},{"title":"Docker的安装与简介","url":"/2018/11/25/Docker的安装与简介/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nDocker养成记之安装与简介\n\n<!-- more -->","tags":["Docker"],"categories":["docker"]},{"title":"MySQL的安装与简介","url":"/2018/11/25/MySQL的安装与简介/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nMySQL养成记之安装与简介\n\n<!-- more -->","tags":["MySQL"],"categories":["database"]},{"title":"MongoDB的安装与简介","url":"/2018/11/25/MongoDB的安装与简介/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nMongoDB养成记之安装与简介\n\n<!-- more -->","tags":["MongoDB"],"categories":["database"]},{"title":"gorountine","url":"/2018/11/25/gorountine/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之gorountine\n\n<!-- more -->","tags":["golang"],"categories":["golang"]},{"title":"channel","url":"/2018/11/25/channel/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之channel\n\n<!-- more -->","tags":["golang"],"categories":["golang"]},{"title":"http及其标准库","url":"/2018/11/25/http及其标准库/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之http及其标准库\n\n<!-- more -->","tags":["golang"],"categories":["golang"]},{"title":"内建容器","url":"/2018/11/25/内建容器/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之内建容器\n\n<!-- more -->\n## 1. 数组 Array\n\n### 1.1 为什么使用数组\n\n- 传统的方法不利于数据管理与维护，使用数组也容易扩展数据。\n- **注：**<font color=\"red\">Go语言中的数组是之拷贝的传递</font>\n\n### 1.2 数组的四种初始化方法\n\n```go\narr := [3]int{1,2,3}\nvar arr [3]int = [3]int{1,2,3}\narr := [...]int{8,9,7}\narr := [...]int{1:800,2:1000,3:900}\n```\n\n### 1.3 数组的遍历\n\n```go\nfor index,value := range arr{\n    ...\n}\nfor index := range arr{\n    ...\n}\n```\n\n注：1. index 为数组元素的下标，value 为下标所对应的值\n\n \t2. index,value 只能在该for 循环内使用\n \t3. 可以用 \"_\" 来忽略index 或 value，当只有一个返回值时为index\n\n### 1.4 数组使用时的注意事项\n\n1. 数组是定长的相同类型的数据集合\n2. 数组中的数据类型可以是任意数据类型，值类型、引用类型，但是不能混用\n3. 数组声明后若没有初始化，则元素的为声明是数据类型的默认零值(0，nil,\"\")\n4. 使用步骤：声明数据开辟空间 -> 初始化值/赋值 -> 使用\n5. 数组的下标是从0开始的，要注意下标越界\n6. 数组是值类型，数据传递为值拷贝\n7. 长度不同数据类型相同的两个数组是不同类型的数组\n8. 若要修改原来的数组值，则需要引用传递，即取地址\n\n## 2. 切片 Slice\n\n## 3. map\n\n## 4. 字符和字符串处理\n\n### 4.1 字符串常用的系统函数","tags":["golang"],"categories":["golang"]},{"title":"面向接口","url":"/2018/11/25/面向接口/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之面向接口\n\n<!-- more -->\n\n\n\n## 1. duck typing 的概念\n\n> \"当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。\"\n>\n> 在鸭子类型中，关注的不是对象的类型本身，而是它是如何使用的。\n>\n> <font color=\"blue\">鸭子本来不是人，但是实现了某些人的方法就会被认为是人。</font>\n\n- 描述事物的外部行为而非内部结构\n\n- 其他语言中的duck typing\n\n  - Python\n\n  ```python\n  def download(retriever): // download 是duck typing 的使用者\n      return retriever.get(\"666\") // retriever是duck typing的对象(实现者)\n  ```\n\n  **注 ：**编译时才知道传入的retriever 有没有get\n\n  - C++\n\n    ```c\n    template <class R>\n        \n    string download(const R& retriever) {\n        return retriever.get(\"666\");\n    }\n    ```\n\n    **注 ：**1. 编译时才知道传入的retriever 有没有get\n\n    ​\t2. 需要注释来说明接口\n\n  - Java\n\n    ```java\n    <R extends Retriever>\n    String download(R r) {\n    \treturn retriever.get(\"666\");\n    }\n    ```\n\n    **注：**传入的参数必须实现Retrieve 接口，并不是duck typing；不需要注释说明接口\n\n    <font color=\"red\">go语言中的duck typing，具有灵活性和类型检查的严格性</font>\n\n\n## 2. 接口的定义和实现\n\n### 2.1 基本介绍\n\n- golang 中多态的特性主要通过接口来实现的\n- interface 类型可以定义一组方法，但并需要实现。并且，interface 不能包含任何变量。到某个自定义类型要使用的时候，根据具体的情况再把这些方法实现出来\n\n- 基本语法\n\n  ```go\n  type 接口名 interface {\n      method1(参数列表) 返回值列表\n      method2(参数列表) 返回值列表\n      ...\n  }\n  \n  func (t 自定义类型) method1(参数列表) 返回值列表{\n      // 具体实现\n  }\n  \n  func (t 自定义类型) method2(参数列表) 返回值列表{\n      // 具体实现\n  }\n  ```\n\n  - 接口里的所有的方法都没有方法体，即<font color=\"red\">接口的方法都是没有实现的方法</font>。接口体现了程序设计的<font color=\"red\">多态和高内聚低耦合</font>的思想\n  - 接口不需要显式的实现，只要有一个变量，含有接口的所有方法，那么这个变量就实现了这个接口\n\n### 2.2 一个例子\n\n```go\npackage main\n\nimport \"fmt\"\n\ntype Retriever interface {\n    Get(url string) string\n}\n\nfunc download(r Retriever) string{\n    return r.Get(\"http://www.baidu.com\")\n}\n\nfunc main() {\n    var r Retriever\n    r = demo.Retriever{}\n    fmt.Println(download(r))\n}\n```\n\n```go\npackage demo\n\nimport (\n\t\"time\"\n    \"net/http\"\n)\n\ntype Retriver struct {\n    UserAgent string\n    TimeOut time.Duration\n}\n\nfunc (r Retriver) Get(url string) string{\n    resp,err := http.Get(url)\n    if err != nil {\n        panic(err)\n    }\n    result,err := httputil.DumpResponse(resp,true)\n    resp.Body.Close()\n    if err != nil {\n        panic(err)\n    }\n    return string(result)\n}\n```\n\n**输出结果**：`baidu.com` 的网页信息\n\n### 注意事项\n\n1. 接口本身不能创建实例，但是<font color=\"red\">可以指向一个实现了该接口的自定义类型的变量（实例）</font>\n\n   ```go\n   package main\n   \n   import \"fmt\"\n   \n   type AInterface interface {\n   \tSay()\n   }\n   \n   type Stu struct {\n   \tName string\n   }\n   \n   func (stu Stu) Say() {\n   \tfmt.Println(\"stu Say()\")\n   }\n   \n   func main() {\n   \tvar stu Stu\n   \tvar a AInterface = stu\n   \ta.Say()\n   }\n   \n   ```\n\n   ***输出结果：***`stu Say()`\n\n2. 接口中所有的方法都没有方法体，即都是没有实现的方法\n\n3. 在`Golang`中，一个自定义类型需要将某个接口的所有方法都实现，我们说这个自定义类型实现了该接口\n\n4. 一个自定义类型只有实现了某个接口，才能将该自定义类型的实例（变量）赋值给接口类型\n\n5. 只要有自定义数据类型，就可以实现接口，不仅仅是结构体类型\n\n   ```go\n   type integer int\n   \n   func (i integer) Say() {\n       fmt.Println(\"integer Say i = \",i)\n   }\n   ...\n   \n   var i integer = 10\n   var b AInterface = i\n   b.Say()\n   ```\n\n6. 一个自定义一类型可以实现多个接口\n\n   ```go\n   package main\n   \n   import \"fmt\"\n   \n   type AInterface interface {\n   \tSay()\n   }\n   \n   type BInterface interface {\n   \tHello()\n   }\n   \n   type Monster struct {\n   \n   }\n   \n   func (m Monster) Hello() {\n   \tfmt.Println(\"Monster Hello() ...\")\n   }\n   \n   func (m Monster) Say() {\n   \tfmt.Println(\"Monster Say() ...\")\n   }\n   \n   func main() {\n   \tvar monster Monster\n   \tvar a2 AInterface = monster\n   \tvar b2 BInterface = monster\n   \ta2.Say()\n   \tb2.Hello()\n   }\n   ```\n\n   ***输出结果：***\n\n   ```bash\n   Monster Say() ...\n   Monster Hello() ...\n   \n   Process finished with exit code \n   ```\n\n7. `Golang`接口中不能有任何变量\n\n   ```go\n   type Test interface {\n       Name string // 错\n       Test01() // 对\n       Test02() // 对\n   }\n   ```\n\n8. 一个接口（假设为A）可以继承多个别的接口（比如B、C接口），这时如果要实现A接口，也必须将B、C的接口方法也全都实现。\n\n   ```go\n   package main\n   \n   type CInterface interface {\n   \ttest01()\n   }\n   \n   type BInterface interface {\n   \ttest02()\n   }\n   \n   type AInterface interface {\n   \tCInterface\n   \tBInterface\n   \ttest03()\n   }\n   \n   type Stu struct {\n   \n   }\n   \n   func (stu Stu) test01() {\n   \n   }\n   \n   func (stu Stu) test02() {\n   \n   }\n   \n   func (stu Stu) test03() {\n   \n   }\n   \n   func main() {\n   \tvar stu Stu\n   \tvar a AInterface = stu\n   \ta.test01()\n   }\n   ```\n\n9. interface 类型默认是指针（引用类型），如果没有对 interface 初始化将就使用，name就会输出 `nil`\n\n10. 空接口 `interface{}`没有任何方法，所以所有类型都实现了空接口，即可以吧任何一个变量赋值给空接口。\n\n## 常用的系统接口\n\n### 案例一：对切片进行排序\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"math/rand\"\n\t\"sort\"\n)\n\ntype Hero struct {\n\tName string\n\tAge int\n}\n\ntype HeroSlice []Hero\n\n// 实现interface接口\nfunc (hs HeroSlice) Len() int {\n\treturn len(hs)\n}\n\n// 实现less方法决定排序方式\n// 按照Hero的年龄从小到达排序\nfunc (hs HeroSlice) Less(i,j int) bool {\n\treturn hs[i].Age < hs[j].Age\n}\n\nfunc (hs HeroSlice) Swap(i,j int) {\n\ths[i],hs[j] = hs[j],hs[i]\n}\n\n\nfunc main() {\n\t// 对切片进行排序\n\tintSlice := []int{0,-1,9,10,7,18}\n\tsort.Ints(intSlice)\n\tfmt.Println(intSlice)\n    // 对结构体进行排序，使用系统方法\n\tvar heroes HeroSlice\n\tfor i := 0; i < 10; i++ {\n\t\thero:=Hero{\n\t\t\tName:fmt.Sprintf(\"英雄-%d\",rand.Intn(100)),\n\t\t\tAge:rand.Intn(100),\n\t\t}\n\t\theroes = append(heroes, hero)\n\t}\n\n\tfor _, value := range heroes {\n\t\tfmt.Println(value)\n\t}\n\n\tfmt.Println(\"----------排序后-----------\")\n\tsort.Sort(heroes)\n\tfor _, value := range heroes {\n\t\tfmt.Println(value)\n\t}\n}\n```\n\n","tags":["golang"],"categories":["golang"]},{"title":"面向对象","url":"/2018/11/25/面向对象/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之面向对象\n\n<!-- more -->\n## 面向对象编程\n\n### 1. 说明\n\n1. golang 支持面向对象编程，与传统的面向对象编程语言有区别\n\n2. golang 没有class 类的，面向对象编程是基于struct 结构体来实现的\n\n3. golang 去掉了继承关键字、方法重载、构造函数和析构函数、隐藏的this 指针\n\n4. golang 通过匿名字段来实现继承，多态和封装的特性仍然具备\n\n5. 通过接口关联能实现低耦合、高灵活度\n\n\n### 2. 结构体与结构体变量(实例/对象)的说明\n\n> - 结构体是自定义数据类型，代表一类事物\n> - 结构体变量(实例)是具体的、实际的代表一个具体的变量\n\n### 3. 如何声明结构体\n\n#### 3.1 基本语法\n\n```go\ntype 结构体名称 struct {\n    field1 type\n    field2 type\n}\n\n//------------------------------\n\ntype Student struct {\n    Name string\n    Age int\n    Score float32\n}\n```\n\n#### 3.2 字段、属性\n\n- ​    从概念上或者叫法上看：结构体字段 = 属性 =field\n\n- 字段是结构体的一个组成部分，一般是**基本数据类型、数组**，也可以是引用类型。\n\n- 注意事项和细节说明\n  - 字段声明语法同变量，例：字段名 字段类型\n  - 字段类型可以为：基本类型、数组或引用类型\n  - 在创建一个结构体变量后，如果没有给该字段赋值，则默认为该数据类型的零值(bool false，int 0...)\n  - 结构体是值类型，不同的结构体字段是独立的，互不影响。一个结构体变量字段的更改，不影响另外一个\n  - 结构体成员变量的访问都使用 person.name 用\" . \"来访问\n  - 结构体的所有字段在内存中是<font color=\"red\">连续的</font>\n  - 结构体类型是用户单独定义的类型，和其他类型进行转换时需要有完全相同的字段(名字、个数、类型)\n\n  ```go\n  type A struct {\n      num int\n  }\n  type B struct {\n      num int\n  }\n  \n  func main(){\n      var a A\n      var b B\n      a = A(b)\n      fmt.Println(a,b)\n  }\n  ```\n\n  - 重新定义相当于区别名，在golang 中认为是新的数据类型，但二者之间可以相互强转\n\n  ```go\n  type A struct {\n      num int\n  }\n  type Num A\n  \n  func main(){\n      var a A\n      var num Num\n      a = A(num)\n      fmt.Println(a,num)\n  }\n  ```\n\n  - struct 的每个字段上，可以写一个tag ，该tag 可以通过反射机制获取，常见的使用场景就是序列化和反序列化\n\n  ```go\n  type Monster struct {\n      Name string `json:\"name\"` // `json:\"name\"`就是 struct tag\n      Age int `json:\"age\"`\n  }\n  ```\n\n\n\n\n\n  ### 4. 方法\n\n  1. 基本介绍\n\n     > 在某些情况下，我们需要声明(定义)方法。比如：Person 结构体除了有一些字段外，Person结构体还有一些行为，比如：说话、跑步、学习，这时候就要用到方法才能实现。\n\n  2. 方法的声明和调用\n\n     ```go\n     type A struct {\n         Num int\n     }\n     \n     func (a A)test(){\n         fmt.Println(a.Num)\n     }\n     ```\n\n     - `func (a A)test (){ }`表示A结构体有一方法，方法名为同test\n     - ` (a A)`体现test方法是和A类型绑定的\n     - `test`方法只能通过`A`变量来调，而不能直接调用\n\n  3. 方法快速入门\n\n     - 给Persion 结构添加speak方法，输出xxx是个好人\n\n       ```go\n       type Persion struct {\n           Name string\n           Age int\n       }\n       \n       func (p Persion) speak() {\n           fmt.Println(p.Name,\"is a good man\")\n       }\n       ```\n\n     - 给Persion 结构添加sum方法，输出1+2+...+1000 的结果\n\n       ```go\n       type Persion struct {\n           Name string\n           Age int\n       }\n       \n       func (p Persion) sum() {\n           res := 0\n           for i := 1,i < 1000; i++ {\n               res += i\n           }\n           fmt.Println(p.Name,\"get sum result is \",res)\n       }\n       ```\n\n  4. 方法的调用和传参机制\n\n     > 方法的调用和传参机制和函数基本一致，不一样的是方法调用时，会将调用方法的变量，当做实参也传递给方法。如果是值类型就进行值拷贝，如果是引用类型，进行地址传递。\n\n### 5. 方法和函数的区别\n\n1. 调用方式不一样\n\n   > 函数的调用方式：函数名（实参列表）\n   >\n   > 方法的调用方式：变量.方法名（实参列表）\n\n2. 对于普通函数，接受者为值类型时，不能将指针类型的数据直接传递，反之亦然\n\n3. 对于方法，接受者为值类型时，可以直接用指针类型的变量调用方法，反之亦然\n\n### 6. 面向对象编程步骤\n\n1. 声明（定义）结构体，确定结构体名\n2. 编写结构体字段\n3. 编写结构体的方法\n\n### 7. 包和封装\n\n- 包 ：每一目录一个包\n\n- main包，包含可执行入口\n\n- 为结构体定义的包必须放在同一个目录下，可以是不同文件\n\n- 工厂模式\n\n  - 说明\n\n    > go 的结构体没有构造函数，通常使用工厂模式来解决这个问题\n\n  - 解决问题\n\n    > 如果当前文件需要引入别的包的结构体变量，当别的包的结构体变量首字母并没有大写时，不能直接引入，可以用工厂模式解决。\n\n```go\n// model 包文件\npackage model\n\ntype student struct {\n    Name string\n    Score float64\n}\n\nfunc NewStudent (n string,s float64) *student {\n    return &student{\n        Name: n,\n        Score: s\n    }\n}\n\n//----------------------main.go--------------------\npackage main\n\nimport(\n\t\"model\"\n    \"fmt\"\n)\n\nfunc main() {\n    stu := model.NewStudent(\"jerry\",68.2)\n    fmt.Println(*stu)\n}\n```\n\n- 封装\n\n  - 基本介绍\n\n    > 封装就是把抽象出的字段和对字段的操作封装在一起，数据被保护在内部，程序的其它包只有通过被授权的操作（方法），才能对字段进行操作。\n\n  - 封装的理解和好处\n\n    > 1. 隐藏实现细节\n    > 2. 可以对数据进行验证，保证安全合理\n\n  - 如何体现封装\n\n    > 1. 对结构体中的属性进行封装\n    > 2. 通过方法、包实现封装\n\n  - 封装的实现方法\n\n    > 1. 将结构体、字段（属性）的首字母小写（不能导出，被其他包所使用，类似于private）\n    >\n    > 2. 给结构体所在的包提供一个工厂模式的函数，首字母大写。类似于一个构造函数\n    >\n    > 3. 提供一个首字母大写的Set方法（类似于public），用于属性判断并赋值\n    >\n    >    ```go\n    >    func (var 结构体类型名) SetXXX(参数列表) (返回值列表){\n    >        // 加入数据验证业务逻辑\n    >        var.字段 = 参数\n    >    }\n    >    ```\n    >\n    > 4. 提供一个首字母大写的Get方法（类似于public），用于获取属性的值\n    >\n    >    ```go\n    >    func (var 结构体类型名) GetXxx() {\n    >        return var.age\n    >    }\n    >    ```\n\n  - 实例\n\n    > 对于隐私信息，工资、年龄保密，输入年龄进行验证。\n    >\n    > ```go\n    > package model\n    > \n    > import \"fmt\"\n    > \n    > type person struct{\n    >     name string\n    >     age int\n    >     sal float64\n    > }\n    > \n    > func NewPerson(name string) *person {\n    >     retrun &person{\n    >         name: name\n    >     }\n    > }\n    > \n    > func (p *person) SetAge(age int) {\n    >     if age > 0 && age < 150 {\n    >         p.age = age\n    >     }else {\n    >         return\n    >     }\n    > }\n    > \n    > func (p *person) GetAge() int {\n    >     return p.Age\n    > }\n    > \n    > func (p *person) SetSel(sel float64) {\n    >     p.sel = sel\n    > }\n    > \n    > func (p *person) GetSel () float64 {\n    >     return p.sel\n    > }\n    > ```\n\n  - 扩充系统类型或者别人的类型\n\n    > 1. 定义别名\n    > 2. 使用组合\n\n  ```go\n  package queue \n  \n  type Queue []int\n  \n  func (q *Queue) Push (v int){\n      *q = append(*q,v)\n  }\n  \n  func (q *Queue) Pop() int {\n      head := (*q)[0]\n      *q = (*q)[1:]\n      return head\n  }\n  ```\n\n  ```go\n  package main\n  \n  import (\n  \t\"queue\"\n      \"fmt\"\n  )\n  \n  func main() {\n      q := queue.Queue{1}\n      q.Push(2)\n      q.Push(3)\n      fmt.Println(q.pop())\n      fmt.Println(q.pop())\n  }\n  ```\n\n### 工厂模式\n\n`Golang`中结构体是没有构造函数的，通常用<font color=\"red\">工厂模式</font>来解决这个问题。\n\n众所周知要想一个结构体被其他的包所引用，必须首字母大写，但是有首字母小写的结构体需要被别的抱所访问时，就要使用到工厂模式来解决。\n\n#### 实例一：\n\n使用工厂模式实现跨包创建结构体实例：\n\n```go\n// model包\npackage model\n\ntype student struct {\n    Name string\n    Age int\n}\n\n// 工厂方法\nfunc NewStudent(n string,a int) *student {\n    return &student{\n        Name: n,\n        Age: a,\n    }\n}\n```\n\n```go\n// main 包\npackage main\n\nimport (\n    \"model\"\n    \"fmt\"\n)\n\nfunc main() {\n    var stu = model.NewStudent(\"Tom\",33)\n    fmt.Println(*stu)\n    fmt.Println(stu.Name)\n    fmt.Println(stu.Age)\n}\n```\n\n<font color=\"red\">假设结构体名首字母小写，还有成员变量首字母小写，通过工厂模式来访问成员变量</font>\n\n```go\n// model包\npackage model\n\ntype student struct {\n    name string\n    Age int\n}\n\n// 工厂方法\nfunc NewStudent(n string,a int) *student {\n    return &student{\n        name: n,\n        Age: a,\n    }\n}\n\nfunc (s *student) GetName() string {\n    return s.name\n}\n```\n\n```go\n// main 包\npackage main\n\nimport (\n    \"model\"\n    \"fmt\"\n)\n\nfunc main() {\n    var stu = model.NewStudent(\"Tom\",33)\n    fmt.Println(*stu)\n    fmt.Println(stu.GetName()) //<<<<<<<<<<<<<<<<<<\n    fmt.Println(stu.Age)\n}\n```\n\n","tags":["golang"],"categories":["golang"]},{"title":"基础语法","url":"/2018/11/25/基础语法/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之基础语法\n\n<!-- more -->","tags":["golang"],"categories":["golang"]},{"title":"函数式编程","url":"/2018/11/25/函数式编程/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之函数式编程\n\n<!-- more -->\n\n[TOC]\n\n# 函数式编程\n\n## 1. 函数与闭包\n\n函数可以作为参数、返回值、和变量\n\n- “正统”函数式编程\n\n  - 不可变性：不能有状态，只有常量和函数\n  - 函数只能有一个参数\n\n  ```go\n  package main\n  \n  improt \"fmt\"\n  \n  func adder() func(int) int{\n      sum := 0\n      return func(v int) int {\n          sum += v\n          return sum\n      }\n  }\n  \n  //以下是传统方式函数式编程\n  //type iAdder func(int) (int,iAdder)\n  \n  //func adder2(base int) iAdder {\n  //    return func(v int) (int, iAdder) {\n  //        return base + v, adder2(base + v)\n  //    }\n  //}\n  \n  func main(){\n      a := adder()\n      for i:=0; i<10; i++ {\n          fmt.Printf(\"0 + ... + %d = %d\",i,a(i))\n      }\n  }\n  ```\n\n  函数体有局部变量\n\n  斐波那契数列\n\n  ```go\n  package main \n  \n  func fibonacci() func() int {\n      a,b := 0,1\n      return func() int {\n          a,b = b,a+b\n          return a\n      }\n  }\n  \n   \n  ```\n\n\n### 闭包\n\n\n\n\n\n","tags":["golang"],"categories":["golang"]},{"title":"错误处理及资源管理","url":"/2018/11/25/错误处理及资源管理/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之错误处理及资源管理\n\n<!-- more -->","tags":["golang"],"categories":["golang"]},{"title":"测试与性能调优","url":"/2018/11/25/测试与性能调优/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\ngo语言养成记之测试与性能调优\n\n<!-- more -->","tags":["golang"],"categories":["golang"]},{"title":"Consul","url":"/2018/11/25/consul/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n微服务之Consul\n\n<!-- more -->\n\n\n# Consul\n\n## 1. Consul的介绍\n\n### 1.1 Consul是什么\n\nConsul是HashiCorp公司推出的开源工具，用于实现分布式系统的服务发现与配置。 Consul是分布式的、高可用的、可横向扩展的。它具备以下特性 :\n\n- service discovery：consul通过DNS或者HTTP接口使服务注册和服务发现变的很容易，一些外部服务，例如saas提供的也可以一样注册。\n- health checking：健康检测使consul可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面。\n- key/value storage：一个用来存储动态配置的系统。提供简单的HTTP接口，可以在任何地方操作。\n- multi-datacenter：无需复杂的配置，即可支持任意数量的区域。\n\n**举例说明**\n\n> 邮递员去某公司一栋大楼投递快件，向门卫询问员工甲在哪一个房间，门卫拿起桌上的通讯录查询，告知邮递员员工甲在具体什么位置。假如公司来了一个员工乙，他想让邮递员送过来，就要先让门卫知道自己在哪一个房间，需要去门卫那边登记，员工乙登记后，当邮递员向门卫询问时，门卫就可以告诉邮递员员工乙的具体位置。门卫知道员工乙的具体位置的过程就是服务发现，员工乙的位置信息可以被看作服务信息，门卫的通讯录就是上文中提到的数据交换格式，此例中员工乙就是上文的已方，门卫就是服务发现的提供者。\n\n### 1.2 什么是服务发现\n\n微服务的框架体系中，服务发现是不能不提的一个模块。相信了解或者熟悉微服务的童鞋应该都知道它的重要性。我们看下面的一幅图片：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/uber5.png)\n\n客户端的一个接口，需要调用服务A-N。客户端必须要知道所有服务的网络位置的，以往的做法是配置文件中，或者有些配置在数据库中。这里就带出几个问题：\n\n- 需要配置N个服务的网络位置，加大配置的复杂性\n- 服务的网络位置变化，都需要改变每个调用者的配置\n- 集群的情况下，难以做负载（反向代理的方式除外）\n\n- <font color=\"red\">总结起来一句话：服务多了，配置很麻烦，问题多多</font>\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/uber6.png)\n\n与上图不同的是，加了个服务发现模块。图比较简单，这边文字描述下。服务A-N把当前自己的网络位置注册到服务发现模块（这里注册的意思就是告诉），服务发现就以K-V的方式记录下，K一般是服务名，V就是IP:PORT。服务发现模块定时的轮询查看这些服务能不能访问的了（这就是健康检查）。客户端在调用服务A-N的时候，就跑去服务发现模块问下它们的网络位置，然后再调用它们的服务。这样的方式是不是就可以解决上面的问题了呢？客户端完全不需要记录这些服务网络位置，客户端和服务端完全解耦！\n\n## 2. Consul的安装\n\nConsul用Golang实现，因此具有天然可移植性 (支持 Linux、windows和macOS)。安装包仅包含一个可执行文件。 Consul安装非常简单，只需要下载对应系统的软件包并解压后就可使用。\n\n### 2.1 下载安装\n\n```shell\n# 这里以 Linux系统为例：\n$ wget https://releases.hashicorp.com/consul/1.2.0/consul_1.2.0_linux_amd64.zip\n$ unzip consul_1.2.0_linux_amd64.zip\n$ mv consul /usr/local/bin/\n```\n\n[其他系统](https://www.consul.io/downloads.html)\n\n### 2.2 验证安装\n\n安装 Consul后，通过执行 consul命令，你可以看到命令列表的输出\n\n```shell\n$ consul # 出现下图内容证明安装成功\n```\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/uber7.png)\n\n## 3. Consul主要作用\n\n- client: 客户端, 无状态, 将 HTTP 和 DNS 接口请求转发给局域网内的服务端集群.\n- server: 服务端, 保存配置信息, 高可用集群, 在局域网内与本地客户端通讯, 通过广域网与其他数据中心通讯. 每个数据中心的 server 数量推荐为 3 个或是 5 个\n\n### 3.1 运行 Consul代理\n\nConsul是典型的 C/S架构，可以运行服务模式或客户模式。每一个数据中心必须有至少一个服务节点， 3到5个服务节点最好。非常不建议只运行一个服务节点，因为在节点失效的情况下数据有极大的丢失风险。\n\n### 3.2 运行Agent\n\n完成Consul的安装后,必须运行agent. agent可以运行为server或client模式.每个数据中心至少必须拥有一台server. 建议在一个集群中有3或者5个server.部署单一的server,在出现失败时会不可避免的造成数据丢失.其他的agent运行为client模式.一个client是一个非常轻量级的进程.用于注册服务,运行健康检查和转发对server的查询.agent必须在集群中的每个主机上运行.\n\n### 3.3 启动 Consul Server\n\n```shell\n#node1:\n$ consul agent -server -bootstrap-expect 2 -data-dir /tmp/consul -node=n1 -\nbind=192.168.110.123 -ui -config-dir /etc/consul.d -rejoin -join 192.168.110.123 -\nclient 0.0.0.0\n#运行cosnul agent以server模式\n-server ： 定义agent运行在server模式\n-bootstrap-expect ：在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用\n-data-dir：提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在\n-node：节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名\n-bind：该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0\n-ui： 启动web界面\n-config-dir：：配置文件目录，里面所有以.json结尾的文件都会被加载\n-rejoin：使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中。\n-client：consul服务侦听地址，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1所以不对外提供服务，如果你要对外提供服务改成0.0.0.0\n```\n\n```shell\n#node2:\n$ consul agent -server -bootstrap-expect 2 -data-dir /tmp/consul -node=n2 -\nbind=192.168.110.148 -ui -rejoin -join 192.168.110.123\n-server ： 定义agent运行在server模式\n-bootstrap-expect ：在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用\n-bind：该地址用来在集群内部的通讯，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0\n-node：节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名\n-ui： 启动web界面\n-rejoin：使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中。\n-config-dir：：配置文件目录，里面所有以.json结尾的文件都会被加载\n-client：consul服务侦听地址，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1所以不对外提供服务，如果你要对外提供服务改成0.0.0.0\n-join 192.168.110.121 ： 启动时加入这个集群\n```\n\n### 3.4 启动 Consul Client\n\n```shell\n#node3：\n$ consul agent -data-dir /tmp/consul -node=n3 -bind=192.168.110.124 -config-dir/etc/consul.d -rejoin -join 192.168.110.123\n运行cosnul agent以client模式，-join 加入到已有的集群中去。\n```\n\n- 查看集群成员\n  - **新开一个终端窗口运行consul members, 你可以看到Consul集群的成员**\n\n```shell\n$ consul members\n#节点 网络地址 状态 类型 版本 协议 数据中心 分管部分\nNode Address Status Type Build Protocol DC Segment\nn1 192.168.110.7:8301 alive server 1.1.0 2 dc1 <all>\nn2 192.168.110.121:8301 alive server 1.1.0 2 dc1 <all>\nn3 192.168.110.122:8301 alive client 1.1.0 2 dc1 <default>\n```\n\n### 3.5 停止Agent\n\n可以使用Ctrl-C 优雅的关闭Agent. 中断Agent之后你可以看到他离开了集群并关闭.\n\n在退出中,Consul提醒其他集群成员,这个节点离开了.如果你强行杀掉进程.集群的其他成员应该能检测到这个节点失效了.当一个成员离开,他的服务和检测也会从目录中移除.当一个成员失效了,他的健康状况被简单的标记为危险,但是不会从目录中移除.Consul会自动尝试对失效的节点进行重连.允许他从某些网络条件下恢复过来.离开的节点则不会再继续联系.\n\n此外,如果一个agent作为一个服务器,一个优雅的离开是很重要的,可以避免引起潜在的可用性故障影响达成一致性协议. consul优雅的退出\n\n```shell\n$ consul leave\n```\n\n## 4. 注册服务\n\n搭建好conusl集群后，用户或者程序就能到consul中去查询或者注册服务。可以通过提供服务定义文件或者调用HTTP API来注册一个服务.\n\n- 首先,为Consul配置创建一个目录.Consul会载入配置文件夹里的所有配置文件.在Unix系统中通常类似/etc/consul.d (.d 后缀意思是这个路径包含了一组配置文件).\n\n  ```shell\n  $ mkdir /etc/consul.d\n  ```\n\n- 然后,我们将编写服务定义配置文件.假设我们有一个名叫web的服务运行在 10000端口.另外,我们将给他设置一个标签.这样我们可以使用他作为额外的查询方式:\n\n  ```json\n  {\n  \t\"service\": { //服务\n  \t\t\"name\": \"web\", //名称\n  \t\t\"tags\": [\"master\"], //标记\n  \t\t\"address\": \"127.0.0.1\", //ip\n  \t\t\"port\": 10000, //端口\n  \t\t\"checks\": [\n  \t\t\t{\n  \t\t\t\t\"http\": \"http://localhost:10000/health\",\n  \t\t\t\t\"interval\": \"10s\" //检查时间\n  \t\t\t}\n  \t\t]\n  \t}\n  }\n  ```\n\n- 测试程序\n\n  ```go\n  package main\n  \n  import (\n  \t\"fmt\"\n  \t\"net/http\"\n  ) \n  \n  func handler(w http.ResponseWriter, r *http.Request) {\n  \tfmt.Println(\"hello Web3! This is n3或者n2\")\n  \tfmt.Fprintf(w, \"Hello Web3! This is n3或者n2\")\n  } \n  \n  func healthHandler(w http.ResponseWriter, r *http.Request) {\n  \tfmt.Println(\"health check! n3或者n2\")\n  } \n  \n  func main() {\n  \thttp.HandleFunc(\"/\", handler)\n  \thttp.HandleFunc(\"/health\", healthHandler)\n  \thttp.ListenAndServe(\":10000\", nil)\n  }\n  ```\n\n## 5. 查询服务\n\n一旦agent启动并且服务同步了.我们可以通过DNS或者HTTP的API来查询服务.\n\n- DNS API\n\n  > 让我们首先使用DNS API来查询.在DNS API中,服务的DNS名字是 NAME.service.consul. 虽然是可配置的,但默认的所有DNS名字会都在consul命名空间下.这个子域告诉Consul,我们在查询服务,NAME则是服务的名称.\n  > 对于我们上面注册的Web服务.它的域名是 web.service.consul :\n\n  ```shell\n  $ dig @127.0.0.1 -p 8600 web.service.consul\n  ```\n\n- 有也可用使用 DNS API 来接收包含 地址和端口的 SRV记录:\n\n  ```shell\n  $ dig @127.0.0.1 -p 8600 web.service.consul SRV\n  ```\n\n## 6. Consul架构\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/uber8.png)\n\n我们只看数据中心1，可以看出consul的集群是由N个SERVER，加上M个CLIENT组成的。而不管是`SERVER`还是`CLIENT`，都是consul的一个节点，所有的服务都可以注册到这些节点上，正是通过这些节点实现服务注册信息的共享。除了这两个，还有一些小细节，一一简单介绍。\n\n` CLIENT` CLIENT表示consul的client模式，就是客户端模式。是consul节点的一种模式，这种模式下，所有注册到当前节点的服务会被转发到SERVER【通过HTTP和DNS接\n口请求server】，本身是`不持久化`这些信息。 \n\n`SERVER `SERVER表示consul的server模式，表明这个consul是个server，这种模式下，功能和CLIENT都一样，唯一不同的是，它会把所有的信息持久化的本地，这样遇到故障，信息是可以被保留的 `SERVER-LEADER` 中间那个SERVER下面有LEADER的字眼，表明这个SERVER是它们的老大，它和其它SERVER不一样的一点是，它需要负责同步注册的信息给其它的SERVER，同时也要负责各个节点的健康监测。\n\n- Consul的client mode把请求转向server，那么client的作用是什么？\n\n  > consul可以用来实现分布式系统的服务发现与配置。client把服务请求传递给server，server负责提供服务以及和其他数据中心交互。题主的问题是，既然server端提供了所有服务，那为何还需要多此一举地用client端来接收一\n  > 次服务请求。我想，采用这种架构有以下几种理由： \n  >\n  > 首先server端的网络连接资源有限。对于一个分布式系统，一般情况下访问量是很大的。如果用户能不通过client直接地访问数据中心，那么数据中心必然要为每个用户提供一个单独的连接资源(线程，端口号等等)，那么server端的负担会非常大。所以很有必要用大量的client端来分散用户的连接请求，在client端先统一整合用户的服务请求，然后一次性地通过一个单一的链接发送大量的请求给server端，能够大量减少server端的网络负担。 \n  >\n  > 其次，在client端可以对用户的请求进行一些处理来提高服务的效率，比如将相同的请求合并成同一个查询，再比如将之前的查询通过cookie的形式缓存下来。但是这些功能都需要消耗不少的计算和存储资源。如果在server端提供这些功能，必然加重server端的负担，使得server端更加不稳定。而通过client端来进行这些服务就没有这些问题了，因为client端不提供实际服务，有很充足的计算资源来进行这些处理这些工作。 最后还有一点，consul规定只要接入一个client就能将自己注册到一个服务网络当中。这种架构使得系统的可扩展性非常的强，网络的拓扑变化可以特别的灵活。这也是依赖于client—server结构的。如果系统中只有几个数据中心存在，那网络的扩张也无从谈起了。\n\n- Consul资料：\n- [http://www.liangxiansen.cn/2017/04/06/consul/](http://www.liangxiansen.cn/2017/04/06/consul/)\n- [https://blog.csdn.net/yuanyuanispeak/article/details/54880743](https://blog.csdn.net/yuanyuanispeak/article/details/54880743)\n\n","tags":["微服务"],"categories":["microServices"]},{"title":"GRPC","url":"/2018/11/25/GRPC/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n微服务之GRPC\n\n<!-- more -->\n# GRPC\n\n## 1. 什么是GRPC\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/Uber2.png)\n\n> GRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。GRPC基于 HTTP/2标准设计，带来诸如双向流、流控、头部压缩、单 TCP连接上的多复用请求等特。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。\n>\n> 在 GRPC里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多 RPC系统类似， GRPC也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个GRPC服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。 GRPC客户端和服务端可以在多种环境中运行和交互 -从 google内部的服务器到你自己的笔记本，并且可以用任何 GRPC支持的语言 来编写。所以，你可以很容易地用 Java创建一个GRPC服务端，用 Go、 Python、Ruby来创建客户端。此外， Google最新 API将有 GRPC版本的接口，使你很容易地将 Google的功能集成到你的应用里。\n\n## 2. RPC\n\nRPC（Remote Procedure Call Protocol）\n\n> 远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。\n>\n> 简单来说，就是跟远程访问或者web请求差不多，都是一个client向远端服务器请求服务返回结果，但是web请求使用的网络协议是http高层协议，而rpc所使用的协议多为TCP，是网络层协议，减少了信息的包装，加快了处理速度。\n\ngolang本身有rpc包，可以方便的使用，来构建自己的rpc服务，示例如下：\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/uber3.png)\n\n1. 调用客户端句柄；执行传送参数 \n\n2. 调用本地系统内核发送网络消息 \n\n3. 消息传送到远程主机 \n\n4. 服务器句柄得到消息并取得参数 \n\n5. 执行远程过程 \n\n6. 执行的过程将结果返回服务器句柄\n\n7. 服务器句柄返回结果，调用远程系统内核 \n\n8. 消息传回本地主机 \n\n9. 客户句柄由内核接收消息 \n\n10. 客户接收句柄返回的数据\n\n### 2.1 服务端\n\n```go\npackage main\n\nimport (\n\t\"net/http\"\n\t\"net/rpc\"\n\t\"net\"\n\t\"github.com/astaxie/beego\"\n\t\"io\"\n) \n\n//- 方法是导出的\n//- 方法有两个参数，都是导出类型或内建类型\n//- 方法的第二个参数是指针\n//- 方法只有一个error接口类型的返回值\n\n//func (t *T) MethodName(argType T1, replyType *T2) error\ntype Panda int;\n\nfunc (this *Panda)Getinfo(argType int, replyType *int) error {\n\tbeego.Info(argType)\n\t*replyType =1 +argType\n    return nil\n} \n\nfunc main() {\n\t//注册1个页面请求\n\thttp.HandleFunc(\"/panda\",pandatext)\n\t//new 一个对象\n\tpd :=new(Panda)\n\t//注册服务\n\t//Register在默认服务中注册并公布 接收服务 pd对象 的方法\n\trpc.Register(pd)\n\trpc.HandleHTTP()\n\t//建立网络监听\n\tln , err :=net.Listen(\"tcp\",\"127.0.0.1:10086\")\n\tif err != nil{\n\t\tbeego.Info(\"网络连接失败\")\n\t} \n    beego.Info(\"正在监听10086\")\n\t//service接受侦听器l上传入的HTTP连接，\n\thttp.Serve(ln,nil)\n} \n\n//用来现实网页的web函数\nfunc pandatext(w http.ResponseWriter, r *http.Request) {\n\tio.WriteString(w,\"panda\")\n}\n```\n\n### 2.2 客户端\n\n```go\npackage main\nimport (\n\t\"net/rpc\"\n\t\"github.com/astaxie/beego\"\n) \n\nfunc main() {\n\t//rpc的与服务端建立网络连接\n\tcli,err := rpc.DialHTTP(\"tcp\",\"127.0.0.1:10086\")\n\tif err !=nil {\n\t\tbeego.Info(\"网络连接失败\")\n\t} \n    var val int\n\t//远程调用函数（被调用的方法，传入的参数 ，返回的参数）\n\terr =cli.Call(\"Panda.Getinfo\",123,&val)\n\tif err!=nil{\n    \tbeego.Info(\"打call失败\")\n\t} \n    beego.Info(\"返回结果\",val)\n}\n```\n\n## 3. GRPC使用 protocol buffers\n\nGRPC默认使用protobuf，这是 Google开源的一套成熟的结构数据序列化机制（当然也可以使用其他数据格式如\nJSON）。正如你将在下方例子里所看到的，你用 proto files创建 GRPC服务，用 protoBuf消息类型来定义方法参\n数和返回类型。你可以在 Protocol Buffers文档找到更多关于 protoBuf的资料。 虽然你可以使用 proto2 (当前默\n认的 protocol buffers版本 )，我们通常建议你在 GRPC里使用 proto3，因为这样你可以使用 GRPC支持全部范围的语言，并且能避免 proto2客户端与 proto3服务端交互时出现的兼容性问题，反之亦然。\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/uber4.png)\n\n## 4. Hello GRPC\n\n了解GRPC工作机制最简单的方法是看一个简单的例子。 Hello World将带领你创建一个简单的客户端 —— 服务端应用，向你展示： 通过一个protoBuf模式，定义一个简单的带有 Hello World方法的RPC服务。 用你最喜欢的语言 (如果可用的话 )来创建一个实现了这个接口的服务端。 用大家最喜欢的 (或者其他你愿意的 )语言来访问你的服务端。这个例子完整的代码在我们 GitHub源码库的 examples目录下。我们使用 Git版本系统来进行源码管理，但是除了如何安装和运行一些 Git命令外，你没必要知道其他关于 Git的任何事情。需要注意的是，并不是所有 GRPC支持的语言都可以编写我们例子的服务端代码，比如 PHP和 Objective-C仅支持创建客户端。比起针对于特定语言的复杂教程，这更像是一个介绍性的例子。你可以在本站找到更有深度的教程，GRPC支持的语言的参考文档很快就会全部开放。\n\n### 4.1 环境搭建\n\n```shell\n#将x.zip 解压到 $GOPATH/src/golang.org/x 目录下\n$ unzip x.zip -d $GOPATH/src/golang.org/x\n#-d 是指定解压目录地址\n#/home/itcast/go/src/golang.org\n#文件名为x\n#将google.golang.org.zip 解压到 $GOPATH/src/google.golang.org 目录下\n```\n\n### 4.2 启动服务端\n\n```shell\n$ cd $GOPATH/src/google.golang.org/grpc/examples/helloworld/greeter_server\n$ go run main.go\n```\n\n### 4.3 启动客户端\n\n```shell\n$ cd $GOPATH/src/google.golang.org/grpc/examples/helloworld/greeter_client\n$ go run main.go\n```\n\n### 4.4 客户端代码介绍\n\n```go\npackage main\nimport (\n\t\"log\"\n\t\"os\"\n\t\"golang.org/x/net/context\"\n\t\"google.golang.org/grpc\"\n\tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n\t//这是引用编译好的protobuf\n) \n\nconst (\n\taddress = \"localhost:50051\"\n\tdefaultName = \"world\"\n) \n\nfunc main() {\n\t// 建立到服务器的连接。\n\tconn, err := grpc.Dial(address, grpc.WithInsecure())\n\tif err != nil {\n\t\tlog.Fatalf(\"did not connect: %v\", err)\n\t}\n\t//延迟关闭连接\n\tdefer conn.Close()\n\t//调用protobuf的函数创建客户端连接句柄\n\tc := pb.NewGreeterClient(conn)\n\t// 联系服务器并打印它的响应。\n\tname := defaultName\n\tif len(os.Args) > 1 {\n\t\tname = os.Args[1]\n\t} \n    //调用protobuf的sayhello函数\n\tr, err := c.SayHello(context.Background(), &pb.HelloRequest{Name: name})\n\tif err != nil {\n\t\tlog.Fatalf(\"could not greet: %v\", err)\n    } \n    //打印结果\n\tlog.Printf(\"Greeting: %s\", r.Message)\n}\n```\n\n### 4.5 服务端代码介绍\n\n```go\npackage main\nimport (\n\t\"log\"\n\t\"net\"\n\t\"golang.org/x/net/context\"\n\t\"google.golang.org/grpc\"\n\tpb \"google.golang.org/grpc/examples/helloworld/helloworld\"\n\t\"google.golang.org/grpc/reflection\"\n)\n\nconst (\n\tport = \":50051\"\n)\n\n// 服务器用于实现helloworld.GreeterServer。\ntype server struct{}\n\n// SayHello实现helloworld.GreeterServer\nfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n\treturn &pb.HelloReply{Message: \"Hello \" + in.Name}, nil\n} \n\nfunc main() {\n\t//监听\n\tlis, err := net.Listen(\"tcp\", port)\n\tif err != nil {\n\t\tlog.Fatalf(\"failed to listen: %v\", err)\n\t} \n    //new服务对象\n\ts := grpc.NewServer()\n\t//注册服务\n\tpb.RegisterGreeterServer(s, &server{})\n\t// 在gRPC服务器上注册反射服务。\n\treflection.Register(s)\n\tif err := s.Serve(lis); err != nil {\n\t\tlog.Fatalf(\"failed to serve: %v\", err)\n\t}\n}\n```\n\n## 5. go语言实现GRPC远程调用\n\n### 5.1 protobuf协议定义\n\n创建一个 protobuf package,如： my_rpc_proto;\n在 $GOPATH/src/下创建 /my_grpc_proto/ 文件夹\n里面创建 protobuf 协议文件 helloServer.proto\n\n```shell\n#到工作目录\n$ CD $GOPATH/src/\n#创建目录\n$ mkdir grpc/myproto\n#进入目录\n$ cd grpc/myproto\n#创建proto文件\n$ vim helloServer.proto\n```\n\n- 文件内容\n\n  ```protobuf\n  syntax = \"proto3\";\n  package my_grpc_proto;\n  \n  service HelloServer{\n  \t// 创建第一个接口\n  \trpc SayHello(HelloRequest)returns(HelloReplay){}\n  \t// 创建第二个接口\n  \trpc GetHelloMsg(HelloRequest)returns(HelloMessage){}\n  } \n  \n  message HelloRequest{\n  \tstring name = 1 ;\n  } \n  \n  message HelloReplay{\n  \tstring message = 1;\n  } \n  \n  message HelloMessage{\n  \tstring msg = 1;\n  }\n  ```\n\n- 在当前文件下，编译 helloServer.proto文件\n\n  ```shell\n  $ protoc --go_out=./ *.proto #不加grpc插件\n  $ protoc --go_out=plugins=grpc:./ *.proto #添加grpc插件\n  #对比发现内容增加\n  #得到 helloServer.pb.go文件\n  ```\n\n- GRPC-Server编写\n\n  ```go\n  package main\n  import (\n  \t\"net\"\n  \t\"fmt\"\n  \t\"google.golang.org/grpc\"\n  \tpt \"demo/grpc/proto\"\n  \t\"context\"\n  ) \n  \n  const (\n  \tpost = \"127.0.0.1:18881\"\n  ) \n  \n  //对象要和proto内定义的服务一样\n  type server struct{}\n  //实现RPC SayHello 接口\n  func(this *server)SayHello(ctx context.Context,in *pt.HelloRequest)(*pt.HelloReplay, error){\n  \treturn &pt.HelloReplay{Message:\"hello\"+in.Name},nil\n  } \n  \n  //实现RPC GetHelloMsg 接口\n  func (this *server) GetHelloMsg(ctx context.Context, in *pt.HelloRequest)(*pt.HelloMessage, error) {\n  \treturn &pt.HelloMessage{Msg: \"this is from server HAHA!\"}, nil\n  } \n  \n  func main() {\n  \t//监听网络\n  \tln ,err :=net.Listen(\"tcp\",post)\n  \tif err!=nil {\n  \t\tfmt.Println(\"网络异常\",err)\n  \t}\n  \t// 创建一个grpc的句柄\n  \tsrv:= grpc.NewServer()\n  \t//将server结构体注册到 grpc服务中\n  \tpt.RegisterHelloServerServer(srv,&server{})\n  \t//监听grpc服务\n      err= srv.Serve(ln)\n      if err!=nil {\n  \t\tfmt.Println(\"网络启动异常\",err)\n  \t}\n  }\n  ```\n\n- GRPC-Client编写\n\n  ```go\n  package main\n  \n  import (\n  \t\"google.golang.org/grpc\"\n  \tpt \"demo/grpc/proto\"\n  \t\"fmt\"\n  \t\"context\"\n  ) \n  \n  const (\n  \tpost = \"127.0.0.1:18881\"\n  ) \n  \n  func main() {\n  \t// 客户端连接服务器\n  \tconn,err:=grpc.Dial(post,grpc.WithInsecure())\n  \tif err!=nil {\n  \t\tfmt.Println(\"连接服务器失败\",err)\n  \t} \n      defer conn.Close()\n  \t//获得grpc句柄\n  \tc:=pt.NewHelloServerClient(conn)\n      // 远程调用 SayHello接口\n      //远程调用 SayHello接口\n  \tr1, err := c.SayHello(context.Background(), \t&pt.HelloRequest{Name: \"panda\"})\n  \tif err != nil {\n  \t\tfmt.Println(\"cloud not get Hello server ..\", err)\n  \t\treturn\n  \t} \n      fmt.Println(\"HelloServer resp: \", r1.Message)\n  \t//远程调用 GetHelloMsg接口\n      r2, err := c.GetHelloMsg(context.Background(), &pt.HelloRequest{Name: \"panda\"})\n  \tif err != nil {\n  \t\tfmt.Println(\"cloud not get hello msg ..\", err)\n  \t\treturn\n  \t} \n      fmt.Println(\"HelloServer resp: \", r2.Msg)\n  }\n  ```\n\n- 运行结果\n\n  ```shell\n  #先运行 server，后运行 client\n  #得到以下输出结果\n  HelloServer resp: hellopanda\n  HelloServer resp: this is from server HAHA!\n  #如果反之则会报错\n  ```\n","tags":["微服务"],"categories":["microServices"]},{"title":"Micro","url":"/2018/11/25/micro/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n微服务之Micro\n\n<!-- more -->\n# Micro\n\n## 1. Micro的介绍\n\nMicro解决了构建云本地系统的关键需求。它采用了微服务体系结构模式，并将其转换为一组工具，作为可伸缩平台的构建块。Micro隐藏了分布式系统的复杂性，并为开发人员提供了很好的理解概念。\n\nMicro是一个专注于简化分布式系统开发的微服务生态系统。是一个工具集合, 通过将微服务架构抽象成一组工具。隐藏了分布式系统的复杂性，为开发人员提供了更简洁的概念。\n\n## 2. Micro的安装\n\n### 2.1 下载micro\n\n```shell\n$ go get -u -v github.com/go-log/log\n$ go get -u -v github.com/gorilla/handlers\n$ go get -u -v github.com/gorilla/mux\n$ go get -u -v github.com/gorilla/websocket\n$ go get -u -v github.com/mitchellh/hashstructure\n$ go get -u -v github.com/nlopes/slack\n$ go get -u -v github.com/pborman/uuid\n$ go get -u -v github.com/pkg/errors\n$ go get -u -v github.com/serenize/snaker\n# hashicorp_consul.zip包解压在github.com/hashicorp/consul\n$ unzip hashicorp_consul.zip -d github.com/hashicorp/consul\n# miekg_dns.zip 包解压在github.com/miekg/dns\n$ unzip miekg_dns.zip -d github.com/miekg/dns\n$ go get github.com/micro/micro\n```\n\n### 2.2 编译安装micro\n\n```shell\n$ cd $GOPATH/src/github.com/micro/micro\n$ go build -o micro main.go\n$ sudo cp micro /bin/\n```\n\n### 2.3 插件安装\n\n```shell\n$ go get -u github.com/golang/protobuf/{proto,protoc-gen-go}\n$ go get -u github.com/micro/protoc-gen-micro\n```\n\n## 3. Micro的基本演示\n\n### 3.1 创建微服务命令说明\n\n```shell\nnew Create a new Micro service by specifying a directory path relative to your $GOPATH\n#创建 通过指定相对于$GOPATH的目录路径，创建一个新的微服务。\nUSAGE:\n#用法\nmicro new [command options][arguments...]\n--namespace \"go.micro\" Namespace for the service e.g com.example\n#服务的命名空间\n--type \"srv\" Type of service e.g api, fnc, srv, web\n#服务类型\n--fqdn FQDN of service e.g com.example.srv.service (defaults to\nnamespace.type.alias)\n#服务的正式定义全面\n--alias Alias is the short name used as part of combined name if\nspecified\n#别名是在指定时作为组合名的一部分使用的短名称\nrun Run the micro runtime\n#运行 运行这个微服务时间\n```\n\n### 3.2 创建2个服务\n\n```shell\n$micro new --type \"srv\" micro/rpc/srv\n#\"srv\" 是表示当前创建的微服务类型\n#sss是相对于go/src下的文件夹名称 可以根据项目进行设置\n#srv是当前创建的微服务的文件名\nCreating service go.micro.srv.srv in /home/itcast/go/src/micro/rpc/srv\n. #\n主函数\n├── main.go\n#插件\n├── plugin.go\n#被调用函数\n├── handler\n│ └── example.go\n#订阅服务\n├── subscriber\n│ └── example.go\n#proto协议\n├── proto/example\n│ └── example.proto\n#docker生成文件\n├── Dockerfile\n├── Makefile\n└──README.md\ndownload protobuf for micro:\n\nbrew install protobuf\n$ go get -u github.com/golang/protobuf/{proto,protoc-gen-go}\n$ go get -u github.com/micro/protoc-gen-micro\ncompile the proto file example.proto:\n$ cd /home/itcast/go/src/micro/rpc/srv\nprotoc --proto_path=. --go_out=. --micro_out=. proto/example/example.proto\n#使用创建srv时给的protobuf命令保留用来将proto文件进行编译\nmicro new --type \"web\" micro/rpc/web\nCreating service go.micro.web.web in /home/itcast/go/src/micro/rpc/web\n. #\n主函数\n├── main.go\n#插件文件\n├── plugin.go\n#被调用处理函数\n├── handler\n│ └── handler.go\n#前端页面\n├── html\n│ └── index.html\n#docker生成文件\n├── Dockerfile\n├── Makefile\n└──README.md\n#编译后将web端呼叫srv端的客户端连接内容修改为srv的内容\n#需要进行调通\n```\n\n### 3.3 启动consul进行监管\n\n```shell\n$ consul agent -dev\n```\n\n### 3.4 对srv服务进行的操作\n\n```shell\n#根据提示将proto文件生成为.go文件\n$ cd /home/itcast/go/src/micro/rpc/srv\nprotoc --proto_path=. --go_out=. --micro_out=. proto/example/example.proto\n#如果报错就按照提示将包进行下载\n$ go get -u github.com/golang/protobuf/{proto,protoc-gen-go}\n$ go get -u github.com/micro/protoc-gen-micro\n#如果还不行就把以前的包删掉从新下载\n```\n\n### 3.5 对web服务进行的操作\n\n#### 3.5.1 main文件\n\n```go\npackage main\n\nimport (\n    \"github.com/micro/go-log\"\n    \"net/http\"\n    \"github.com/micro/go-web\"\n    \"micro/rpc/web/handler\"\n) \n\nfunc main() {\n    // 创建1个web服务\n    service := web.NewService(\n        //注册服务名\n        web.Name(\"go.micro.web.web\"),\n        //服务的版本号\n        web.Version(\"latest\"),\n        //！添加端口\n        web.Address(\":8080\"),\n\t)\n\n    //服务进行初始化\n\tif err := service.Init(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n    //处理请求 / 的路由 //当前这个web微服务的 html文件进行映射\n    service.Handle(\"/\", http.FileServer(http.Dir(\"html\")))\n    //处理请求 /example/call 的路由 这个相应函数 在当前项目下的handler\n    service.HandleFunc(\"/example/call\", handler.ExampleCall)\n    //运行服务\n\tif err := service.Run(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\n***将准备好的`html`文件替换掉原有的文件***\n\n#### 3.5.2 handler文件\n\n```go\npackage handler\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"net/http\"\n    \"time\"\n    \"github.com/micro/go-micro/client\"\n    //将srv中的proto的文件导入进来进行通信的使用\n    example \"micro/rpc/srv/proto/example\"\n) \n\n//相应请求的业务函数\nfunc ExampleCall(w http.ResponseWriter, r *http.Request) {\n\t// 将传入的请求解码为json\n\tvar request map[string]interface{}\n\tif err := json.NewDecoder(r.Body).Decode(&request); err != nil{\n\t\thttp.Error(w, err.Error(), 500)\n\t\treturn\n\t} \n    \n    // 调用服务\n\t//替换掉原有的服务名\n\t//通过服务名和\n\texampleClient := example.NewExampleService(\"go.micro.srv.srv\",\n\tclient.DefaultClient)\n\trsp, err := exampleClient.Call(context.TODO(), &example.Request{\n\t\tName: request[\"name\"].(string),\n\t})\n\tif err != nil {\n\t\thttp.Error(w, err.Error(), 500)\n    return\n\t} \n    \n    // we want to augment the response\n\tresponse := map[string]interface{}{\n\t\t\"msg\": rsp.Msg,\n    \t\"ref\": time.Now().UnixNano(),\n\t} \n    \n    // encode and write the response as json\n\tif err := json.NewEncoder(w).Encode(response); err != nil {\n\t\thttp.Error(w, err.Error(), 500)\n\t\treturn\n\t}\n}\n```\n\n#### 3.5.3 升级成为grpc的版本\n\n- 重新生成proto文件、srv的main.go\n\n```go\npackage main\nimport (\n    \"github.com/micro/go-log\"\n    \"github.com/micro/go-micro\"\n    \"micro/grpc/srv/handler\"\n    \"micro/grpc/srv/subscriber\"\n    example \"micro/grpc/srv/proto/example\"\n    \"github.com/micro/go-grpc\"\n) \n\nfunc main() {\n    // New Service\n    service := grpc.NewService(\n    \tmicro.Name(\"go.micro.srv.srv\"),\n    \tmicro.Version(\"latest\"),\n\t) \n    \n    // Initialise service\n    service.Init()\n    // Register Handler\n  \texample.RegisterExampleHandler(service.Server(),\nnew(handler.Example))\n\t// Register Struct as Subscriber\n\tmicro.RegisterSubscriber(\"go.micro.srv.srv\", service.Server(),\nnew(subscriber.Example))\n\t// Register Function as Subscriber\n\tmicro.RegisterSubscriber(\"go.micro.srv.srv\", service.Server(),\nsubscriber.Handler)\n\t// Run service\n\tif err := service.Run(); err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\n- srv的example.go\n\n  ```go\n  package handler\n  \n  import (\n      \"context\"\n      \"github.com/micro/go-log\"\n      example \"micro/grpc/srv/proto/example\"\n  ) \n  \n  type Example struct{}\n  \n  // Call is a single request handler called via client.Call or the generated client code\n  func (e *Example) Call(ctx context.Context, req *example.Request, rsp *example.Response) error {\n  \tlog.Log(\"Received Example.Call request\")\n  \trsp.Msg = \"Hello \" + req.Name\n  \treturn nil\n  }\n  \n  // Stream is a server side stream handler called via client.Stream or the generated client code\n  func (e *Example) Stream(ctx context.Context, req *example.StreamingRequest, stream example.Example_StreamStream) error {\n  \tlog.Logf(\"Received Example.Stream request with count: %d\", req.Count)\n  \tfor i := 0; i < int(req.Count); i++ {\n  \t\tlog.Logf(\"Responding: %d\", i)\n  \t\tif err := stream.Send(&example.StreamingResponse{\n  \t\t\tCount: int64(i),\n  \t\t}); err != nil {\n  \t\t\treturn err\n  \t\t}\n  \t} \n      return nil\n  } \n  \n  // PingPong is a bidirectional stream handler called via client.Stream or the generated client code\n  func (e *Example) PingPong(ctx context.Context, stream\n  example.Example_PingPongStream) error {\n  \tfor {\n  \t\treq, err := stream.Recv()\n  \t\tif err != nil {\n  \t\t\treturn err\n  \t\t} \n      \tlog.Logf(\"Got ping %v\", req.Stroke)\n  \t\tif err := stream.Send(&example.Pong{Stroke: req.Stroke}); err != nil {\n  \t\t\treturn err\n  \t\t}\n  \t}\n  }\n  ```\n\n- 修改web的main.go\n\n  ```go\n  package main\n  import (\n      \"github.com/micro/go-log\"\n      \"net/http\"\n      \"github.com/micro/go-web\"\n  \t\"micro/grpc/web/handler\"\n  ) \n  \n  func main() {\n      // create new web service\n      service := web.NewService(\n      \tweb.Name(\"go.micro.web.web\"),\n      \tweb.Version(\"latest\"),\n      \tweb.Address(\":8080\"),\n      )\n  \t// initialise service\n  \tif err := service.Init(); err != nil {\n  \t\tlog.Fatal(err)\n  \t}\n  \t// register html handler\n  \tservice.Handle(\"/\", http.FileServer(http.Dir(\"html\")))\n  \t// register call handler\n  \tservice.HandleFunc(\"/example/call\", handler.ExampleCall)\n  \t// run service\n  \tif err := service.Run(); err != nil {\n  \t\tlog.Fatal(err)\n  \t}\n  }\n  ```\n\n- 修改web的handler.go\n\n  ```go\n  package handler\n  \n  import (\n  \t\"context\"\n      \"encoding/json\"\n      \"net/http\"\n      \"time\"\n      example \"micro/grpc/srv/proto/example\"\n      \"github.com/micro/go-grpc\"\n  ) \n  \n  func ExampleCall(w http.ResponseWriter, r *http.Request) {\n      server :=grpc.NewService()\n      server.Init()\n      // decode the incoming request as json\n      var request map[string]interface{}\n      if err := json.NewDecoder(r.Body).Decode(&request); err != nil {\n  \t\thttp.Error(w, err.Error(), 500)\n  \t\treturn\n  \t} \n      \n      // call the backend service\n  \t//exampleClient := example.NewExampleService(\"go.micro.srv.srv\",client.DefaultClient)\n  \texampleClient := example.NewExampleService(\"go.micro.srv.srv\", server.Client())\n  \trsp, err := exampleClient.Call(context.TODO(), &example.Request{\n  \t\tName: request[\"name\"].(string),\n  })\n  \tif err != nil {\n     \t\thttp.Error(w, err.Error(), 500)\n  \t\treturn\n  \t} \n      \n      // we want to augment the response\n  \tresponse := map[string]interface{}{\n  \t\t\"msg\": rsp.Msg,\n  \t\t\"ref\": time.Now().UnixNano(),\n  \t} \n      // encode and write the response as json\n  \tif err := json.NewEncoder(w).Encode(response); err != nil {\n  \t\thttp.Error(w, err.Error(), 500)\n  \t\treturn\n  \t}\n  }\n  ```\n\n## 4. 关于插件化\n\nGo Micro跟其他工具最大的不同是它是插件化的架构，这让上面每个包的具体实现都可以切换出去。举个例子，默认的服务发现的机制是通过Consul，但是如果想切换成`etcd`或者`zookeeper `或者任何你实现的方案，都是非常便利的","tags":["微服务"],"categories":["microServices"]},{"title":"protobuf","url":"/2018/11/25/protobuf/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n微服务之protobuf\n\n<!-- more -->\n# protobuf\n\n## 1. protobuf 简介\n\n> <font color=\"red\">Google Protocol Buffer(简称 Protobuf)</font>是一种轻便高效的结构化数据格式，无关平台、无关语言、可扩展，用于通讯协议和数据存储等领域。\n\n### 1.1 protobuf 的优点\n\n> protobuf 有如XML，不过它更小、更快、规范、更简单。可以自定义自己的数据结构，然后使用代码生成器的代码来读写这个数据结构。甚至可以在无需重新部署程序的情况下更新数据结构。只需使用protobuf 对数据结构进行一次描述，即可利用各种不同的语言或从各种不同数据流中对结构化的数据轻松读写。\n>\n> protobuf 向后兼容性好，不必破坏已经部署的“老”数据格式的程序就可以对数据结构进行升级。\n>\n> protobuf 语义更清晰，无需类似XML 解析器的东西（因为protobuf 编译器会将.proto 文件编译生成对应的数据，访问类似于对protobuf 数据进行序列化、反序列化操作）。\n>\n> protobuf 的编程模式比较友好，无需学习复杂的文档对象模型，简单易学。\n\n### 1.2 protobuf 的缺点\n\n> protobuf 与 XML 相比的不足之处有以下几点：\n>\n> - 功能简单，无法用来表示复杂的概念\n> - XML 已经成为多种行业的标准编写工具，protobuf 只是Google 内部使用的工具，在通用性上差很多\n> - 文本并不适合描述数据结构，所以 protobuf 不适合用来对基于文本的标记文档（如HTML）建模\n> - 由于XML具有某种程度的字自解释性，它可以被人直接读取编辑，protobuf不行，它以二进制的方式存储，除非有 .proto 定义，否则无法直接读出 protobuf 的任何内容\n\n## 2. 常见数据交互的格式比较\n\n1. json：一般的web项目中，最流行的主要还是json，因为浏览器对于json数据支持非常好，有很多内建函数的支持。\n\n2. XML：在 WebService 中应用最为广泛，但相比json 更加冗余，因为需要成对的闭合标签，而json 使用了 键值对的方式，不仅压缩了一定的数据空间，而且具有一定的可读性\n\n3. protobuf：是谷歌开源的一种数据格式，适合高性能，对响应速度有要求的传输数据场景。protobuf 是二进制数据，需要编码和解码，数据本身并不具有可读性，只有对其进行反序列化之后才能得到可读的数据\n\n   > 对于其他数据格式，protobuf的优势\n   >\n   > 1. 序列化之后体积相对于json 和 XML 很小，适合网络传输\n   > 2. 支持跨平台多语言\n   > 3. 消息格式升级兼容性好\n   > 4. 序列化、反序列化的速度快，快于json的处理速度\n\n## 3. protobuf 的安装\n\n### 3.1 安装 protobuf\n\n```shell\n# 下载 protobuf\n$ git clone https://github.com/protocolbuffers/protobuf.git\n\n# 下载依赖库\n$ sudo apt-get install autoconf automake libtool curl make g++ unzip libffi-dev -y\n\n# 安装\n$ cd protobuf/\n$ ./autogen.sh\n$ ./configure\n$ make\n$ sudo make install\n$ sudo ldconfig # 刷新共享库（重要）\n$ protoc -h\n# 出现帮助列表说明protobuf 安装成功\n```\n\n### 3.2 获取 proto 包\n\n```shell\n$ go get -v -u github.com/golang/protobuf/protoc\n```\n\n### 3.3 安装 protoc-gen-go 插件\n\n```shell\n# 安装\n$ go get -v -u github.com/golang/protobuf/protoc-gen-go\n# 编译\n$ cd $GOPATH/src/github.com/golang/protobuf/protoc-gen-go\n$ go build\n# 将生成的 protoc-gen-go 可执行文件放在/bin 目录下\n$ sudo cp protoc-gen-go /bin/\n```\n\n## 4. protobuf 的语法\n\n### 4.1 定义一个消息\n\n要想使用 protobuf 必须先得定义 proto 文件，所以先得 熟悉消息定义的相关语法\n\n```protobuf\nsyntax = \"proto3\";\n\nmessage BruceRequest {\n    string name = 1;\n    int32 height = 2;\n    repeated int32 weight = 3；\n}\n```\n\n- **BruceRequest** 消息格式有三个字段，在消息中承载的数据分别对应于每一个字段，其中每一个字段都有一个名字和一种类型\n\n- 文件第一行是指定了使用`proto3` 语法，如果没有指定，默认`proto2` 语法。指定语法行，必须是非空、非注释的第一行\n- ` repeated` 关键字表示重复的，在go语言中用切片进行代表\n- 在消息定义中每个字段都有一个唯一的标识符\n\n### 4.3 定义一个消息类型\n\n在一个 .proto 文件中可以定义多个消息类型。在定义多个相关的消息的时候，这一点特别有用——例如，如果想定义与 SearchResponse 消息类型对应的回复消息格式的话，你可以将它添加到相同的 .proto 文件中\n\n```protobuf\nsyntax = \"proto3\";\n\nmessage BruceRequest {\n    string name = 1;\n    int32 height = 2;\n    repeated int32 weight = 3；\n}\n\nmessage AlexRequest {\n    ...\n}\n```\n\n### 4.4 添加注释 \n\n如一般的编程语言一直使用 '//'\n\n```protobuf\nsyntax = \"proto3\";\n\nmessage BruceRequest {\n    string name = 1; // 姓名\n    int32 height = 2; // 身高\n    repeated int32 weight = 3；// 体重\n}\n\nmessage AlexRequest {\n    ...\n}\n```\n\n### 4.5 .proto 文件生成文件\n\n当用protocol buffer编译器来运行.proto文件时，编译器将生成所选择语言的代码，这些代码可以操作在.proto文件中定义的消息类型，包括获取、设置字段值，将消息序列化到一个输出流中，以及从一个输入流中解析消息。\n\n> 对C++来说，编译器会为每个.proto文件生成一个.h文件和一个.cc文件，.proto文件中的每一个消息有一个对应的类。 对Python来说，有点不太一样——Python编译器为.proto文件中的每个消息类型生成一个含有静态描述符的模块，，该模块与一个元类（metaclass）在运行时（runtime）被用来创建所需的Python数据访问类。 对go来说，编译器会为每个消息类型生成了一个.pd.go文件。\n\n### 4.6 标准数据类型\n\n一个标量消息字段可以含有一个如下的类型:\n\n> 该表格展示了定义于.proto文件中的类型，以及与之对应的、在自动生成的访问类中定义的类型\n\n|  .proto  |                            Notes                             |  C++   |   Python    |   Go    |\n| :------: | :----------------------------------------------------------: | :----: | :---------: | :-----: |\n|  double  |                                                              | double |    float    | float64 |\n|  float   |                                                              | float  |    float    | float32 |\n|  int32   | 使用变长编码，对于负值的效率很低,如果你的域有可能有负值，请使用sint64替代 | int32  |     int     |  int32  |\n|  uint32  |                         使用变长编码                         | uint32 |  int/long   | uint32  |\n|  uint64  |                         使用变长编码                         | uint64 |  int/long   | uint64  |\n|  sint32  |        使用变长编码，这些编码在负值时比int32高效的多         | int32  |     int     |  int32  |\n|  sint64  |    使用变长编码，有符号的整型值。编码时比通常的int64高效     | int64  |  int/long   |  int64  |\n| fixed32  | 总是4个字节，如果数值总是比总是比228大的话，这个类型会比uint32高效 | uint32 |     int     | uint32  |\n| fixed64  | 总是8个字节，如果数值总是比总是比256大的话，这个类型会比uint64高效 | uint64 |  int/long   | uint64  |\n| sfixed32 |                         总是4个字节                          | int32  |     int     |  int32  |\n| sfixed32 |                         总是4个字节                          | int32  |     int     |  int32  |\n| sfixed64 |                         总是8个字节                          | int64  |  int/long   |  int64  |\n|   bool   |                                                              |  bool  |    bool     |  bool   |\n|  string  |      一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本      | string | str/unicode | string  |\n|  bytes   |                  可能包含任意顺序的字节数据                  | string |     str     | []byte  |\n\n#### 4.6.1 默认值\n\n当一个消息被解析的时候，如果被编码的信息不包含一个特定的元素，被解析的对象锁对应的域被设置位一个默认值，对于不同类型指定如下： \n\n- 对于strings，默认是一个空string \n- 对于bytes，默认是一个空的bytes \n- 对于bool，默认是false \n- 对于数值类型，默认是0\n\n### 4.7 使用其他消息类型\n\n可以将其他消息类型用作字段类型。\n\n> 例如，假设在每一个PersonInfo消息中包含Person消息，此时可以在相同的 .proto 文件中定义一个Result消息类型，然后在PersonInfo消息中指定一个Person类型的字段\n\n```protobuf\nsyntax = \"proto3\";\n\nmessage BruceRequest {\n    string name = 1;\n    int32 height = 2;\n    repeated int32 weight = 3；\n}\n```\n\n### 4.8 使用proto2消息类型\n\n在你的proto3消息中导入proto2的消息类型也是可以的，反之亦然，然后proto2枚举不可以直接在proto3的标识符中使用（如果仅仅在proto2消息中使用是可以的）。\n\n#### 4.8.1 嵌套类型\n\n你可以在其他消息类型中定义、使用消息类型，在下面的例子中，Person消息就定义在PersonInfo消息内，如：\n\n```protobuf\nmessage PersonInfo {\n\tmessage Person {\n\t\tstring name = 1;\n\t\tint32 shengao = 2;\n\t\trepeated int32 tizhong = 3;\n\t} \n\trepeated Person info = 1;\n}\n```\n\n如果你想在它的父消息类型的外部重用这个消息类型，你需要以PersonInfo.Person的形式使用它，如：\n\n```protobuf\nmessage PersonMessage {\n\tPersonInfo.Person info = 1;\n}\n```\n\n当然，你也可以将消息嵌套任意多层，如：\n\n```protobuf\nmessage Grandpa { // Level 0\n\tmessage Father { // Level 1\n\t\tmessage son { // Level 2\n\t\t\tstring name = 1;\n\t\t\tint32 age = 2;\n\t\t}\n\t} \n\n\tmessage Uncle { // Level 1\n\t\tmessage Son { // Level 2\n\t\t\tstring name = 1;\n\t\t\tint32 age = 2;\n\t\t}\n\t}\n}\n```\n\n#### 4.8.2 定义服务(Service)\n\n果想要将消息类型用在RPC(远程方法调用)系统中，可以在.proto文件中定义一个RPC服务接口，protocol buffer编译器将会根据所选择的不同语言生成服务接口代码及存根。如，想要定义一个RPC服务并具有一个方法，该方法能够接收 SearchRequest并返回一个SearchResponse，此时可以在.proto文件中进行如下定义：\n\n```protobuf\nservice SearchService {\n\t//rpc 服务的函数名 （传入参数）返回（返回参数）\n\trpc Search (SearchRequest) returns (SearchResponse);\n}\n```\n\n最直观的使用protocol buffer的RPC系统是gRPC一个由谷歌开发的语言和平台中的开源的RPC系统，gRPC在使用protocl buffer时非常有效，如果使用特殊的protocol buffer插件可以直接为您从.proto文件中产生相关的RPC代码。\n\n如果你不想使用gRPC，也可以使用protocol buffer用于自己的RPC实现，你可以从proto2语言指南中找到更多信息\n\n#### 4.8.3 生成访问类\n\n可以通过定义好的.proto文件来生成Java,Python,C++, Ruby, JavaNano, Objective-C,或者C# 代码，需要基于.proto文件运行protocol buffer编译器protoc。如果你没有安装编译器，下载安装包并遵照README安装。对于Go,你还需要安装一个特殊的代码生成器件。你可以通过GitHub上的protobuf库找到安装过程\n通过如下方式调用protocol编译器:\n\n```shell\n$ protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR path/to/file.proto\n```\n\nIMPORT_PATH声明了一个.proto文件所在的解析import具体目录。如果忽略该值，则使用当前目录。如果有多个目录则可以多次调用--proto_path，它们将会顺序的被访问并执行导入。-I=IMPORT_PATH是--proto_path的简化形式。\n\n**当然也可以提供一个或多个输出路径：**\n\n --cpp_out 在目标目录DST_DIR中产生C++代码，可以在C++代码生成参考中查看更多。 \n\n--python_out 在目标目录 DST_DIR 中产生Python代码，可以在Python代码生成参考中查看更多。\n\n--go_out 在目标目录 DST_DIR 中产生Go代码，可以在GO代码生成参考中查看更多。\n\n> 作为一个方便的拓展，如果DST_DIR以.zip或者.jar结尾，编译器会将输出写到一个ZIP格式文件或者符合JAR标准的.jar文件中。注意如果输出已经存在则会被覆盖，编译器还没有智能到可以追加文件。 - 你必须提议一个或多个.proto文件作为输入，多\n> 个.proto文件可以只指定一次。虽然文件路径是相对于当前目录的，每个文件必须位于其IMPORT_PATH下，以便每个文件可以确定其规范的名称。\n\n#### 4.8.4 测试\n\nprotobuf的使用方法是将数据结构写入到 .proto文件中，使用 protoc编译器编译(间接使用了插件）得到一个新的go包，里面包含 go中可以使用的数据结构和一些辅助方法。\n\n- 编写 test.proto文件\n\n  - $GOPATH/src/创建 myproto文件夹\n\n    ```shell\n    $ cd $GOPATH/src/\n    $ mkdir myproto\n    ```\n\n  - myproto文件夹中创建 test.proto文件 (protobuf协议文件)\n\n    ```sh\n    $ vim test.proto\n    ```\n\n  - 文件内容\n\n    ```protobuf\n    syntax = \"proto3\";\n    package myproto;\n    \n    message Test {\n    \tstring name = 1;\n    \tint32 stature = 2 ;\n    \trepeated int64 weight = 3;\n    \tstring motto = 4;\n    }\n    ```\n\n- 编译 :执行\n\n  ```sh\n  $ protoc --go_out=./ *.proto \n  # 生成 test.pb.go文件\n  ```\n\n- 使用 protobuf 做数据格式转换\n\n  ```go\n  package main\n  \n  import (\n  \t\"fmt\"\n  \t\"github.com/golang/protobuf/proto\"\n  \t\"myproto\"\n  ) \n  \n  func main() {\n  \ttest := &myproto.Test{\n  \t\tName : \"panda\",\n  \t\tStature : 180,\n  \t\tWeight : []int64{120,125,198,180,150,180},\n  \t\tMotto : \"天行健，地势坤\",\n  \t} \n      //将Struct test 转换成 protobuf\n  \tdata,err:= proto.Marshal(test)\n  \tif err!=nil{\n  \t\tfmt.Println(\"转码失败\",err)\n  \t} \n      //得到一个新的Test结构体 newTest\n  \tnewtest:= &myproto.Test{}\n      //将data转换为test结构体\n  \terr = proto.Unmarshal(data,newtest)\n  \tif err!=nil {\n  \t\tfmt.Println(\"转码失败\",err)\n  \t} \n      fmt.Println(newtest.String())\n  \t//得到name字段\n  \tfmt.Println(\"newtest->name\",newtest.GetName())\n  \tfmt.Println(\"newtest->Stature\",newtest.GetStature())\n  \tfmt.Println(\"newtest->Weight\",newtest.GetWeight())\n  \tfmt.Println(\"newtest->Motto\",newtest.GetMotto())\n  }\n  ```\n\n\n\n\n\n\n","tags":["微服务"],"categories":["microServices"]},{"title":"微服务基础简介","url":"/2018/11/25/01/","content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n微服务基础概念简介\n\n<!-- more -->\n\n\n\n# 一、微服务（microServices）\n\n## 1. 什么是微服务？\n\n在介绍微服务时，首先得先理解什么是微服务，顾名思义，微服务得从两个方面去理解，什么是\"微\"、什么是\"服\n务\"？ 微（micro） 狭义来讲就是体积小，著名的\"2 pizza 团队\"很好的诠释了这一解释（2 pizza 团队最早是亚马\n逊 CEO Bezos提出来的，意思是说单个服务的设计，所有参与人从设计、开发、测试、运维所有人加起来 只需要2个披萨就够了 ）。 服务（service） 一定要区别于系统，服务一个或者一组相对较小且独立的功能单元，是用户\n可以感知最小功能集。\n\n那么广义上来讲，微服务是一种分布式系统解决方案，推动细粒度服务的使用，这些服务协同工作。\n\n## 2. 为什么需要微服务？\n\n### 2.1 开发单体式应用的不足之处\n\n- **单体式打车软件的架构示意图**\n\n![示意图](https://github.com/AlexBruceLu/DAPP/wiki/Uber0.png)\n\n\n\n- **三层架构（MVC）的具体内容如下：**\n\n  - **表示层（view）**： 用户使用应用程序时，看到的、听见的、输入的或者交互的部分。\n\n  - **业务逻辑层（controller）**： 根据用户输入的信息，进行逻辑计算或者业务处理的部分。\n\n  - **数据访问层（model）**： 关注有效地操作原始数据的部分，如将数据存储到存储介质（如数据库、文件系统）及从存储介质中读取数据等。\n\n    > <font color=\"green\">虽然现在程序被分成了三层，但只是逻辑上的分层，并不是物理上的分层。也就是说，对不同层的代码而言，经过编译、打包和部署后，所有的代码最终还是运行在同一个进程中。而这，就是所谓的单块架构。</font>\n\n- **随着业务的不断扩大，不断暴露出的问题**\n\n  - 复杂性逐渐变高\n\n    > 比如有的项目有几十万行代码，各个模块之间区别比较模糊，逻辑比较混乱，代码越多复杂性越高，越难解决遇到的问题。\n\n  - 技术债务逐渐上升\n\n    > 公司的人员流动是再正常不过的事情，有的员工在离职之前，疏于代码质量的自我管束，导致留下来很多坑，由于单体项目代码量庞大的惊人，留下的坑很难被发觉，这就给新来的员工带来很大的烦恼，人员流动越大所留下的坑越多，也就是所谓的技术债务越来越多。\n\n  - 维护成本大\n\n    > 当应用程序的功能越来越多、团队越来越大时，沟通成本、管理成本显著增加。当出现 bug 时，可能引起 bug 的原因组合越来越多，导致分析、定位和修复的成本增加；并且在对全局功能缺乏深度理解的情况下，容易在修复bug 时引入新的 bug。\n\n  - 持续交付周期长\n\n    > 构建和部署时间会随着功能的增多而增加，任何细微的修改都会触发部署流水线。新人培养周期长：新成员了解背景、熟悉业务和配置环境的时间越来越长。 技术选型成本高 单块架构倾向于采用统一的技术平台或方案来解决所有问题，如果后续想引入新的技术或框架，成本和风险都很大。\n\n  - 可扩展性差\n\n    > 随着功能的增加，垂直扩展的成本将会越来越大；而对于水平扩展而言，因为所有代码都运行在同一个进程，没办法做到针对应用程序的部分功能做独立的扩展。\n\n### 2.2 微服务的优点\n\n- **微服务架构示意图**\n\n![](https://github.com/AlexBruceLu/DAPP/wiki/Uber1.png)\n\n- <font color=\"red\">**微服务架构的特性**</font>\n\n  - 职责单一\n\n    > 微服务架构中的每个服务，都是具有业务逻辑的，符合高内聚、低耦合原则以及单一职责原则的单元，不同的服务通过“管道”的方式灵活组合，从而构建出庞大的系统。\n\n  - 轻量级通信\n\n    > 服务之间通过轻量级的通信机制实现互通互联，而所谓的轻量级，通常指语言无关、平台无关的交互方式。对于轻量级通信的格式而言，我们熟悉的 XML 和 JSON，它们是语言无关、平台无关的；对于通信的协议而言，通常基于 HTTP，能让服务间的通信变得标准化、无状态化。目前大家熟悉的 REST（Representational State Transfer）是实现服务间互相协作的轻量级通信机制之一。使用轻量级通信机制，可以让团队选择更适合的语言、工具或者平台来开发服务本身。\n    >\n    > <font color=\"red\">问：REST是什么和restful一样吗？</font>\n    > 答：REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就RESTful。\n\n  - 独立性\n\n    > 在微服务架构中，每个服务都是独立的业务单元，与其他服务高度解耦，只需要改变当前服务本身，就可以完成独立的开发、测试和部署。\n\n  - 进程隔离\n\n    > 在微服务架构中，应用程序由多个服务组成，每个服务都是高度自治的独立业务实体，可以运行在独立的进程中，不同的服务能非常容易地部署到不同的主机上。\n\n### 2.3 微服务的缺点\n\n- 运维要求较高\n\n  > 对于单体架构来讲，我们只需要维护好这一个项目就可以了，但是对于微服务架构来讲，由于项目是由多个微服务构成的，每个模块出现问题都会造成整个项目运行出现异常，想要知道是哪个模块造成的问题往往是不容易的，因为我们无法一步一步通过debug的方式来跟踪，这就对运维人员提出了很高的要求。\n\n- 分布式的复杂性\n\n  > 对于单体架构来讲，我们可以不使用分布式，但是对于微服务架构来说，分布式几乎是必会用的技术，由于分布式本身的复杂性，导致微服务架构也变得复杂起来。\n  >\n\n- 接口调整成本高\n\n  > 比如，用户微服务是要被订单微服务和电影微服务所调用的，一旦用户微服务的接口发生大的变动，那么所有依赖它的微服务都要做相应的调整，由于微服务可能非常多，那么调整接口所造成的成本将会明显提高。\n\n- 重复劳动\n\n  > 对于单体架构来讲，如果某段业务被多个模块所共同使用，我们便可以抽象成一个工具类，被所有模块直接调用，但是微服务却无法这样做，因为这个微服务的工具类是不能被其它微服务所直接调用的，从而我们便不得不在每个微服务上都建这么一个工具类，从而导致代码的重复。\n\n## 3. 传统单体架构与分布式微服务架构的区别\n\n|                |    **传统单体架构**    |              **分布式微服务化架构**              |\n| :------------: | :--------------------: | :----------------------------------------------: |\n| **新功能开发** |        需要时间        |                  容易开发和实线                  |\n|    **部署**    |   不经常而且容易部署   |                经常发布，部署复杂                |\n|   **隔离性**   |     故障影响范围大     |                  故障影响范围小                  |\n|  **架构设计**  |   初期设计选型难度大   |                  设计逻辑难度大                  |\n|  **系统性能**  |  响应时间快，吞吐量小  |               响应时间慢，吞吐量大               |\n|  **系统运维**  |        运维简单        |                     运维复杂                     |\n|  **新人上手**  | 学习曲线大（应用逻辑） |              学习曲线大（架构逻辑）              |\n|    **技术**    |    技术单一而且封闭    |                 技术多样而且开发                 |\n| **测试和差错** |          简单          | 复杂（每个服务都要进行单独测试，还需要集群测试） |\n| **系统扩展性** |        扩展性差        |                     扩展性好                     |\n|  **系统管理**  |    重点在于开发成本    |              重点在于服务治理和调度              |\n\n## 4. 为什么使用微服务架构\n\n- 开发简单\n\n  > 微服务架构将复杂系统进行拆分之后，让每个微服务应用都开放变得非常简单，没有太多的累赘。对于每一个开发者来说，这无疑是一种解脱，因为再也不用进行繁重的劳动了，每天都在一种轻松愉快的氛围中工作，其效率也会整备地提高\n\n- 快速响应需求变化\n\n  > 一般的需求变化来自于举步功能的变化，这种变化落实到每个微服务上，而每个微服务的功能相对来说都非常简单，更改起来非常容易，所以微服务非常适合敏捷开发方式，能够快速的影响业务的需求变化。\n\n- 随时随地更新\n\n  > 一方面，微服务的部署和更新并不会影响全局系统的正常运行；\n  >\n  > 另一方面，使用多实例的部署方法，可以做到一个服务的重启和更新在不易察觉的情况下进行，所以每个服务任何时候都可以进行更新部署。\n\n- 系统更加稳定可靠\n\n  > 微服务运行在一个高可用的分布式环境之中，有配套的监控和调度管理机制，并且还可以提供自由伸缩的管理，充分保证了系统的稳定性和可靠性。\n\n","tags":["微服务"],"categories":["microServices"]}]